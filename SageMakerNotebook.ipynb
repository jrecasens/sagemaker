{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting financial time series with dynamic deep learning: A combo RNN architecture with GRUs and covariates compared to ARIMAx and DeepAR              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and define session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed for this session to develop and evaluate the RNN combo designed in train file\n",
    "import boto3, s3fs\n",
    "import re, os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import sagemaker as sage\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from time import gmtime, strftime\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Define IAM role and session\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data and define model image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-452477717799\n"
     ]
    }
   ],
   "source": [
    "# Upload directory with data files on daily stock values and top news headlines \n",
    "data_location = sess.upload_data('./inputdata', key_prefix='data')\n",
    "\n",
    "# Define model artifact name and image\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "artifactname = 'rnn-forecast009'\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account, region, artifactname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and push Docker container on ECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  117.1MB\r",
      "\r\n",
      "Step 1/9 : FROM ubuntu:16.04\n",
      " ---> f975c5035748\n",
      "Step 2/9 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 1c403bf931a3\n",
      "Step 3/9 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 54aff9ba0378\n",
      "Step 4/9 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip install numpy scipy scikit-learn pandas flask gevent gunicorn keras tensorflow theano h5py textblob\n",
      " ---> Using cache\n",
      " ---> e2cf555147db\n",
      "Step 5/9 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 694bbf80e51e\n",
      "Step 6/9 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 76ab5ff77959\n",
      "Step 7/9 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> cddf80f39f29\n",
      "Step 8/9 : COPY rnn /opt/program\n",
      " ---> 9edab3943433\n",
      "Step 9/9 : WORKDIR /opt/program\n",
      "Removing intermediate container bab8c7d5e991\n",
      " ---> fdbb83a01cde\n",
      "Successfully built fdbb83a01cde\n",
      "Successfully tagged rnn-forecast009:latest\n",
      "The push refers to repository [452477717799.dkr.ecr.us-east-1.amazonaws.com/rnn-forecast009]\n",
      "3b57881c2e7d: Preparing\n",
      "78ae4b121de1: Preparing\n",
      "90c657f2c0c8: Preparing\n",
      "db584c622b50: Preparing\n",
      "52a7ea2bb533: Preparing\n",
      "52f389ea437e: Preparing\n",
      "88888b9b1b5b: Preparing\n",
      "a94e0d5a7c40: Preparing\n",
      "88888b9b1b5b: Waiting\n",
      "a94e0d5a7c40: Waiting\n",
      "52f389ea437e: Waiting\n",
      "90c657f2c0c8: Layer already exists\n",
      "52a7ea2bb533: Layer already exists\n",
      "db584c622b50: Layer already exists\n",
      "78ae4b121de1: Layer already exists\n",
      "a94e0d5a7c40: Layer already exists\n",
      "88888b9b1b5b: Layer already exists\n",
      "52f389ea437e: Layer already exists\n",
      "3b57881c2e7d: Pushed\n",
      "latest: digest: sha256:c76618f4afcd17e8797f3087855ea931857770faa350f7b32740cdeebb9375e9 size: 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Name artifact\n",
    "artifactname=rnn-forecast009\n",
    "\n",
    "# Build and push the container\n",
    "cd container\n",
    "chmod +x rnn/serve\n",
    "chmod +x rnn/train\n",
    "chmod u+x build_and_push.sh\n",
    "./build_and_push.sh $artifactname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: rnn-forecast009-2018-07-26-23-33-55-313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "\u001b[31m/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mTraining path:  /opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mInput file(s):  ['prices-split-adjusted.csv', 'stockprices.csv', 'Combined_News_DJIA.csv']\u001b[0m\n",
      "\u001b[31mStarting the training.\u001b[0m\n",
      "\u001b[31mRescaling  STOCKA\u001b[0m\n",
      "\u001b[31mRescaling  open\u001b[0m\n",
      "\u001b[31mRescaling  low\u001b[0m\n",
      "\u001b[31mRescaling  high\u001b[0m\n",
      "\u001b[31mRescaling  volume\u001b[0m\n",
      "\u001b[31mRescaling  adjclose\u001b[0m\n",
      "\u001b[31mRescaling  STOCKB\u001b[0m\n",
      "\u001b[31m/opt/program/train:181: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[31mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[31mTry using .loc[row_indexer,col_indexer] = value instead\n",
      "\u001b[0m\n",
      "\u001b[31mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  train_exo1[\"s\"] = news.s\u001b[0m\n",
      "\u001b[31m/opt/program/train:182: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[31mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
      "\u001b[31mTry using .loc[row_indexer,col_indexer] = value instead\n",
      "\u001b[0m\n",
      "\u001b[31mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  train_exo1[\"adjclose\"] = train_exo1.close\u001b[0m\n",
      "\u001b[31m/opt/program/train:183: SettingWithCopyWarning: \u001b[0m\n",
      "\u001b[31mA value is trying to be set on a copy of a slice from a DataFrame\n",
      "\u001b[0m\n",
      "\u001b[31mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  train_exo1.drop(['close','symbol'], 1, inplace=True)\u001b[0m\n",
      "\u001b[31mRescaling  open\u001b[0m\n",
      "\u001b[31mRescaling  low\u001b[0m\n",
      "\u001b[31mRescaling  high\u001b[0m\n",
      "\u001b[31mRescaling  volume\u001b[0m\n",
      "\u001b[31mRescaling  s\u001b[0m\n",
      "\u001b[31mRescaling  adjclose\u001b[0m\n",
      "\u001b[31mNumber of horizons (train + test):  1730\u001b[0m\n",
      "\u001b[31mNumber of horizons (train + test):  1730\u001b[0m\n",
      "\u001b[31mEpoch 1/100\u001b[0m\n",
      "\u001b[31m2018-07-26 23:36:40.017670: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 38s - loss: 0.6803 - main_out_loss: 0.6782 - combo_out_loss: 0.6887\n",
      "  96/1557 [>.............................] - ETA: 13s - loss: 0.6495 - main_out_loss: 0.6485 - combo_out_loss: 0.6536\n",
      " 160/1557 [==>...........................] - ETA: 8s - loss: 0.6524 - main_out_loss: 0.6515 - combo_out_loss: 0.6556 \n",
      " 224/1557 [===>..........................] - ETA: 6s - loss: 0.6621 - main_out_loss: 0.6618 - combo_out_loss: 0.6634\n",
      " 288/1557 [====>.........................] - ETA: 4s - loss: 0.6588 - main_out_loss: 0.6586 - combo_out_loss: 0.6597\n",
      " 352/1557 [=====>........................] - ETA: 4s - loss: 0.6608 - main_out_loss: 0.6608 - combo_out_loss: 0.6609\n",
      " 416/1557 [=======>......................] - ETA: 3s - loss: 0.6622 - main_out_loss: 0.6620 - combo_out_loss: 0.6627\n",
      " 480/1557 [========>.....................] - ETA: 3s - loss: 0.6721 - main_out_loss: 0.6720 - combo_out_loss: 0.6726\n",
      " 544/1557 [=========>....................] - ETA: 2s - loss: 0.6693 - main_out_loss: 0.6693 - combo_out_loss: 0.6695\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 2s - loss: 0.6685 - main_out_loss: 0.6685 - combo_out_loss: 0.6686\n",
      " 672/1557 [===========>..................] - ETA: 2s - loss: 0.6672 - main_out_loss: 0.6673 - combo_out_loss: 0.6672\n",
      " 736/1557 [=============>................] - ETA: 1s - loss: 0.6665 - main_out_loss: 0.6666 - combo_out_loss: 0.6663\n",
      " 800/1557 [==============>...............] - ETA: 1s - loss: 0.6676 - main_out_loss: 0.6675 - combo_out_loss: 0.6678\n",
      " 864/1557 [===============>..............] - ETA: 1s - loss: 0.6687 - main_out_loss: 0.6686 - combo_out_loss: 0.6688\n",
      " 928/1557 [================>.............] - ETA: 1s - loss: 0.6669 - main_out_loss: 0.6669 - combo_out_loss: 0.6670\n",
      " 992/1557 [==================>...........] - ETA: 1s - loss: 0.6666 - main_out_loss: 0.6665 - combo_out_loss: 0.6669\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6662 - main_out_loss: 0.6661 - combo_out_loss: 0.6666\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6656 - main_out_loss: 0.6656 - combo_out_loss: 0.6660\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6670 - main_out_loss: 0.6669 - combo_out_loss: 0.6675\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6652 - main_out_loss: 0.6650 - combo_out_loss: 0.6657\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6657 - main_out_loss: 0.6656 - combo_out_loss: 0.6662\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6685 - main_out_loss: 0.6684 - combo_out_loss: 0.6690\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6668 - main_out_loss: 0.6666 - combo_out_loss: 0.6673\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6668 - main_out_loss: 0.6666 - combo_out_loss: 0.6672\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 3s 2ms/step - loss: 0.6660 - main_out_loss: 0.6659 - combo_out_loss: 0.6665\u001b[0m\n",
      "\u001b[31mEpoch 2/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6055 - main_out_loss: 0.6053 - combo_out_loss: 0.6061\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6637 - main_out_loss: 0.6637 - combo_out_loss: 0.6636\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6602 - main_out_loss: 0.6606 - combo_out_loss: 0.6588\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6527 - main_out_loss: 0.6532 - combo_out_loss: 0.6507\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6594 - main_out_loss: 0.6599 - combo_out_loss: 0.6578\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6607 - main_out_loss: 0.6610 - combo_out_loss: 0.6594\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6702 - main_out_loss: 0.6706 - combo_out_loss: 0.6687\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6649 - main_out_loss: 0.6653 - combo_out_loss: 0.6632\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6614 - main_out_loss: 0.6617 - combo_out_loss: 0.6603\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6604 - main_out_loss: 0.6607 - combo_out_loss: 0.6592\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6586 - main_out_loss: 0.6589 - combo_out_loss: 0.6574\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 0s - loss: 0.6584 - main_out_loss: 0.6586 - combo_out_loss: 0.6573\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6622 - main_out_loss: 0.6625 - combo_out_loss: 0.6613\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6683 - main_out_loss: 0.6685 - combo_out_loss: 0.6672\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6682 - main_out_loss: 0.6685 - combo_out_loss: 0.6671\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6670 - main_out_loss: 0.6673 - combo_out_loss: 0.6658\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6666 - main_out_loss: 0.6668 - combo_out_loss: 0.6657\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6675 - main_out_loss: 0.6677 - combo_out_loss: 0.6667\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6658 - main_out_loss: 0.6660 - combo_out_loss: 0.6649\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6637 - main_out_loss: 0.6639 - combo_out_loss: 0.6629\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6613 - main_out_loss: 0.6615 - combo_out_loss: 0.6605\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6623 - main_out_loss: 0.6625 - combo_out_loss: 0.6615\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6625 - main_out_loss: 0.6627 - combo_out_loss: 0.6617\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6636 - main_out_loss: 0.6638 - combo_out_loss: 0.6627\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6646 - main_out_loss: 0.6648 - combo_out_loss: 0.6637\u001b[0m\n",
      "\u001b[31mEpoch 3/100\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.7379 - main_out_loss: 0.7380 - combo_out_loss: 0.7375\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6368 - main_out_loss: 0.6373 - combo_out_loss: 0.6348\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6549 - main_out_loss: 0.6553 - combo_out_loss: 0.6536\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6527 - main_out_loss: 0.6529 - combo_out_loss: 0.6515\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6451 - main_out_loss: 0.6454 - combo_out_loss: 0.6439\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6515 - main_out_loss: 0.6520 - combo_out_loss: 0.6494\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6505 - main_out_loss: 0.6511 - combo_out_loss: 0.6482\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6532 - main_out_loss: 0.6537 - combo_out_loss: 0.6513\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6575 - main_out_loss: 0.6580 - combo_out_loss: 0.6558\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6568 - main_out_loss: 0.6572 - combo_out_loss: 0.6550\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6565 - main_out_loss: 0.6569 - combo_out_loss: 0.6549\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6551 - main_out_loss: 0.6555 - combo_out_loss: 0.6536\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.6537 - main_out_loss: 0.6541 - combo_out_loss: 0.6521\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6605 - main_out_loss: 0.6609 - combo_out_loss: 0.6591\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6619 - main_out_loss: 0.6623 - combo_out_loss: 0.6604\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6627 - main_out_loss: 0.6631 - combo_out_loss: 0.6612\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6609 - main_out_loss: 0.6613 - combo_out_loss: 0.6592\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6615 - main_out_loss: 0.6619 - combo_out_loss: 0.6600\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6616 - main_out_loss: 0.6619 - combo_out_loss: 0.6602\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6610 - main_out_loss: 0.6614 - combo_out_loss: 0.6597\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6633 - main_out_loss: 0.6636 - combo_out_loss: 0.6621\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6671 - main_out_loss: 0.6674 - combo_out_loss: 0.6659\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6659 - main_out_loss: 0.6661 - combo_out_loss: 0.6647\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6659 - main_out_loss: 0.6662 - combo_out_loss: 0.6649\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6637 - main_out_loss: 0.6640 - combo_out_loss: 0.6628\u001b[0m\n",
      "\u001b[31mEpoch 4/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6827 - main_out_loss: 0.6837 - combo_out_loss: 0.6786\u001b[0m\n",
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.6967 - main_out_loss: 0.6973 - combo_out_loss: 0.6943\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6811 - main_out_loss: 0.6815 - combo_out_loss: 0.6796\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.7011 - main_out_loss: 0.7015 - combo_out_loss: 0.6995\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6869 - main_out_loss: 0.6872 - combo_out_loss: 0.6857\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6824 - main_out_loss: 0.6829 - combo_out_loss: 0.6806\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6822 - main_out_loss: 0.6826 - combo_out_loss: 0.6806\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6759 - main_out_loss: 0.6763 - combo_out_loss: 0.6745\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6812 - main_out_loss: 0.6815 - combo_out_loss: 0.6798\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6816 - main_out_loss: 0.6821 - combo_out_loss: 0.6800\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6801 - main_out_loss: 0.6805 - combo_out_loss: 0.6785\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6759 - main_out_loss: 0.6763 - combo_out_loss: 0.6745\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6737 - main_out_loss: 0.6740 - combo_out_loss: 0.6724\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6745 - main_out_loss: 0.6748 - combo_out_loss: 0.6733\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.6760 - main_out_loss: 0.6762 - combo_out_loss: 0.6752\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6747 - main_out_loss: 0.6749 - combo_out_loss: 0.6740\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6718 - main_out_loss: 0.6719 - combo_out_loss: 0.6711\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6709 - main_out_loss: 0.6711 - combo_out_loss: 0.6699\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6714 - main_out_loss: 0.6716 - combo_out_loss: 0.6705\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6661 - main_out_loss: 0.6664 - combo_out_loss: 0.6653\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6664 - main_out_loss: 0.6665 - combo_out_loss: 0.6656\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6645 - main_out_loss: 0.6647 - combo_out_loss: 0.6639\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6635 - main_out_loss: 0.6637 - combo_out_loss: 0.6627\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6635 - main_out_loss: 0.6637 - combo_out_loss: 0.6628\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6630 - main_out_loss: 0.6631 - combo_out_loss: 0.6623\u001b[0m\n",
      "\u001b[31mEpoch 5/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 2s - loss: 0.6405 - main_out_loss: 0.6407 - combo_out_loss: 0.6397\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6582 - main_out_loss: 0.6577 - combo_out_loss: 0.6602\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6427 - main_out_loss: 0.6425 - combo_out_loss: 0.6435\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.6314 - main_out_loss: 0.6313 - combo_out_loss: 0.6319\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6265 - main_out_loss: 0.6263 - combo_out_loss: 0.6271\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6488 - main_out_loss: 0.6488 - combo_out_loss: 0.6485\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6437 - main_out_loss: 0.6438 - combo_out_loss: 0.6436\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6426 - main_out_loss: 0.6428 - combo_out_loss: 0.6419\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6486 - main_out_loss: 0.6489 - combo_out_loss: 0.6478\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6514 - main_out_loss: 0.6518 - combo_out_loss: 0.6499\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6517 - main_out_loss: 0.6521 - combo_out_loss: 0.6499\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6534 - main_out_loss: 0.6539 - combo_out_loss: 0.6515\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6543 - main_out_loss: 0.6548 - combo_out_loss: 0.6526\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6531 - main_out_loss: 0.6536 - combo_out_loss: 0.6514\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6550 - main_out_loss: 0.6554 - combo_out_loss: 0.6534\u001b[0m\n",
      "\u001b[31m 992/1557 [==================>...........] - ETA: 0s - loss: 0.6596 - main_out_loss: 0.6601 - combo_out_loss: 0.6580\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6603 - main_out_loss: 0.6607 - combo_out_loss: 0.6585\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6621 - main_out_loss: 0.6625 - combo_out_loss: 0.6604\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6608 - main_out_loss: 0.6612 - combo_out_loss: 0.6590\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6612 - main_out_loss: 0.6617 - combo_out_loss: 0.6595\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6599 - main_out_loss: 0.6604 - combo_out_loss: 0.6582\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6630 - main_out_loss: 0.6634 - combo_out_loss: 0.6612\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6607 - main_out_loss: 0.6611 - combo_out_loss: 0.6588\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6602 - main_out_loss: 0.6607 - combo_out_loss: 0.6585\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6624 - main_out_loss: 0.6629 - combo_out_loss: 0.6608\u001b[0m\n",
      "\u001b[31mEpoch 6/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6798 - main_out_loss: 0.6798 - combo_out_loss: 0.6796\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6809 - main_out_loss: 0.6813 - combo_out_loss: 0.6795\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6481 - main_out_loss: 0.6484 - combo_out_loss: 0.6470\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6502 - main_out_loss: 0.6507 - combo_out_loss: 0.6481\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.6660 - main_out_loss: 0.6668 - combo_out_loss: 0.6631\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6702 - main_out_loss: 0.6711 - combo_out_loss: 0.6670\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6648 - main_out_loss: 0.6656 - combo_out_loss: 0.6618\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6627 - main_out_loss: 0.6633 - combo_out_loss: 0.6605\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6665 - main_out_loss: 0.6670 - combo_out_loss: 0.6643\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6688 - main_out_loss: 0.6692 - combo_out_loss: 0.6675\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6720 - main_out_loss: 0.6724 - combo_out_loss: 0.6706\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6734 - main_out_loss: 0.6738 - combo_out_loss: 0.6717\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6767 - main_out_loss: 0.6771 - combo_out_loss: 0.6750\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6740 - main_out_loss: 0.6745 - combo_out_loss: 0.6724\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6797 - main_out_loss: 0.6801 - combo_out_loss: 0.6779\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6760 - main_out_loss: 0.6765 - combo_out_loss: 0.6739\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6753 - main_out_loss: 0.6758 - combo_out_loss: 0.6732\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6726 - main_out_loss: 0.6732 - combo_out_loss: 0.6705\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6737 - main_out_loss: 0.6743 - combo_out_loss: 0.6714\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6724 - main_out_loss: 0.6729 - combo_out_loss: 0.6702\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6689 - main_out_loss: 0.6694 - combo_out_loss: 0.6669\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6652 - main_out_loss: 0.6657 - combo_out_loss: 0.6632\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6617 - main_out_loss: 0.6622 - combo_out_loss: 0.6600\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6608 - main_out_loss: 0.6612 - combo_out_loss: 0.6592\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6624 - main_out_loss: 0.6628 - combo_out_loss: 0.6606\u001b[0m\n",
      "\u001b[31mEpoch 7/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.7795 - main_out_loss: 0.7787 - combo_out_loss: 0.7829\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6796 - main_out_loss: 0.6790 - combo_out_loss: 0.6822\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6530 - main_out_loss: 0.6530 - combo_out_loss: 0.6531\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6519 - main_out_loss: 0.6520 - combo_out_loss: 0.6518\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6656 - main_out_loss: 0.6660 - combo_out_loss: 0.6642\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6653 - main_out_loss: 0.6659 - combo_out_loss: 0.6628\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.6674 - main_out_loss: 0.6681 - combo_out_loss: 0.6647\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6646 - main_out_loss: 0.6653 - combo_out_loss: 0.6618\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6643 - main_out_loss: 0.6650 - combo_out_loss: 0.6615\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6618 - main_out_loss: 0.6623 - combo_out_loss: 0.6594\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6591 - main_out_loss: 0.6597 - combo_out_loss: 0.6566\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6641 - main_out_loss: 0.6647 - combo_out_loss: 0.6613\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6633 - main_out_loss: 0.6639 - combo_out_loss: 0.6607\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6663 - main_out_loss: 0.6669 - combo_out_loss: 0.6636\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6673 - main_out_loss: 0.6680 - combo_out_loss: 0.6642\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6695 - main_out_loss: 0.6702 - combo_out_loss: 0.6664\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6670 - main_out_loss: 0.6678 - combo_out_loss: 0.6637\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6655 - main_out_loss: 0.6663 - combo_out_loss: 0.6622\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6649 - main_out_loss: 0.6657 - combo_out_loss: 0.6615\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6614 - main_out_loss: 0.6622 - combo_out_loss: 0.6582\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6622 - main_out_loss: 0.6631 - combo_out_loss: 0.6589\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6627 - main_out_loss: 0.6635 - combo_out_loss: 0.6592\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6623 - main_out_loss: 0.6631 - combo_out_loss: 0.6590\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6627 - main_out_loss: 0.6635 - combo_out_loss: 0.6594\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6616 - main_out_loss: 0.6624 - combo_out_loss: 0.6584\u001b[0m\n",
      "\u001b[31mEpoch 8/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.7110 - main_out_loss: 0.7109 - combo_out_loss: 0.7116\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6516 - main_out_loss: 0.6525 - combo_out_loss: 0.6483\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6722 - main_out_loss: 0.6733 - combo_out_loss: 0.6678\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6506 - main_out_loss: 0.6517 - combo_out_loss: 0.6459\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6501 - main_out_loss: 0.6515 - combo_out_loss: 0.6448\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6504 - main_out_loss: 0.6520 - combo_out_loss: 0.6440\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6481 - main_out_loss: 0.6496 - combo_out_loss: 0.6423\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6524 - main_out_loss: 0.6537 - combo_out_loss: 0.6474\u001b[0m\n",
      "\u001b[31m 544/1557 [=========>....................] - ETA: 1s - loss: 0.6546 - main_out_loss: 0.6559 - combo_out_loss: 0.6492\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6573 - main_out_loss: 0.6587 - combo_out_loss: 0.6520\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6584 - main_out_loss: 0.6598 - combo_out_loss: 0.6527\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6558 - main_out_loss: 0.6572 - combo_out_loss: 0.6501\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6562 - main_out_loss: 0.6576 - combo_out_loss: 0.6508\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6619 - main_out_loss: 0.6633 - combo_out_loss: 0.6562\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6596 - main_out_loss: 0.6610 - combo_out_loss: 0.6540\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6610 - main_out_loss: 0.6623 - combo_out_loss: 0.6555\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6629 - main_out_loss: 0.6643 - combo_out_loss: 0.6574\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6657 - main_out_loss: 0.6670 - combo_out_loss: 0.6604\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6647 - main_out_loss: 0.6660 - combo_out_loss: 0.6596\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6653 - main_out_loss: 0.6665 - combo_out_loss: 0.6603\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6656 - main_out_loss: 0.6668 - combo_out_loss: 0.6608\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6651 - main_out_loss: 0.6663 - combo_out_loss: 0.6603\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6628 - main_out_loss: 0.6640 - combo_out_loss: 0.6580\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6606 - main_out_loss: 0.6618 - combo_out_loss: 0.6557\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6610 - main_out_loss: 0.6621 - combo_out_loss: 0.6562\u001b[0m\n",
      "\u001b[31mEpoch 9/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6837 - main_out_loss: 0.6852 - combo_out_loss: 0.6780\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6498 - main_out_loss: 0.6514 - combo_out_loss: 0.6432\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6573 - main_out_loss: 0.6585 - combo_out_loss: 0.6526\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6652 - main_out_loss: 0.6665 - combo_out_loss: 0.6600\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6545 - main_out_loss: 0.6560 - combo_out_loss: 0.6487\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6715 - main_out_loss: 0.6728 - combo_out_loss: 0.6661\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6634 - main_out_loss: 0.6648 - combo_out_loss: 0.6582\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6568 - main_out_loss: 0.6583 - combo_out_loss: 0.6508\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6575 - main_out_loss: 0.6589 - combo_out_loss: 0.6515\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.6568 - main_out_loss: 0.6582 - combo_out_loss: 0.6513\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6516 - main_out_loss: 0.6529 - combo_out_loss: 0.6461\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6600 - main_out_loss: 0.6614 - combo_out_loss: 0.6546\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6568 - main_out_loss: 0.6582 - combo_out_loss: 0.6513\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6593 - main_out_loss: 0.6607 - combo_out_loss: 0.6535\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6618 - main_out_loss: 0.6632 - combo_out_loss: 0.6562\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6618 - main_out_loss: 0.6633 - combo_out_loss: 0.6559\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6621 - main_out_loss: 0.6637 - combo_out_loss: 0.6557\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6616 - main_out_loss: 0.6632 - combo_out_loss: 0.6554\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6593 - main_out_loss: 0.6608 - combo_out_loss: 0.6531\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6609 - main_out_loss: 0.6625 - combo_out_loss: 0.6544\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6612 - main_out_loss: 0.6628 - combo_out_loss: 0.6547\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6594 - main_out_loss: 0.6611 - combo_out_loss: 0.6528\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6592 - main_out_loss: 0.6609 - combo_out_loss: 0.6523\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6619 - main_out_loss: 0.6636 - combo_out_loss: 0.6548\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6610 - main_out_loss: 0.6628 - combo_out_loss: 0.6539\u001b[0m\n",
      "\u001b[31mEpoch 10/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5793 - main_out_loss: 0.5787 - combo_out_loss: 0.5817\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6133 - main_out_loss: 0.6144 - combo_out_loss: 0.6091\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6311 - main_out_loss: 0.6332 - combo_out_loss: 0.6229\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6459 - main_out_loss: 0.6483 - combo_out_loss: 0.6363\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6533 - main_out_loss: 0.6554 - combo_out_loss: 0.6449\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6494 - main_out_loss: 0.6515 - combo_out_loss: 0.6407\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6483 - main_out_loss: 0.6504 - combo_out_loss: 0.6399\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6487 - main_out_loss: 0.6507 - combo_out_loss: 0.6408\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6441 - main_out_loss: 0.6461 - combo_out_loss: 0.6361\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6463 - main_out_loss: 0.6483 - combo_out_loss: 0.6382\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6487 - main_out_loss: 0.6510 - combo_out_loss: 0.6396\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 1s - loss: 0.6542 - main_out_loss: 0.6566 - combo_out_loss: 0.6447\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6512 - main_out_loss: 0.6533 - combo_out_loss: 0.6426\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6539 - main_out_loss: 0.6560 - combo_out_loss: 0.6458\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6564 - main_out_loss: 0.6585 - combo_out_loss: 0.6481\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6606 - main_out_loss: 0.6625 - combo_out_loss: 0.6528\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6591 - main_out_loss: 0.6610 - combo_out_loss: 0.6518\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6569 - main_out_loss: 0.6588 - combo_out_loss: 0.6496\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6599 - main_out_loss: 0.6617 - combo_out_loss: 0.6529\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6586 - main_out_loss: 0.6604 - combo_out_loss: 0.6513\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6566 - main_out_loss: 0.6585 - combo_out_loss: 0.6492\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6598 - main_out_loss: 0.6616 - combo_out_loss: 0.6522\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6614 - main_out_loss: 0.6633 - combo_out_loss: 0.6537\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6612 - main_out_loss: 0.6631 - combo_out_loss: 0.6536\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6596 - main_out_loss: 0.6615 - combo_out_loss: 0.6520\u001b[0m\n",
      "\u001b[31mEpoch 11/100\n",
      "\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.5711 - main_out_loss: 0.5745 - combo_out_loss: 0.5574\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6379 - main_out_loss: 0.6418 - combo_out_loss: 0.6223\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6717 - main_out_loss: 0.6748 - combo_out_loss: 0.6594\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6609 - main_out_loss: 0.6633 - combo_out_loss: 0.6512\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6563 - main_out_loss: 0.6587 - combo_out_loss: 0.6466\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6530 - main_out_loss: 0.6554 - combo_out_loss: 0.6431\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6465 - main_out_loss: 0.6489 - combo_out_loss: 0.6369\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6481 - main_out_loss: 0.6505 - combo_out_loss: 0.6384\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6407 - main_out_loss: 0.6431 - combo_out_loss: 0.6308\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6403 - main_out_loss: 0.6428 - combo_out_loss: 0.6306\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6423 - main_out_loss: 0.6447 - combo_out_loss: 0.6324\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6414 - main_out_loss: 0.6438 - combo_out_loss: 0.6322\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6447 - main_out_loss: 0.6470 - combo_out_loss: 0.6355\u001b[0m\n",
      "\u001b[31m 864/1557 [===============>..............] - ETA: 0s - loss: 0.6492 - main_out_loss: 0.6515 - combo_out_loss: 0.6402\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6485 - main_out_loss: 0.6506 - combo_out_loss: 0.6398\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6513 - main_out_loss: 0.6534 - combo_out_loss: 0.6431\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6516 - main_out_loss: 0.6538 - combo_out_loss: 0.6429\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6527 - main_out_loss: 0.6549 - combo_out_loss: 0.6439\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6550 - main_out_loss: 0.6572 - combo_out_loss: 0.6459\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6560 - main_out_loss: 0.6582 - combo_out_loss: 0.6469\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6583 - main_out_loss: 0.6606 - combo_out_loss: 0.6492\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6620 - main_out_loss: 0.6644 - combo_out_loss: 0.6527\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6614 - main_out_loss: 0.6637 - combo_out_loss: 0.6521\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6601 - main_out_loss: 0.6624 - combo_out_loss: 0.6507\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6589 - main_out_loss: 0.6612 - combo_out_loss: 0.6495\u001b[0m\n",
      "\u001b[31mEpoch 12/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.7313 - main_out_loss: 0.7348 - combo_out_loss: 0.7169\u001b[0m\n",
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.7117 - main_out_loss: 0.7145 - combo_out_loss: 0.7008\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6914 - main_out_loss: 0.6939 - combo_out_loss: 0.6811\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6725 - main_out_loss: 0.6753 - combo_out_loss: 0.6614\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6733 - main_out_loss: 0.6758 - combo_out_loss: 0.6631\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6661 - main_out_loss: 0.6690 - combo_out_loss: 0.6544\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6665 - main_out_loss: 0.6695 - combo_out_loss: 0.6544\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6575 - main_out_loss: 0.6604 - combo_out_loss: 0.6458\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6549 - main_out_loss: 0.6578 - combo_out_loss: 0.6430\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6564 - main_out_loss: 0.6593 - combo_out_loss: 0.6447\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6613 - main_out_loss: 0.6642 - combo_out_loss: 0.6497\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6564 - main_out_loss: 0.6591 - combo_out_loss: 0.6453\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6512 - main_out_loss: 0.6540 - combo_out_loss: 0.6398\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6545 - main_out_loss: 0.6574 - combo_out_loss: 0.6428\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.6570 - main_out_loss: 0.6598 - combo_out_loss: 0.6457\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6568 - main_out_loss: 0.6597 - combo_out_loss: 0.6453\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6576 - main_out_loss: 0.6605 - combo_out_loss: 0.6461\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6579 - main_out_loss: 0.6607 - combo_out_loss: 0.6464\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6569 - main_out_loss: 0.6598 - combo_out_loss: 0.6455\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6600 - main_out_loss: 0.6628 - combo_out_loss: 0.6486\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6599 - main_out_loss: 0.6628 - combo_out_loss: 0.6484\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6564 - main_out_loss: 0.6591 - combo_out_loss: 0.6454\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6568 - main_out_loss: 0.6597 - combo_out_loss: 0.6455\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6571 - main_out_loss: 0.6600 - combo_out_loss: 0.6458\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6568 - main_out_loss: 0.6596 - combo_out_loss: 0.6452\u001b[0m\n",
      "\u001b[31mEpoch 13/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6914 - main_out_loss: 0.6947 - combo_out_loss: 0.6781\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6597 - main_out_loss: 0.6632 - combo_out_loss: 0.6455\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6587 - main_out_loss: 0.6626 - combo_out_loss: 0.6434\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.6594 - main_out_loss: 0.6632 - combo_out_loss: 0.6445\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6496 - main_out_loss: 0.6533 - combo_out_loss: 0.6349\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6414 - main_out_loss: 0.6448 - combo_out_loss: 0.6279\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6422 - main_out_loss: 0.6460 - combo_out_loss: 0.6270\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6461 - main_out_loss: 0.6497 - combo_out_loss: 0.6319\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6414 - main_out_loss: 0.6448 - combo_out_loss: 0.6277\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6385 - main_out_loss: 0.6421 - combo_out_loss: 0.6242\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6382 - main_out_loss: 0.6417 - combo_out_loss: 0.6240\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6396 - main_out_loss: 0.6431 - combo_out_loss: 0.6259\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6385 - main_out_loss: 0.6418 - combo_out_loss: 0.6252\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6349 - main_out_loss: 0.6383 - combo_out_loss: 0.6213\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6364 - main_out_loss: 0.6399 - combo_out_loss: 0.6226\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6381 - main_out_loss: 0.6417 - combo_out_loss: 0.6236\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6399 - main_out_loss: 0.6436 - combo_out_loss: 0.6252\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6468 - main_out_loss: 0.6504 - combo_out_loss: 0.6324\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6495 - main_out_loss: 0.6531 - combo_out_loss: 0.6352\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6542 - main_out_loss: 0.6577 - combo_out_loss: 0.6402\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6546 - main_out_loss: 0.6580 - combo_out_loss: 0.6409\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6513 - main_out_loss: 0.6547 - combo_out_loss: 0.6378\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6534 - main_out_loss: 0.6569 - combo_out_loss: 0.6398\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6552 - main_out_loss: 0.6586 - combo_out_loss: 0.6416\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6543 - main_out_loss: 0.6577 - combo_out_loss: 0.6408\u001b[0m\n",
      "\u001b[31mEpoch 14/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6997 - main_out_loss: 0.7074 - combo_out_loss: 0.6690\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6601 - main_out_loss: 0.6649 - combo_out_loss: 0.6411\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6476 - main_out_loss: 0.6522 - combo_out_loss: 0.6288\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6460 - main_out_loss: 0.6500 - combo_out_loss: 0.6299\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6537 - main_out_loss: 0.6572 - combo_out_loss: 0.6394\u001b[0m\n",
      "\u001b[31m 352/1557 [=====>........................] - ETA: 1s - loss: 0.6427 - main_out_loss: 0.6462 - combo_out_loss: 0.6286\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6413 - main_out_loss: 0.6449 - combo_out_loss: 0.6270\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6394 - main_out_loss: 0.6427 - combo_out_loss: 0.6261\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6563 - main_out_loss: 0.6598 - combo_out_loss: 0.6425\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6606 - main_out_loss: 0.6641 - combo_out_loss: 0.6467\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6525 - main_out_loss: 0.6557 - combo_out_loss: 0.6399\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6522 - main_out_loss: 0.6554 - combo_out_loss: 0.6392\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6548 - main_out_loss: 0.6581 - combo_out_loss: 0.6416\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6515 - main_out_loss: 0.6548 - combo_out_loss: 0.6384\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6552 - main_out_loss: 0.6585 - combo_out_loss: 0.6417\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6511 - main_out_loss: 0.6544 - combo_out_loss: 0.6376\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6491 - main_out_loss: 0.6523 - combo_out_loss: 0.6361\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6509 - main_out_loss: 0.6543 - combo_out_loss: 0.6372\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6531 - main_out_loss: 0.6565 - combo_out_loss: 0.6394\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6522 - main_out_loss: 0.6557 - combo_out_loss: 0.6385\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6503 - main_out_loss: 0.6537 - combo_out_loss: 0.6366\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6522 - main_out_loss: 0.6557 - combo_out_loss: 0.6382\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6548 - main_out_loss: 0.6583 - combo_out_loss: 0.6408\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6536 - main_out_loss: 0.6571 - combo_out_loss: 0.6396\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6530 - main_out_loss: 0.6566 - combo_out_loss: 0.6386\u001b[0m\n",
      "\u001b[31mEpoch 15/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6364 - main_out_loss: 0.6397 - combo_out_loss: 0.6229\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6535 - main_out_loss: 0.6575 - combo_out_loss: 0.6375\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6460 - main_out_loss: 0.6491 - combo_out_loss: 0.6336\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6434 - main_out_loss: 0.6468 - combo_out_loss: 0.6298\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6488 - main_out_loss: 0.6530 - combo_out_loss: 0.6320\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6497 - main_out_loss: 0.6539 - combo_out_loss: 0.6328\u001b[0m\n",
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.6541 - main_out_loss: 0.6582 - combo_out_loss: 0.6381\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6519 - main_out_loss: 0.6559 - combo_out_loss: 0.6358\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6557 - main_out_loss: 0.6598 - combo_out_loss: 0.6391\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6514 - main_out_loss: 0.6556 - combo_out_loss: 0.6345\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6545 - main_out_loss: 0.6585 - combo_out_loss: 0.6383\n",
      " 736/1557 [=============>................] - ETA: 1s - loss: 0.6587 - main_out_loss: 0.6630 - combo_out_loss: 0.6417\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6602 - main_out_loss: 0.6645 - combo_out_loss: 0.6430\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6652 - main_out_loss: 0.6695 - combo_out_loss: 0.6482\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6656 - main_out_loss: 0.6699 - combo_out_loss: 0.6485\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6638 - main_out_loss: 0.6681 - combo_out_loss: 0.6467\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6652 - main_out_loss: 0.6694 - combo_out_loss: 0.6483\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6616 - main_out_loss: 0.6658 - combo_out_loss: 0.6450\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6591 - main_out_loss: 0.6633 - combo_out_loss: 0.6426\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6579 - main_out_loss: 0.6619 - combo_out_loss: 0.6417\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6533 - main_out_loss: 0.6574 - combo_out_loss: 0.6369\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6570 - main_out_loss: 0.6613 - combo_out_loss: 0.6400\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6551 - main_out_loss: 0.6594 - combo_out_loss: 0.6382\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6526 - main_out_loss: 0.6567 - combo_out_loss: 0.6362\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6510 - main_out_loss: 0.6552 - combo_out_loss: 0.6342\u001b[0m\n",
      "\u001b[31mEpoch 16/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5800 - main_out_loss: 0.5844 - combo_out_loss: 0.5625\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6178 - main_out_loss: 0.6218 - combo_out_loss: 0.6019\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6407 - main_out_loss: 0.6452 - combo_out_loss: 0.6225\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6608 - main_out_loss: 0.6653 - combo_out_loss: 0.6426\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6623 - main_out_loss: 0.6664 - combo_out_loss: 0.6457\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6538 - main_out_loss: 0.6574 - combo_out_loss: 0.6395\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6519 - main_out_loss: 0.6557 - combo_out_loss: 0.6365\u001b[0m\n",
      "\u001b[31m 480/1557 [========>.....................] - ETA: 1s - loss: 0.6472 - main_out_loss: 0.6515 - combo_out_loss: 0.6302\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6449 - main_out_loss: 0.6492 - combo_out_loss: 0.6277\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6435 - main_out_loss: 0.6477 - combo_out_loss: 0.6265\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6444 - main_out_loss: 0.6488 - combo_out_loss: 0.6269\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6494 - main_out_loss: 0.6542 - combo_out_loss: 0.6303\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6476 - main_out_loss: 0.6523 - combo_out_loss: 0.6291\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6444 - main_out_loss: 0.6492 - combo_out_loss: 0.6255\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6433 - main_out_loss: 0.6481 - combo_out_loss: 0.6242\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6488 - main_out_loss: 0.6536 - combo_out_loss: 0.6298\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6448 - main_out_loss: 0.6496 - combo_out_loss: 0.6252\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6450 - main_out_loss: 0.6500 - combo_out_loss: 0.6250\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6477 - main_out_loss: 0.6527 - combo_out_loss: 0.6278\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6469 - main_out_loss: 0.6519 - combo_out_loss: 0.6271\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6482 - main_out_loss: 0.6531 - combo_out_loss: 0.6284\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6471 - main_out_loss: 0.6522 - combo_out_loss: 0.6270\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6465 - main_out_loss: 0.6516 - combo_out_loss: 0.6260\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6474 - main_out_loss: 0.6525 - combo_out_loss: 0.6270\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6479 - main_out_loss: 0.6531 - combo_out_loss: 0.6274\u001b[0m\n",
      "\u001b[31mEpoch 17/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.7130 - main_out_loss: 0.7174 - combo_out_loss: 0.6956\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6506 - main_out_loss: 0.6540 - combo_out_loss: 0.6369\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6470 - main_out_loss: 0.6519 - combo_out_loss: 0.6273\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6444 - main_out_loss: 0.6496 - combo_out_loss: 0.6237\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6513 - main_out_loss: 0.6570 - combo_out_loss: 0.6286\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6488 - main_out_loss: 0.6543 - combo_out_loss: 0.6268\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6494 - main_out_loss: 0.6545 - combo_out_loss: 0.6291\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6425 - main_out_loss: 0.6478 - combo_out_loss: 0.6210\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6470 - main_out_loss: 0.6527 - combo_out_loss: 0.6240\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.6533 - main_out_loss: 0.6590 - combo_out_loss: 0.6302\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6513 - main_out_loss: 0.6570 - combo_out_loss: 0.6284\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6546 - main_out_loss: 0.6601 - combo_out_loss: 0.6327\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6536 - main_out_loss: 0.6592 - combo_out_loss: 0.6315\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6532 - main_out_loss: 0.6588 - combo_out_loss: 0.6310\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6548 - main_out_loss: 0.6602 - combo_out_loss: 0.6330\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6519 - main_out_loss: 0.6572 - combo_out_loss: 0.6307\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6558 - main_out_loss: 0.6610 - combo_out_loss: 0.6347\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6545 - main_out_loss: 0.6597 - combo_out_loss: 0.6334\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6504 - main_out_loss: 0.6557 - combo_out_loss: 0.6291\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6511 - main_out_loss: 0.6563 - combo_out_loss: 0.6300\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6518 - main_out_loss: 0.6570 - combo_out_loss: 0.6307\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6481 - main_out_loss: 0.6534 - combo_out_loss: 0.6271\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6466 - main_out_loss: 0.6520 - combo_out_loss: 0.6250\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6464 - main_out_loss: 0.6519 - combo_out_loss: 0.6243\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6453 - main_out_loss: 0.6508 - combo_out_loss: 0.6234\u001b[0m\n",
      "\u001b[31mEpoch 18/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6110 - main_out_loss: 0.6219 - combo_out_loss: 0.5675\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5727 - main_out_loss: 0.5799 - combo_out_loss: 0.5439\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6104 - main_out_loss: 0.6176 - combo_out_loss: 0.5818\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6035 - main_out_loss: 0.6101 - combo_out_loss: 0.5771\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6283 - main_out_loss: 0.6348 - combo_out_loss: 0.6023\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6363 - main_out_loss: 0.6425 - combo_out_loss: 0.6116\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6389 - main_out_loss: 0.6449 - combo_out_loss: 0.6148\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6485 - main_out_loss: 0.6546 - combo_out_loss: 0.6240\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6447 - main_out_loss: 0.6507 - combo_out_loss: 0.6206\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6478 - main_out_loss: 0.6539 - combo_out_loss: 0.6235\u001b[0m\n",
      "\u001b[31m 672/1557 [===========>..................] - ETA: 1s - loss: 0.6457 - main_out_loss: 0.6517 - combo_out_loss: 0.6221\n",
      " 736/1557 [=============>................] - ETA: 1s - loss: 0.6429 - main_out_loss: 0.6489 - combo_out_loss: 0.6191\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6486 - main_out_loss: 0.6542 - combo_out_loss: 0.6263\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6548 - main_out_loss: 0.6604 - combo_out_loss: 0.6324\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6538 - main_out_loss: 0.6594 - combo_out_loss: 0.6314\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6513 - main_out_loss: 0.6568 - combo_out_loss: 0.6297\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6499 - main_out_loss: 0.6555 - combo_out_loss: 0.6273\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6474 - main_out_loss: 0.6530 - combo_out_loss: 0.6250\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6472 - main_out_loss: 0.6530 - combo_out_loss: 0.6243\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6464 - main_out_loss: 0.6522 - combo_out_loss: 0.6230\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6451 - main_out_loss: 0.6511 - combo_out_loss: 0.6209\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6439 - main_out_loss: 0.6501 - combo_out_loss: 0.6192\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6407 - main_out_loss: 0.6468 - combo_out_loss: 0.6160\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6430 - main_out_loss: 0.6491 - combo_out_loss: 0.6183\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6406 - main_out_loss: 0.6467 - combo_out_loss: 0.6159\u001b[0m\n",
      "\u001b[31mEpoch 19/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5969 - main_out_loss: 0.6082 - combo_out_loss: 0.5518\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6046 - main_out_loss: 0.6101 - combo_out_loss: 0.5827\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6259 - main_out_loss: 0.6314 - combo_out_loss: 0.6040\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6261 - main_out_loss: 0.6310 - combo_out_loss: 0.6066\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6471 - main_out_loss: 0.6507 - combo_out_loss: 0.6325\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6469 - main_out_loss: 0.6509 - combo_out_loss: 0.6309\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6427 - main_out_loss: 0.6473 - combo_out_loss: 0.6240\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6401 - main_out_loss: 0.6453 - combo_out_loss: 0.6191\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6430 - main_out_loss: 0.6483 - combo_out_loss: 0.6218\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6464 - main_out_loss: 0.6517 - combo_out_loss: 0.6251\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6446 - main_out_loss: 0.6503 - combo_out_loss: 0.6219\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6471 - main_out_loss: 0.6528 - combo_out_loss: 0.6245\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.6463 - main_out_loss: 0.6521 - combo_out_loss: 0.6231\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6473 - main_out_loss: 0.6531 - combo_out_loss: 0.6241\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6435 - main_out_loss: 0.6493 - combo_out_loss: 0.6203\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6459 - main_out_loss: 0.6516 - combo_out_loss: 0.6232\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6450 - main_out_loss: 0.6506 - combo_out_loss: 0.6224\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6468 - main_out_loss: 0.6524 - combo_out_loss: 0.6244\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6423 - main_out_loss: 0.6477 - combo_out_loss: 0.6203\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6411 - main_out_loss: 0.6468 - combo_out_loss: 0.6185\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6410 - main_out_loss: 0.6466 - combo_out_loss: 0.6186\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6404 - main_out_loss: 0.6461 - combo_out_loss: 0.6178\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6397 - main_out_loss: 0.6454 - combo_out_loss: 0.6168\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6386 - main_out_loss: 0.6443 - combo_out_loss: 0.6160\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6382 - main_out_loss: 0.6438 - combo_out_loss: 0.6161\u001b[0m\n",
      "\u001b[31mEpoch 20/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6251 - main_out_loss: 0.6319 - combo_out_loss: 0.5975\u001b[0m\n",
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.6475 - main_out_loss: 0.6549 - combo_out_loss: 0.6178\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6342 - main_out_loss: 0.6410 - combo_out_loss: 0.6069\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6248 - main_out_loss: 0.6314 - combo_out_loss: 0.5982\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6225 - main_out_loss: 0.6295 - combo_out_loss: 0.5943\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6254 - main_out_loss: 0.6327 - combo_out_loss: 0.5965\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6236 - main_out_loss: 0.6310 - combo_out_loss: 0.5937\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6225 - main_out_loss: 0.6293 - combo_out_loss: 0.5952\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6209 - main_out_loss: 0.6280 - combo_out_loss: 0.5924\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6228 - main_out_loss: 0.6300 - combo_out_loss: 0.5940\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6239 - main_out_loss: 0.6311 - combo_out_loss: 0.5954\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6203 - main_out_loss: 0.6276 - combo_out_loss: 0.5913\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6235 - main_out_loss: 0.6309 - combo_out_loss: 0.5939\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6256 - main_out_loss: 0.6329 - combo_out_loss: 0.5963\u001b[0m\n",
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.6209 - main_out_loss: 0.6281 - combo_out_loss: 0.5923\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6214 - main_out_loss: 0.6285 - combo_out_loss: 0.5928\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6233 - main_out_loss: 0.6303 - combo_out_loss: 0.5951\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6289 - main_out_loss: 0.6358 - combo_out_loss: 0.6012\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6312 - main_out_loss: 0.6381 - combo_out_loss: 0.6036\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6301 - main_out_loss: 0.6369 - combo_out_loss: 0.6027\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6325 - main_out_loss: 0.6393 - combo_out_loss: 0.6052\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6336 - main_out_loss: 0.6406 - combo_out_loss: 0.6055\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6351 - main_out_loss: 0.6421 - combo_out_loss: 0.6072\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6339 - main_out_loss: 0.6409 - combo_out_loss: 0.6060\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6363 - main_out_loss: 0.6435 - combo_out_loss: 0.6074\u001b[0m\n",
      "\u001b[31mEpoch 21/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6327 - main_out_loss: 0.6421 - combo_out_loss: 0.5953\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6223 - main_out_loss: 0.6319 - combo_out_loss: 0.5840\u001b[0m\n",
      "\u001b[31m 160/1557 [==>...........................] - ETA: 1s - loss: 0.5894 - main_out_loss: 0.5986 - combo_out_loss: 0.5526\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6144 - main_out_loss: 0.6230 - combo_out_loss: 0.5797\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6163 - main_out_loss: 0.6251 - combo_out_loss: 0.5809\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6133 - main_out_loss: 0.6217 - combo_out_loss: 0.5797\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6174 - main_out_loss: 0.6257 - combo_out_loss: 0.5839\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6229 - main_out_loss: 0.6316 - combo_out_loss: 0.5878\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6212 - main_out_loss: 0.6294 - combo_out_loss: 0.5882\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6199 - main_out_loss: 0.6280 - combo_out_loss: 0.5874\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6208 - main_out_loss: 0.6291 - combo_out_loss: 0.5879\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6205 - main_out_loss: 0.6288 - combo_out_loss: 0.5876\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6266 - main_out_loss: 0.6348 - combo_out_loss: 0.5937\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6299 - main_out_loss: 0.6381 - combo_out_loss: 0.5972\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6339 - main_out_loss: 0.6421 - combo_out_loss: 0.6009\u001b[0m\n",
      "\u001b[31m 992/1557 [==================>...........] - ETA: 0s - loss: 0.6334 - main_out_loss: 0.6415 - combo_out_loss: 0.6011\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6364 - main_out_loss: 0.6443 - combo_out_loss: 0.6048\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6363 - main_out_loss: 0.6442 - combo_out_loss: 0.6045\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6357 - main_out_loss: 0.6435 - combo_out_loss: 0.6044\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6355 - main_out_loss: 0.6435 - combo_out_loss: 0.6033\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6337 - main_out_loss: 0.6419 - combo_out_loss: 0.6010\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6321 - main_out_loss: 0.6402 - combo_out_loss: 0.5998\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6326 - main_out_loss: 0.6406 - combo_out_loss: 0.6005\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6310 - main_out_loss: 0.6390 - combo_out_loss: 0.5990\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6329 - main_out_loss: 0.6409 - combo_out_loss: 0.6008\u001b[0m\n",
      "\u001b[31mEpoch 22/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6568 - main_out_loss: 0.6664 - combo_out_loss: 0.6183\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6478 - main_out_loss: 0.6571 - combo_out_loss: 0.6110\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6408 - main_out_loss: 0.6513 - combo_out_loss: 0.5986\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6467 - main_out_loss: 0.6572 - combo_out_loss: 0.6044\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.6406 - main_out_loss: 0.6508 - combo_out_loss: 0.6000\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6407 - main_out_loss: 0.6495 - combo_out_loss: 0.6053\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6365 - main_out_loss: 0.6451 - combo_out_loss: 0.6021\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6317 - main_out_loss: 0.6405 - combo_out_loss: 0.5967\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6302 - main_out_loss: 0.6384 - combo_out_loss: 0.5975\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6309 - main_out_loss: 0.6396 - combo_out_loss: 0.5959\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6347 - main_out_loss: 0.6437 - combo_out_loss: 0.5987\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6296 - main_out_loss: 0.6388 - combo_out_loss: 0.5930\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6289 - main_out_loss: 0.6383 - combo_out_loss: 0.5916\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6260 - main_out_loss: 0.6355 - combo_out_loss: 0.5880\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6292 - main_out_loss: 0.6383 - combo_out_loss: 0.5927\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6275 - main_out_loss: 0.6365 - combo_out_loss: 0.5915\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6294 - main_out_loss: 0.6384 - combo_out_loss: 0.5932\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6303 - main_out_loss: 0.6392 - combo_out_loss: 0.5949\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6333 - main_out_loss: 0.6420 - combo_out_loss: 0.5982\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6320 - main_out_loss: 0.6407 - combo_out_loss: 0.5973\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6309 - main_out_loss: 0.6395 - combo_out_loss: 0.5963\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6289 - main_out_loss: 0.6374 - combo_out_loss: 0.5950\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6303 - main_out_loss: 0.6386 - combo_out_loss: 0.5971\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6280 - main_out_loss: 0.6362 - combo_out_loss: 0.5949\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6278 - main_out_loss: 0.6360 - combo_out_loss: 0.5953\u001b[0m\n",
      "\u001b[31mEpoch 23/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6190 - main_out_loss: 0.6273 - combo_out_loss: 0.5860\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6343 - main_out_loss: 0.6473 - combo_out_loss: 0.5820\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6251 - main_out_loss: 0.6361 - combo_out_loss: 0.5814\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6360 - main_out_loss: 0.6461 - combo_out_loss: 0.5954\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6293 - main_out_loss: 0.6390 - combo_out_loss: 0.5905\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6279 - main_out_loss: 0.6375 - combo_out_loss: 0.5894\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.6202 - main_out_loss: 0.6302 - combo_out_loss: 0.5801\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6276 - main_out_loss: 0.6381 - combo_out_loss: 0.5855\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6279 - main_out_loss: 0.6385 - combo_out_loss: 0.5854\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6226 - main_out_loss: 0.6323 - combo_out_loss: 0.5838\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6191 - main_out_loss: 0.6284 - combo_out_loss: 0.5820\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6208 - main_out_loss: 0.6307 - combo_out_loss: 0.5815\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6210 - main_out_loss: 0.6310 - combo_out_loss: 0.5810\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6251 - main_out_loss: 0.6351 - combo_out_loss: 0.5853\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6274 - main_out_loss: 0.6377 - combo_out_loss: 0.5865\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6300 - main_out_loss: 0.6401 - combo_out_loss: 0.5893\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6280 - main_out_loss: 0.6381 - combo_out_loss: 0.5875\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6277 - main_out_loss: 0.6380 - combo_out_loss: 0.5866\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6293 - main_out_loss: 0.6397 - combo_out_loss: 0.5877\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6245 - main_out_loss: 0.6349 - combo_out_loss: 0.5830\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6241 - main_out_loss: 0.6343 - combo_out_loss: 0.5835\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6215 - main_out_loss: 0.6316 - combo_out_loss: 0.5812\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6216 - main_out_loss: 0.6316 - combo_out_loss: 0.5816\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6232 - main_out_loss: 0.6333 - combo_out_loss: 0.5829\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6266 - main_out_loss: 0.6369 - combo_out_loss: 0.5853\u001b[0m\n",
      "\u001b[31mEpoch 24/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6586 - main_out_loss: 0.6732 - combo_out_loss: 0.6000\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6324 - main_out_loss: 0.6456 - combo_out_loss: 0.5793\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6272 - main_out_loss: 0.6386 - combo_out_loss: 0.5816\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6170 - main_out_loss: 0.6279 - combo_out_loss: 0.5736\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6151 - main_out_loss: 0.6264 - combo_out_loss: 0.5700\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6130 - main_out_loss: 0.6235 - combo_out_loss: 0.5708\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6156 - main_out_loss: 0.6262 - combo_out_loss: 0.5734\u001b[0m\n",
      "\u001b[31m 480/1557 [========>.....................] - ETA: 1s - loss: 0.6213 - main_out_loss: 0.6319 - combo_out_loss: 0.5789\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6240 - main_out_loss: 0.6347 - combo_out_loss: 0.5813\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6331 - main_out_loss: 0.6437 - combo_out_loss: 0.5909\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6289 - main_out_loss: 0.6390 - combo_out_loss: 0.5886\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6286 - main_out_loss: 0.6385 - combo_out_loss: 0.5890\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6252 - main_out_loss: 0.6354 - combo_out_loss: 0.5847\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6223 - main_out_loss: 0.6322 - combo_out_loss: 0.5829\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6161 - main_out_loss: 0.6261 - combo_out_loss: 0.5762\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6149 - main_out_loss: 0.6252 - combo_out_loss: 0.5736\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6125 - main_out_loss: 0.6226 - combo_out_loss: 0.5721\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6173 - main_out_loss: 0.6274 - combo_out_loss: 0.5772\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6204 - main_out_loss: 0.6304 - combo_out_loss: 0.5803\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6215 - main_out_loss: 0.6315 - combo_out_loss: 0.5814\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6199 - main_out_loss: 0.6297 - combo_out_loss: 0.5806\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6195 - main_out_loss: 0.6292 - combo_out_loss: 0.5807\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6211 - main_out_loss: 0.6307 - combo_out_loss: 0.5827\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6198 - main_out_loss: 0.6295 - combo_out_loss: 0.5811\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6188 - main_out_loss: 0.6285 - combo_out_loss: 0.5800\u001b[0m\n",
      "\u001b[31mEpoch 25/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6757 - main_out_loss: 0.6879 - combo_out_loss: 0.6269\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6263 - main_out_loss: 0.6387 - combo_out_loss: 0.5766\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6207 - main_out_loss: 0.6321 - combo_out_loss: 0.5754\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6366 - main_out_loss: 0.6483 - combo_out_loss: 0.5896\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6379 - main_out_loss: 0.6500 - combo_out_loss: 0.5897\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6202 - main_out_loss: 0.6318 - combo_out_loss: 0.5740\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6141 - main_out_loss: 0.6255 - combo_out_loss: 0.5683\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6170 - main_out_loss: 0.6279 - combo_out_loss: 0.5732\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6154 - main_out_loss: 0.6262 - combo_out_loss: 0.5722\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.6172 - main_out_loss: 0.6276 - combo_out_loss: 0.5758\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6185 - main_out_loss: 0.6288 - combo_out_loss: 0.5775\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6165 - main_out_loss: 0.6267 - combo_out_loss: 0.5754\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6129 - main_out_loss: 0.6235 - combo_out_loss: 0.5706\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6149 - main_out_loss: 0.6254 - combo_out_loss: 0.5731\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6140 - main_out_loss: 0.6243 - combo_out_loss: 0.5729\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6162 - main_out_loss: 0.6266 - combo_out_loss: 0.5749\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6155 - main_out_loss: 0.6261 - combo_out_loss: 0.5731\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6148 - main_out_loss: 0.6254 - combo_out_loss: 0.5723\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6129 - main_out_loss: 0.6234 - combo_out_loss: 0.5709\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6114 - main_out_loss: 0.6221 - combo_out_loss: 0.5686\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6101 - main_out_loss: 0.6208 - combo_out_loss: 0.5672\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6091 - main_out_loss: 0.6199 - combo_out_loss: 0.5656\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6094 - main_out_loss: 0.6203 - combo_out_loss: 0.5659\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6107 - main_out_loss: 0.6217 - combo_out_loss: 0.5667\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6122 - main_out_loss: 0.6233 - combo_out_loss: 0.5677\u001b[0m\n",
      "\u001b[31mEpoch 26/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6127 - main_out_loss: 0.6251 - combo_out_loss: 0.5630\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6142 - main_out_loss: 0.6234 - combo_out_loss: 0.5777\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6229 - main_out_loss: 0.6353 - combo_out_loss: 0.5732\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6331 - main_out_loss: 0.6460 - combo_out_loss: 0.5819\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.6236 - main_out_loss: 0.6364 - combo_out_loss: 0.5723\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6202 - main_out_loss: 0.6332 - combo_out_loss: 0.5679\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6256 - main_out_loss: 0.6384 - combo_out_loss: 0.5742\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6190 - main_out_loss: 0.6319 - combo_out_loss: 0.5678\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6157 - main_out_loss: 0.6287 - combo_out_loss: 0.5640\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6140 - main_out_loss: 0.6270 - combo_out_loss: 0.5621\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.6105 - main_out_loss: 0.6238 - combo_out_loss: 0.5574\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 0s - loss: 0.6107 - main_out_loss: 0.6238 - combo_out_loss: 0.5582\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6102 - main_out_loss: 0.6235 - combo_out_loss: 0.5568\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.6075 - main_out_loss: 0.6205 - combo_out_loss: 0.5552\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6083 - main_out_loss: 0.6214 - combo_out_loss: 0.5559\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6071 - main_out_loss: 0.6201 - combo_out_loss: 0.5551\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6077 - main_out_loss: 0.6203 - combo_out_loss: 0.5573\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.6068 - main_out_loss: 0.6193 - combo_out_loss: 0.5571\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6056 - main_out_loss: 0.6180 - combo_out_loss: 0.5559\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6072 - main_out_loss: 0.6198 - combo_out_loss: 0.5571\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6079 - main_out_loss: 0.6203 - combo_out_loss: 0.5581\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6089 - main_out_loss: 0.6213 - combo_out_loss: 0.5592\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6120 - main_out_loss: 0.6247 - combo_out_loss: 0.5614\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6108 - main_out_loss: 0.6234 - combo_out_loss: 0.5607\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6120 - main_out_loss: 0.6245 - combo_out_loss: 0.5620\u001b[0m\n",
      "\u001b[31mEpoch 27/100\n",
      "\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.5702 - main_out_loss: 0.5779 - combo_out_loss: 0.5397\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6022 - main_out_loss: 0.6119 - combo_out_loss: 0.5636\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5913 - main_out_loss: 0.6022 - combo_out_loss: 0.5480\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6006 - main_out_loss: 0.6121 - combo_out_loss: 0.5547\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5982 - main_out_loss: 0.6095 - combo_out_loss: 0.5527\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.6003 - main_out_loss: 0.6125 - combo_out_loss: 0.5513\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.6023 - main_out_loss: 0.6146 - combo_out_loss: 0.5532\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.6002 - main_out_loss: 0.6128 - combo_out_loss: 0.5499\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6001 - main_out_loss: 0.6135 - combo_out_loss: 0.5466\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5987 - main_out_loss: 0.6118 - combo_out_loss: 0.5463\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5959 - main_out_loss: 0.6088 - combo_out_loss: 0.5444\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.6031 - main_out_loss: 0.6162 - combo_out_loss: 0.5506\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.6052 - main_out_loss: 0.6185 - combo_out_loss: 0.5517\u001b[0m\n",
      "\u001b[31m 864/1557 [===============>..............] - ETA: 0s - loss: 0.6053 - main_out_loss: 0.6188 - combo_out_loss: 0.5513\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.6014 - main_out_loss: 0.6148 - combo_out_loss: 0.5477\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.6045 - main_out_loss: 0.6182 - combo_out_loss: 0.5495\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.6027 - main_out_loss: 0.6163 - combo_out_loss: 0.5479\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5994 - main_out_loss: 0.6130 - combo_out_loss: 0.5452\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.6007 - main_out_loss: 0.6142 - combo_out_loss: 0.5469\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.6010 - main_out_loss: 0.6146 - combo_out_loss: 0.5466\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.6007 - main_out_loss: 0.6141 - combo_out_loss: 0.5471\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.6040 - main_out_loss: 0.6175 - combo_out_loss: 0.5500\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.6035 - main_out_loss: 0.6171 - combo_out_loss: 0.5490\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.6040 - main_out_loss: 0.6176 - combo_out_loss: 0.5494\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.6036 - main_out_loss: 0.6173 - combo_out_loss: 0.5488\u001b[0m\n",
      "\u001b[31mEpoch 28/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6492 - main_out_loss: 0.6686 - combo_out_loss: 0.5712\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6192 - main_out_loss: 0.6364 - combo_out_loss: 0.5508\u001b[0m\n",
      "\u001b[31m 160/1557 [==>...........................] - ETA: 1s - loss: 0.5948 - main_out_loss: 0.6112 - combo_out_loss: 0.5293\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6084 - main_out_loss: 0.6236 - combo_out_loss: 0.5476\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5966 - main_out_loss: 0.6104 - combo_out_loss: 0.5416\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5878 - main_out_loss: 0.6022 - combo_out_loss: 0.5302\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5832 - main_out_loss: 0.5968 - combo_out_loss: 0.5289\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5863 - main_out_loss: 0.6000 - combo_out_loss: 0.5315\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5982 - main_out_loss: 0.6122 - combo_out_loss: 0.5422\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.6008 - main_out_loss: 0.6157 - combo_out_loss: 0.5414\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5938 - main_out_loss: 0.6078 - combo_out_loss: 0.5376\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5945 - main_out_loss: 0.6086 - combo_out_loss: 0.5384\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5910 - main_out_loss: 0.6048 - combo_out_loss: 0.5356\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5915 - main_out_loss: 0.6050 - combo_out_loss: 0.5372\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5969 - main_out_loss: 0.6106 - combo_out_loss: 0.5421\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 992/1557 [==================>...........] - ETA: 0s - loss: 0.5949 - main_out_loss: 0.6085 - combo_out_loss: 0.5404\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5964 - main_out_loss: 0.6099 - combo_out_loss: 0.5423\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5958 - main_out_loss: 0.6090 - combo_out_loss: 0.5434\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5968 - main_out_loss: 0.6100 - combo_out_loss: 0.5443\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5968 - main_out_loss: 0.6101 - combo_out_loss: 0.5437\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5986 - main_out_loss: 0.6119 - combo_out_loss: 0.5453\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5978 - main_out_loss: 0.6109 - combo_out_loss: 0.5451\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5973 - main_out_loss: 0.6104 - combo_out_loss: 0.5452\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5978 - main_out_loss: 0.6111 - combo_out_loss: 0.5448\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5992 - main_out_loss: 0.6124 - combo_out_loss: 0.5462\u001b[0m\n",
      "\u001b[31mEpoch 29/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 2s - loss: 0.6052 - main_out_loss: 0.6105 - combo_out_loss: 0.5838\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5870 - main_out_loss: 0.6008 - combo_out_loss: 0.5316\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5838 - main_out_loss: 0.5988 - combo_out_loss: 0.5237\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.5856 - main_out_loss: 0.5997 - combo_out_loss: 0.5292\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5765 - main_out_loss: 0.5900 - combo_out_loss: 0.5228\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5837 - main_out_loss: 0.5976 - combo_out_loss: 0.5280\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5812 - main_out_loss: 0.5951 - combo_out_loss: 0.5254\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5797 - main_out_loss: 0.5936 - combo_out_loss: 0.5239\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5761 - main_out_loss: 0.5896 - combo_out_loss: 0.5222\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5736 - main_out_loss: 0.5866 - combo_out_loss: 0.5217\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5736 - main_out_loss: 0.5865 - combo_out_loss: 0.5221\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5766 - main_out_loss: 0.5891 - combo_out_loss: 0.5267\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5776 - main_out_loss: 0.5900 - combo_out_loss: 0.5280\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5829 - main_out_loss: 0.5957 - combo_out_loss: 0.5318\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5808 - main_out_loss: 0.5940 - combo_out_loss: 0.5281\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5828 - main_out_loss: 0.5961 - combo_out_loss: 0.5298\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5838 - main_out_loss: 0.5970 - combo_out_loss: 0.5308\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5856 - main_out_loss: 0.5992 - combo_out_loss: 0.5313\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5841 - main_out_loss: 0.5980 - combo_out_loss: 0.5285\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5861 - main_out_loss: 0.5997 - combo_out_loss: 0.5315\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5874 - main_out_loss: 0.6010 - combo_out_loss: 0.5331\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5867 - main_out_loss: 0.6005 - combo_out_loss: 0.5315\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5877 - main_out_loss: 0.6015 - combo_out_loss: 0.5323\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5877 - main_out_loss: 0.6019 - combo_out_loss: 0.5310\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5889 - main_out_loss: 0.6031 - combo_out_loss: 0.5320\u001b[0m\n",
      "\u001b[31mEpoch 30/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6300 - main_out_loss: 0.6481 - combo_out_loss: 0.5573\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6034 - main_out_loss: 0.6192 - combo_out_loss: 0.5400\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5764 - main_out_loss: 0.5911 - combo_out_loss: 0.5175\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5638 - main_out_loss: 0.5778 - combo_out_loss: 0.5078\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5765 - main_out_loss: 0.5919 - combo_out_loss: 0.5150\u001b[0m\n",
      "\u001b[31m 352/1557 [=====>........................] - ETA: 1s - loss: 0.5753 - main_out_loss: 0.5911 - combo_out_loss: 0.5120\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5820 - main_out_loss: 0.5974 - combo_out_loss: 0.5203\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5806 - main_out_loss: 0.5954 - combo_out_loss: 0.5213\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5827 - main_out_loss: 0.5978 - combo_out_loss: 0.5223\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5858 - main_out_loss: 0.6011 - combo_out_loss: 0.5247\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5893 - main_out_loss: 0.6047 - combo_out_loss: 0.5278\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5846 - main_out_loss: 0.5998 - combo_out_loss: 0.5239\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5840 - main_out_loss: 0.5993 - combo_out_loss: 0.5230\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5876 - main_out_loss: 0.6032 - combo_out_loss: 0.5252\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5869 - main_out_loss: 0.6027 - combo_out_loss: 0.5239\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5868 - main_out_loss: 0.6026 - combo_out_loss: 0.5234\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5856 - main_out_loss: 0.6014 - combo_out_loss: 0.5224\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5844 - main_out_loss: 0.5998 - combo_out_loss: 0.5231\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5845 - main_out_loss: 0.5999 - combo_out_loss: 0.5230\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5871 - main_out_loss: 0.6025 - combo_out_loss: 0.5256\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5874 - main_out_loss: 0.6031 - combo_out_loss: 0.5243\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5870 - main_out_loss: 0.6029 - combo_out_loss: 0.5235\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5874 - main_out_loss: 0.6034 - combo_out_loss: 0.5233\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5859 - main_out_loss: 0.6022 - combo_out_loss: 0.5210\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5857 - main_out_loss: 0.6019 - combo_out_loss: 0.5210\u001b[0m\n",
      "\u001b[31mEpoch 31/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5694 - main_out_loss: 0.5817 - combo_out_loss: 0.5198\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.6297 - main_out_loss: 0.6457 - combo_out_loss: 0.5655\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.6082 - main_out_loss: 0.6236 - combo_out_loss: 0.5465\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.6084 - main_out_loss: 0.6231 - combo_out_loss: 0.5496\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5980 - main_out_loss: 0.6125 - combo_out_loss: 0.5399\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5827 - main_out_loss: 0.5971 - combo_out_loss: 0.5251\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5902 - main_out_loss: 0.6057 - combo_out_loss: 0.5282\u001b[0m\n",
      "\u001b[31m 480/1557 [========>.....................] - ETA: 1s - loss: 0.5999 - main_out_loss: 0.6155 - combo_out_loss: 0.5372\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.6012 - main_out_loss: 0.6166 - combo_out_loss: 0.5400\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5949 - main_out_loss: 0.6097 - combo_out_loss: 0.5353\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5943 - main_out_loss: 0.6092 - combo_out_loss: 0.5350\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5889 - main_out_loss: 0.6040 - combo_out_loss: 0.5285\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5898 - main_out_loss: 0.6053 - combo_out_loss: 0.5278\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5849 - main_out_loss: 0.6006 - combo_out_loss: 0.5219\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5869 - main_out_loss: 0.6032 - combo_out_loss: 0.5217\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5861 - main_out_loss: 0.6025 - combo_out_loss: 0.5204\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5855 - main_out_loss: 0.6019 - combo_out_loss: 0.5199\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5828 - main_out_loss: 0.5991 - combo_out_loss: 0.5174\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5845 - main_out_loss: 0.6010 - combo_out_loss: 0.5186\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5811 - main_out_loss: 0.5975 - combo_out_loss: 0.5155\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5785 - main_out_loss: 0.5951 - combo_out_loss: 0.5124\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5766 - main_out_loss: 0.5933 - combo_out_loss: 0.5096\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5759 - main_out_loss: 0.5928 - combo_out_loss: 0.5087\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5751 - main_out_loss: 0.5920 - combo_out_loss: 0.5077\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5756 - main_out_loss: 0.5926 - combo_out_loss: 0.5074\u001b[0m\n",
      "\u001b[31mEpoch 32/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5603 - main_out_loss: 0.5787 - combo_out_loss: 0.4866\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5573 - main_out_loss: 0.5749 - combo_out_loss: 0.4871\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5592 - main_out_loss: 0.5783 - combo_out_loss: 0.4829\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5607 - main_out_loss: 0.5789 - combo_out_loss: 0.4878\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5596 - main_out_loss: 0.5785 - combo_out_loss: 0.4837\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5606 - main_out_loss: 0.5792 - combo_out_loss: 0.4864\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5688 - main_out_loss: 0.5869 - combo_out_loss: 0.4964\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5762 - main_out_loss: 0.5956 - combo_out_loss: 0.4989\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5702 - main_out_loss: 0.5893 - combo_out_loss: 0.4938\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.5752 - main_out_loss: 0.5941 - combo_out_loss: 0.4993\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5719 - main_out_loss: 0.5909 - combo_out_loss: 0.4961\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5708 - main_out_loss: 0.5899 - combo_out_loss: 0.4943\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5735 - main_out_loss: 0.5931 - combo_out_loss: 0.4952\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5770 - main_out_loss: 0.5963 - combo_out_loss: 0.4998\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5804 - main_out_loss: 0.5995 - combo_out_loss: 0.5039\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5779 - main_out_loss: 0.5965 - combo_out_loss: 0.5033\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5776 - main_out_loss: 0.5961 - combo_out_loss: 0.5037\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5757 - main_out_loss: 0.5940 - combo_out_loss: 0.5021\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5752 - main_out_loss: 0.5934 - combo_out_loss: 0.5027\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5760 - main_out_loss: 0.5940 - combo_out_loss: 0.5042\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5770 - main_out_loss: 0.5948 - combo_out_loss: 0.5056\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5759 - main_out_loss: 0.5938 - combo_out_loss: 0.5042\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5751 - main_out_loss: 0.5930 - combo_out_loss: 0.5036\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5739 - main_out_loss: 0.5917 - combo_out_loss: 0.5028\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5721 - main_out_loss: 0.5898 - combo_out_loss: 0.5014\u001b[0m\n",
      "\u001b[31mEpoch 33/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5065 - main_out_loss: 0.5166 - combo_out_loss: 0.4663\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5282 - main_out_loss: 0.5476 - combo_out_loss: 0.4505\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5526 - main_out_loss: 0.5721 - combo_out_loss: 0.4746\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5539 - main_out_loss: 0.5711 - combo_out_loss: 0.4849\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5551 - main_out_loss: 0.5723 - combo_out_loss: 0.4864\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5551 - main_out_loss: 0.5725 - combo_out_loss: 0.4852\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5554 - main_out_loss: 0.5731 - combo_out_loss: 0.4846\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5596 - main_out_loss: 0.5787 - combo_out_loss: 0.4832\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5591 - main_out_loss: 0.5776 - combo_out_loss: 0.4854\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5553 - main_out_loss: 0.5743 - combo_out_loss: 0.4791\u001b[0m\n",
      "\u001b[31m 672/1557 [===========>..................] - ETA: 1s - loss: 0.5561 - main_out_loss: 0.5753 - combo_out_loss: 0.4794\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5581 - main_out_loss: 0.5781 - combo_out_loss: 0.4782\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5565 - main_out_loss: 0.5763 - combo_out_loss: 0.4771\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5593 - main_out_loss: 0.5792 - combo_out_loss: 0.4797\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5594 - main_out_loss: 0.5790 - combo_out_loss: 0.4810\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5595 - main_out_loss: 0.5794 - combo_out_loss: 0.4800\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5597 - main_out_loss: 0.5796 - combo_out_loss: 0.4802\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5598 - main_out_loss: 0.5795 - combo_out_loss: 0.4811\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5579 - main_out_loss: 0.5777 - combo_out_loss: 0.4787\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5591 - main_out_loss: 0.5790 - combo_out_loss: 0.4797\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5568 - main_out_loss: 0.5769 - combo_out_loss: 0.4765\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5569 - main_out_loss: 0.5771 - combo_out_loss: 0.4761\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5573 - main_out_loss: 0.5776 - combo_out_loss: 0.4760\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5575 - main_out_loss: 0.5778 - combo_out_loss: 0.4763\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5597 - main_out_loss: 0.5805 - combo_out_loss: 0.4767\u001b[0m\n",
      "\u001b[31mEpoch 34/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.6219 - main_out_loss: 0.6413 - combo_out_loss: 0.5444\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5480 - main_out_loss: 0.5682 - combo_out_loss: 0.4674\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5435 - main_out_loss: 0.5629 - combo_out_loss: 0.4658\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5490 - main_out_loss: 0.5694 - combo_out_loss: 0.4673\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5437 - main_out_loss: 0.5641 - combo_out_loss: 0.4623\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5469 - main_out_loss: 0.5677 - combo_out_loss: 0.4634\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5520 - main_out_loss: 0.5732 - combo_out_loss: 0.4672\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5552 - main_out_loss: 0.5758 - combo_out_loss: 0.4725\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5603 - main_out_loss: 0.5809 - combo_out_loss: 0.4777\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5540 - main_out_loss: 0.5749 - combo_out_loss: 0.4706\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5481 - main_out_loss: 0.5690 - combo_out_loss: 0.4642\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5502 - main_out_loss: 0.5712 - combo_out_loss: 0.4660\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.5512 - main_out_loss: 0.5721 - combo_out_loss: 0.4676\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5515 - main_out_loss: 0.5724 - combo_out_loss: 0.4680\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5507 - main_out_loss: 0.5714 - combo_out_loss: 0.4679\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5515 - main_out_loss: 0.5720 - combo_out_loss: 0.4693\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5495 - main_out_loss: 0.5703 - combo_out_loss: 0.4662\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5488 - main_out_loss: 0.5696 - combo_out_loss: 0.4659\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5506 - main_out_loss: 0.5715 - combo_out_loss: 0.4669\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5531 - main_out_loss: 0.5742 - combo_out_loss: 0.4689\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5533 - main_out_loss: 0.5741 - combo_out_loss: 0.4697\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5519 - main_out_loss: 0.5728 - combo_out_loss: 0.4682\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5519 - main_out_loss: 0.5729 - combo_out_loss: 0.4680\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5516 - main_out_loss: 0.5727 - combo_out_loss: 0.4670\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5521 - main_out_loss: 0.5734 - combo_out_loss: 0.4669\u001b[0m\n",
      "\u001b[31mEpoch 35/100\n",
      "\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.5695 - main_out_loss: 0.5973 - combo_out_loss: 0.4582\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5540 - main_out_loss: 0.5806 - combo_out_loss: 0.4477\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5297 - main_out_loss: 0.5563 - combo_out_loss: 0.4230\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5397 - main_out_loss: 0.5662 - combo_out_loss: 0.4338\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5325 - main_out_loss: 0.5580 - combo_out_loss: 0.4308\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5446 - main_out_loss: 0.5679 - combo_out_loss: 0.4514\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5447 - main_out_loss: 0.5679 - combo_out_loss: 0.4521\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5403 - main_out_loss: 0.5630 - combo_out_loss: 0.4493\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5419 - main_out_loss: 0.5653 - combo_out_loss: 0.4482\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5396 - main_out_loss: 0.5621 - combo_out_loss: 0.4495\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5379 - main_out_loss: 0.5604 - combo_out_loss: 0.4477\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5392 - main_out_loss: 0.5620 - combo_out_loss: 0.4478\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5442 - main_out_loss: 0.5671 - combo_out_loss: 0.4528\u001b[0m\n",
      "\u001b[31m 864/1557 [===============>..............] - ETA: 0s - loss: 0.5417 - main_out_loss: 0.5640 - combo_out_loss: 0.4524\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5466 - main_out_loss: 0.5687 - combo_out_loss: 0.4580\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5436 - main_out_loss: 0.5660 - combo_out_loss: 0.4538\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5460 - main_out_loss: 0.5688 - combo_out_loss: 0.4547\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5465 - main_out_loss: 0.5694 - combo_out_loss: 0.4553\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5485 - main_out_loss: 0.5717 - combo_out_loss: 0.4555\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5474 - main_out_loss: 0.5706 - combo_out_loss: 0.4547\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5471 - main_out_loss: 0.5704 - combo_out_loss: 0.4542\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5480 - main_out_loss: 0.5714 - combo_out_loss: 0.4543\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5476 - main_out_loss: 0.5710 - combo_out_loss: 0.4542\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5472 - main_out_loss: 0.5705 - combo_out_loss: 0.4541\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5477 - main_out_loss: 0.5711 - combo_out_loss: 0.4542\u001b[0m\n",
      "\u001b[31mEpoch 36/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5380 - main_out_loss: 0.5606 - combo_out_loss: 0.4474\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5439 - main_out_loss: 0.5656 - combo_out_loss: 0.4574\u001b[0m\n",
      "\u001b[31m 160/1557 [==>...........................] - ETA: 1s - loss: 0.5567 - main_out_loss: 0.5794 - combo_out_loss: 0.4656\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5483 - main_out_loss: 0.5718 - combo_out_loss: 0.4542\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5485 - main_out_loss: 0.5714 - combo_out_loss: 0.4573\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5434 - main_out_loss: 0.5661 - combo_out_loss: 0.4523\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5446 - main_out_loss: 0.5671 - combo_out_loss: 0.4546\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5415 - main_out_loss: 0.5643 - combo_out_loss: 0.4504\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5431 - main_out_loss: 0.5665 - combo_out_loss: 0.4495\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5391 - main_out_loss: 0.5625 - combo_out_loss: 0.4458\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5316 - main_out_loss: 0.5546 - combo_out_loss: 0.4398\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5306 - main_out_loss: 0.5541 - combo_out_loss: 0.4367\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5309 - main_out_loss: 0.5541 - combo_out_loss: 0.4377\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5332 - main_out_loss: 0.5564 - combo_out_loss: 0.4404\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5322 - main_out_loss: 0.5553 - combo_out_loss: 0.4401\u001b[0m\n",
      "\u001b[31m 992/1557 [==================>...........] - ETA: 0s - loss: 0.5320 - main_out_loss: 0.5549 - combo_out_loss: 0.4405\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5332 - main_out_loss: 0.5561 - combo_out_loss: 0.4418\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5363 - main_out_loss: 0.5589 - combo_out_loss: 0.4459\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5360 - main_out_loss: 0.5588 - combo_out_loss: 0.4449\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5382 - main_out_loss: 0.5611 - combo_out_loss: 0.4466\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5376 - main_out_loss: 0.5606 - combo_out_loss: 0.4454\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5372 - main_out_loss: 0.5603 - combo_out_loss: 0.4446\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5382 - main_out_loss: 0.5616 - combo_out_loss: 0.4446\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5382 - main_out_loss: 0.5616 - combo_out_loss: 0.4443\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5372 - main_out_loss: 0.5607 - combo_out_loss: 0.4429\u001b[0m\n",
      "\u001b[31mEpoch 37/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5048 - main_out_loss: 0.5374 - combo_out_loss: 0.3747\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5182 - main_out_loss: 0.5457 - combo_out_loss: 0.4083\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5005 - main_out_loss: 0.5268 - combo_out_loss: 0.3955\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.5067 - main_out_loss: 0.5333 - combo_out_loss: 0.4002\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5227 - main_out_loss: 0.5486 - combo_out_loss: 0.4190\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5195 - main_out_loss: 0.5446 - combo_out_loss: 0.4194\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5153 - main_out_loss: 0.5402 - combo_out_loss: 0.4159\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5202 - main_out_loss: 0.5447 - combo_out_loss: 0.4224\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5220 - main_out_loss: 0.5460 - combo_out_loss: 0.4260\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5231 - main_out_loss: 0.5474 - combo_out_loss: 0.4260\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5246 - main_out_loss: 0.5488 - combo_out_loss: 0.4281\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5275 - main_out_loss: 0.5519 - combo_out_loss: 0.4297\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5235 - main_out_loss: 0.5475 - combo_out_loss: 0.4276\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5228 - main_out_loss: 0.5464 - combo_out_loss: 0.4283\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5259 - main_out_loss: 0.5501 - combo_out_loss: 0.4289\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5277 - main_out_loss: 0.5525 - combo_out_loss: 0.4289\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5276 - main_out_loss: 0.5525 - combo_out_loss: 0.4280\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5295 - main_out_loss: 0.5544 - combo_out_loss: 0.4298\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5270 - main_out_loss: 0.5521 - combo_out_loss: 0.4264\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5265 - main_out_loss: 0.5513 - combo_out_loss: 0.4271\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5273 - main_out_loss: 0.5520 - combo_out_loss: 0.4287\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5269 - main_out_loss: 0.5516 - combo_out_loss: 0.4279\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5264 - main_out_loss: 0.5511 - combo_out_loss: 0.4278\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5275 - main_out_loss: 0.5523 - combo_out_loss: 0.4285\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5270 - main_out_loss: 0.5515 - combo_out_loss: 0.4290\u001b[0m\n",
      "\u001b[31mEpoch 38/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4735 - main_out_loss: 0.4865 - combo_out_loss: 0.4218\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4897 - main_out_loss: 0.5054 - combo_out_loss: 0.4271\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5045 - main_out_loss: 0.5230 - combo_out_loss: 0.4304\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5114 - main_out_loss: 0.5338 - combo_out_loss: 0.4215\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5181 - main_out_loss: 0.5423 - combo_out_loss: 0.4215\u001b[0m\n",
      "\u001b[31m 352/1557 [=====>........................] - ETA: 1s - loss: 0.5119 - main_out_loss: 0.5352 - combo_out_loss: 0.4186\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5147 - main_out_loss: 0.5392 - combo_out_loss: 0.4169\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5143 - main_out_loss: 0.5388 - combo_out_loss: 0.4163\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5255 - main_out_loss: 0.5508 - combo_out_loss: 0.4242\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5190 - main_out_loss: 0.5446 - combo_out_loss: 0.4165\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5228 - main_out_loss: 0.5490 - combo_out_loss: 0.4178\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5252 - main_out_loss: 0.5515 - combo_out_loss: 0.4198\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5222 - main_out_loss: 0.5479 - combo_out_loss: 0.4193\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5205 - main_out_loss: 0.5459 - combo_out_loss: 0.4188\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5216 - main_out_loss: 0.5470 - combo_out_loss: 0.4196\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5200 - main_out_loss: 0.5453 - combo_out_loss: 0.4189\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5185 - main_out_loss: 0.5434 - combo_out_loss: 0.4188\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5169 - main_out_loss: 0.5416 - combo_out_loss: 0.4179\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5170 - main_out_loss: 0.5423 - combo_out_loss: 0.4156\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5149 - main_out_loss: 0.5400 - combo_out_loss: 0.4143\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5149 - main_out_loss: 0.5402 - combo_out_loss: 0.4137\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5173 - main_out_loss: 0.5428 - combo_out_loss: 0.4153\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5173 - main_out_loss: 0.5428 - combo_out_loss: 0.4150\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5187 - main_out_loss: 0.5443 - combo_out_loss: 0.4165\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5181 - main_out_loss: 0.5435 - combo_out_loss: 0.4165\u001b[0m\n",
      "\u001b[31mEpoch 39/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5661 - main_out_loss: 0.5984 - combo_out_loss: 0.4372\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5064 - main_out_loss: 0.5315 - combo_out_loss: 0.4060\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5078 - main_out_loss: 0.5340 - combo_out_loss: 0.4029\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5176 - main_out_loss: 0.5447 - combo_out_loss: 0.4090\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5182 - main_out_loss: 0.5462 - combo_out_loss: 0.4063\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5095 - main_out_loss: 0.5377 - combo_out_loss: 0.3966\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5186 - main_out_loss: 0.5485 - combo_out_loss: 0.3992\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 480/1557 [========>.....................] - ETA: 1s - loss: 0.5184 - main_out_loss: 0.5481 - combo_out_loss: 0.3999\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5196 - main_out_loss: 0.5500 - combo_out_loss: 0.3980\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5156 - main_out_loss: 0.5453 - combo_out_loss: 0.3971\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.5146 - main_out_loss: 0.5439 - combo_out_loss: 0.3972\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5102 - main_out_loss: 0.5384 - combo_out_loss: 0.3972\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5117 - main_out_loss: 0.5396 - combo_out_loss: 0.4000\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5113 - main_out_loss: 0.5386 - combo_out_loss: 0.4023\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.5117 - main_out_loss: 0.5387 - combo_out_loss: 0.4038\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.5125 - main_out_loss: 0.5401 - combo_out_loss: 0.4024\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.5155 - main_out_loss: 0.5430 - combo_out_loss: 0.4056\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.5144 - main_out_loss: 0.5421 - combo_out_loss: 0.4036\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.5174 - main_out_loss: 0.5455 - combo_out_loss: 0.4051\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.5153 - main_out_loss: 0.5429 - combo_out_loss: 0.4047\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.5149 - main_out_loss: 0.5420 - combo_out_loss: 0.4064\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.5176 - main_out_loss: 0.5446 - combo_out_loss: 0.4095\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.5167 - main_out_loss: 0.5440 - combo_out_loss: 0.4076\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.5158 - main_out_loss: 0.5433 - combo_out_loss: 0.4059\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.5139 - main_out_loss: 0.5413 - combo_out_loss: 0.4040\u001b[0m\n",
      "\u001b[31mEpoch 40/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5473 - main_out_loss: 0.5836 - combo_out_loss: 0.4019\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4787 - main_out_loss: 0.5078 - combo_out_loss: 0.3623\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4731 - main_out_loss: 0.5032 - combo_out_loss: 0.3528\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4747 - main_out_loss: 0.5031 - combo_out_loss: 0.3609\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4757 - main_out_loss: 0.5032 - combo_out_loss: 0.3656\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4791 - main_out_loss: 0.5089 - combo_out_loss: 0.3598\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4837 - main_out_loss: 0.5127 - combo_out_loss: 0.3676\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4806 - main_out_loss: 0.5090 - combo_out_loss: 0.3672\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4819 - main_out_loss: 0.5101 - combo_out_loss: 0.3694\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.4816 - main_out_loss: 0.5098 - combo_out_loss: 0.3688\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4864 - main_out_loss: 0.5140 - combo_out_loss: 0.3759\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4887 - main_out_loss: 0.5161 - combo_out_loss: 0.3792\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4900 - main_out_loss: 0.5173 - combo_out_loss: 0.3804\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4896 - main_out_loss: 0.5164 - combo_out_loss: 0.3822\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4900 - main_out_loss: 0.5169 - combo_out_loss: 0.3823\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4923 - main_out_loss: 0.5192 - combo_out_loss: 0.3846\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4930 - main_out_loss: 0.5198 - combo_out_loss: 0.3855\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4961 - main_out_loss: 0.5231 - combo_out_loss: 0.3880\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4973 - main_out_loss: 0.5245 - combo_out_loss: 0.3883\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4994 - main_out_loss: 0.5273 - combo_out_loss: 0.3880\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4997 - main_out_loss: 0.5273 - combo_out_loss: 0.3895\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4977 - main_out_loss: 0.5249 - combo_out_loss: 0.3893\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4977 - main_out_loss: 0.5246 - combo_out_loss: 0.3899\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4959 - main_out_loss: 0.5227 - combo_out_loss: 0.3889\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4968 - main_out_loss: 0.5235 - combo_out_loss: 0.3900\u001b[0m\n",
      "\u001b[31mEpoch 41/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.5299 - main_out_loss: 0.5579 - combo_out_loss: 0.4179\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.5342 - main_out_loss: 0.5629 - combo_out_loss: 0.4194\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5361 - main_out_loss: 0.5657 - combo_out_loss: 0.4175\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.5189 - main_out_loss: 0.5492 - combo_out_loss: 0.3976\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.5293 - main_out_loss: 0.5580 - combo_out_loss: 0.4146\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.5221 - main_out_loss: 0.5502 - combo_out_loss: 0.4097\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.5146 - main_out_loss: 0.5420 - combo_out_loss: 0.4048\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.5085 - main_out_loss: 0.5352 - combo_out_loss: 0.4016\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.5136 - main_out_loss: 0.5412 - combo_out_loss: 0.4032\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.5137 - main_out_loss: 0.5423 - combo_out_loss: 0.3994\u001b[0m\n",
      "\u001b[31m 672/1557 [===========>..................] - ETA: 1s - loss: 0.5075 - main_out_loss: 0.5359 - combo_out_loss: 0.3940\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.5043 - main_out_loss: 0.5333 - combo_out_loss: 0.3883\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.5049 - main_out_loss: 0.5336 - combo_out_loss: 0.3900\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.5001 - main_out_loss: 0.5291 - combo_out_loss: 0.3841\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4971 - main_out_loss: 0.5258 - combo_out_loss: 0.3822\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4970 - main_out_loss: 0.5260 - combo_out_loss: 0.3813\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4987 - main_out_loss: 0.5279 - combo_out_loss: 0.3816\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4998 - main_out_loss: 0.5285 - combo_out_loss: 0.3850\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4969 - main_out_loss: 0.5256 - combo_out_loss: 0.3819\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4957 - main_out_loss: 0.5242 - combo_out_loss: 0.3817\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4937 - main_out_loss: 0.5219 - combo_out_loss: 0.3809\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4939 - main_out_loss: 0.5221 - combo_out_loss: 0.3811\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4950 - main_out_loss: 0.5234 - combo_out_loss: 0.3816\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4953 - main_out_loss: 0.5237 - combo_out_loss: 0.3814\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4953 - main_out_loss: 0.5236 - combo_out_loss: 0.3819\u001b[0m\n",
      "\u001b[31mEpoch 42/100\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.5215 - main_out_loss: 0.5442 - combo_out_loss: 0.4308\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4981 - main_out_loss: 0.5240 - combo_out_loss: 0.3944\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4850 - main_out_loss: 0.5092 - combo_out_loss: 0.3879\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4769 - main_out_loss: 0.5027 - combo_out_loss: 0.3739\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4780 - main_out_loss: 0.5052 - combo_out_loss: 0.3691\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4815 - main_out_loss: 0.5086 - combo_out_loss: 0.3731\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4842 - main_out_loss: 0.5121 - combo_out_loss: 0.3724\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4895 - main_out_loss: 0.5168 - combo_out_loss: 0.3802\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4820 - main_out_loss: 0.5089 - combo_out_loss: 0.3743\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4815 - main_out_loss: 0.5083 - combo_out_loss: 0.3744\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4827 - main_out_loss: 0.5092 - combo_out_loss: 0.3765\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4879 - main_out_loss: 0.5148 - combo_out_loss: 0.3803\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.4895 - main_out_loss: 0.5165 - combo_out_loss: 0.3817\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4913 - main_out_loss: 0.5183 - combo_out_loss: 0.3834\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4915 - main_out_loss: 0.5181 - combo_out_loss: 0.3854\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4900 - main_out_loss: 0.5166 - combo_out_loss: 0.3839\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4903 - main_out_loss: 0.5172 - combo_out_loss: 0.3830\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4908 - main_out_loss: 0.5175 - combo_out_loss: 0.3839\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4875 - main_out_loss: 0.5140 - combo_out_loss: 0.3813\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4867 - main_out_loss: 0.5134 - combo_out_loss: 0.3802\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4875 - main_out_loss: 0.5143 - combo_out_loss: 0.3801\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4881 - main_out_loss: 0.5155 - combo_out_loss: 0.3788\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4855 - main_out_loss: 0.5127 - combo_out_loss: 0.3764\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4860 - main_out_loss: 0.5136 - combo_out_loss: 0.3758\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4877 - main_out_loss: 0.5156 - combo_out_loss: 0.3759\u001b[0m\n",
      "\u001b[31mEpoch 43/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4335 - main_out_loss: 0.4583 - combo_out_loss: 0.3344\u001b[0m\n",
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.4768 - main_out_loss: 0.5063 - combo_out_loss: 0.3589\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.5014 - main_out_loss: 0.5303 - combo_out_loss: 0.3854\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4805 - main_out_loss: 0.5089 - combo_out_loss: 0.3671\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4750 - main_out_loss: 0.5018 - combo_out_loss: 0.3675\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4833 - main_out_loss: 0.5105 - combo_out_loss: 0.3746\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4754 - main_out_loss: 0.5025 - combo_out_loss: 0.3672\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4757 - main_out_loss: 0.5034 - combo_out_loss: 0.3649\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4797 - main_out_loss: 0.5076 - combo_out_loss: 0.3681\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4834 - main_out_loss: 0.5115 - combo_out_loss: 0.3711\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4799 - main_out_loss: 0.5065 - combo_out_loss: 0.3733\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4795 - main_out_loss: 0.5064 - combo_out_loss: 0.3718\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4795 - main_out_loss: 0.5067 - combo_out_loss: 0.3709\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4781 - main_out_loss: 0.5049 - combo_out_loss: 0.3708\u001b[0m\n",
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.4786 - main_out_loss: 0.5049 - combo_out_loss: 0.3735\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4794 - main_out_loss: 0.5058 - combo_out_loss: 0.3739\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4770 - main_out_loss: 0.5033 - combo_out_loss: 0.3718\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4747 - main_out_loss: 0.5008 - combo_out_loss: 0.3704\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4743 - main_out_loss: 0.5006 - combo_out_loss: 0.3694\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4738 - main_out_loss: 0.5004 - combo_out_loss: 0.3678\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4758 - main_out_loss: 0.5024 - combo_out_loss: 0.3691\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4744 - main_out_loss: 0.5009 - combo_out_loss: 0.3683\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4752 - main_out_loss: 0.5020 - combo_out_loss: 0.3679\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4758 - main_out_loss: 0.5022 - combo_out_loss: 0.3702\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4746 - main_out_loss: 0.5012 - combo_out_loss: 0.3680\u001b[0m\n",
      "\u001b[31mEpoch 44/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4742 - main_out_loss: 0.5048 - combo_out_loss: 0.3520\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4960 - main_out_loss: 0.5221 - combo_out_loss: 0.3919\u001b[0m\n",
      "\u001b[31m 160/1557 [==>...........................] - ETA: 1s - loss: 0.4664 - main_out_loss: 0.4944 - combo_out_loss: 0.3544\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4728 - main_out_loss: 0.4995 - combo_out_loss: 0.3656\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4763 - main_out_loss: 0.5035 - combo_out_loss: 0.3679\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4721 - main_out_loss: 0.4998 - combo_out_loss: 0.3613\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4676 - main_out_loss: 0.4950 - combo_out_loss: 0.3577\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4658 - main_out_loss: 0.4942 - combo_out_loss: 0.3523\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4630 - main_out_loss: 0.4909 - combo_out_loss: 0.3512\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4653 - main_out_loss: 0.4936 - combo_out_loss: 0.3522\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4686 - main_out_loss: 0.4963 - combo_out_loss: 0.3577\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4722 - main_out_loss: 0.5004 - combo_out_loss: 0.3592\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4756 - main_out_loss: 0.5042 - combo_out_loss: 0.3610\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4768 - main_out_loss: 0.5052 - combo_out_loss: 0.3631\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4780 - main_out_loss: 0.5065 - combo_out_loss: 0.3642\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4784 - main_out_loss: 0.5069 - combo_out_loss: 0.3643\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4804 - main_out_loss: 0.5090 - combo_out_loss: 0.3661\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4773 - main_out_loss: 0.5058 - combo_out_loss: 0.3634\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4780 - main_out_loss: 0.5063 - combo_out_loss: 0.3647\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4769 - main_out_loss: 0.5051 - combo_out_loss: 0.3641\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4727 - main_out_loss: 0.5006 - combo_out_loss: 0.3610\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4742 - main_out_loss: 0.5017 - combo_out_loss: 0.3641\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4764 - main_out_loss: 0.5043 - combo_out_loss: 0.3649\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4757 - main_out_loss: 0.5034 - combo_out_loss: 0.3648\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4763 - main_out_loss: 0.5042 - combo_out_loss: 0.3647\u001b[0m\n",
      "\u001b[31mEpoch 45/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 2s - loss: 0.4306 - main_out_loss: 0.4596 - combo_out_loss: 0.3149\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4619 - main_out_loss: 0.4914 - combo_out_loss: 0.3439\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4715 - main_out_loss: 0.5013 - combo_out_loss: 0.3524\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4599 - main_out_loss: 0.4869 - combo_out_loss: 0.3521\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.4683 - main_out_loss: 0.4941 - combo_out_loss: 0.3649\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4670 - main_out_loss: 0.4937 - combo_out_loss: 0.3603\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4590 - main_out_loss: 0.4858 - combo_out_loss: 0.3517\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4568 - main_out_loss: 0.4835 - combo_out_loss: 0.3500\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4625 - main_out_loss: 0.4910 - combo_out_loss: 0.3488\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4640 - main_out_loss: 0.4928 - combo_out_loss: 0.3488\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4639 - main_out_loss: 0.4925 - combo_out_loss: 0.3491\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4604 - main_out_loss: 0.4889 - combo_out_loss: 0.3462\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4626 - main_out_loss: 0.4909 - combo_out_loss: 0.3496\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4608 - main_out_loss: 0.4890 - combo_out_loss: 0.3479\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4595 - main_out_loss: 0.4877 - combo_out_loss: 0.3469\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4618 - main_out_loss: 0.4898 - combo_out_loss: 0.3500\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4623 - main_out_loss: 0.4899 - combo_out_loss: 0.3519\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4648 - main_out_loss: 0.4920 - combo_out_loss: 0.3560\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4640 - main_out_loss: 0.4909 - combo_out_loss: 0.3565\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4606 - main_out_loss: 0.4874 - combo_out_loss: 0.3532\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4602 - main_out_loss: 0.4869 - combo_out_loss: 0.3534\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4607 - main_out_loss: 0.4875 - combo_out_loss: 0.3536\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4591 - main_out_loss: 0.4860 - combo_out_loss: 0.3515\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4579 - main_out_loss: 0.4846 - combo_out_loss: 0.3508\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4582 - main_out_loss: 0.4852 - combo_out_loss: 0.3499\u001b[0m\n",
      "\u001b[31mEpoch 46/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4275 - main_out_loss: 0.4535 - combo_out_loss: 0.3236\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4367 - main_out_loss: 0.4654 - combo_out_loss: 0.3221\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4254 - main_out_loss: 0.4481 - combo_out_loss: 0.3347\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4357 - main_out_loss: 0.4600 - combo_out_loss: 0.3388\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4386 - main_out_loss: 0.4637 - combo_out_loss: 0.3383\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4401 - main_out_loss: 0.4659 - combo_out_loss: 0.3365\u001b[0m\n",
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.4494 - main_out_loss: 0.4765 - combo_out_loss: 0.3407\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4576 - main_out_loss: 0.4859 - combo_out_loss: 0.3444\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4556 - main_out_loss: 0.4843 - combo_out_loss: 0.3407\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4578 - main_out_loss: 0.4871 - combo_out_loss: 0.3408\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4559 - main_out_loss: 0.4858 - combo_out_loss: 0.3361\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4570 - main_out_loss: 0.4869 - combo_out_loss: 0.3374\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4592 - main_out_loss: 0.4894 - combo_out_loss: 0.3385\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4581 - main_out_loss: 0.4885 - combo_out_loss: 0.3368\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4612 - main_out_loss: 0.4915 - combo_out_loss: 0.3403\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4623 - main_out_loss: 0.4920 - combo_out_loss: 0.3436\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4588 - main_out_loss: 0.4882 - combo_out_loss: 0.3412\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4562 - main_out_loss: 0.4853 - combo_out_loss: 0.3397\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4540 - main_out_loss: 0.4823 - combo_out_loss: 0.3407\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4533 - main_out_loss: 0.4814 - combo_out_loss: 0.3412\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4540 - main_out_loss: 0.4821 - combo_out_loss: 0.3418\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4534 - main_out_loss: 0.4817 - combo_out_loss: 0.3404\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4506 - main_out_loss: 0.4786 - combo_out_loss: 0.3387\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4509 - main_out_loss: 0.4788 - combo_out_loss: 0.3397\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4503 - main_out_loss: 0.4779 - combo_out_loss: 0.3399\u001b[0m\n",
      "\u001b[31mEpoch 47/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4602 - main_out_loss: 0.4919 - combo_out_loss: 0.3336\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4543 - main_out_loss: 0.4811 - combo_out_loss: 0.3471\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4401 - main_out_loss: 0.4651 - combo_out_loss: 0.3402\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4422 - main_out_loss: 0.4684 - combo_out_loss: 0.3373\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4342 - main_out_loss: 0.4603 - combo_out_loss: 0.3298\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4352 - main_out_loss: 0.4620 - combo_out_loss: 0.3280\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4305 - main_out_loss: 0.4573 - combo_out_loss: 0.3234\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4337 - main_out_loss: 0.4606 - combo_out_loss: 0.3261\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 544/1557 [=========>....................] - ETA: 1s - loss: 0.4309 - main_out_loss: 0.4579 - combo_out_loss: 0.3228\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4305 - main_out_loss: 0.4577 - combo_out_loss: 0.3219\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4303 - main_out_loss: 0.4573 - combo_out_loss: 0.3223\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4314 - main_out_loss: 0.4582 - combo_out_loss: 0.3241\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4309 - main_out_loss: 0.4576 - combo_out_loss: 0.3240\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4318 - main_out_loss: 0.4584 - combo_out_loss: 0.3252\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4361 - main_out_loss: 0.4630 - combo_out_loss: 0.3283\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4358 - main_out_loss: 0.4623 - combo_out_loss: 0.3299\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4381 - main_out_loss: 0.4644 - combo_out_loss: 0.3330\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4370 - main_out_loss: 0.4628 - combo_out_loss: 0.3338\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4378 - main_out_loss: 0.4633 - combo_out_loss: 0.3359\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4379 - main_out_loss: 0.4632 - combo_out_loss: 0.3363\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4393 - main_out_loss: 0.4649 - combo_out_loss: 0.3367\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4386 - main_out_loss: 0.4642 - combo_out_loss: 0.3361\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4384 - main_out_loss: 0.4636 - combo_out_loss: 0.3379\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4396 - main_out_loss: 0.4648 - combo_out_loss: 0.3386\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4386 - main_out_loss: 0.4640 - combo_out_loss: 0.3370\u001b[0m\n",
      "\u001b[31mEpoch 48/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4349 - main_out_loss: 0.4715 - combo_out_loss: 0.2883\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4047 - main_out_loss: 0.4279 - combo_out_loss: 0.3122\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4039 - main_out_loss: 0.4277 - combo_out_loss: 0.3086\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4024 - main_out_loss: 0.4268 - combo_out_loss: 0.3049\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4079 - main_out_loss: 0.4326 - combo_out_loss: 0.3091\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4145 - main_out_loss: 0.4372 - combo_out_loss: 0.3235\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4233 - main_out_loss: 0.4466 - combo_out_loss: 0.3299\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4252 - main_out_loss: 0.4492 - combo_out_loss: 0.3295\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4287 - main_out_loss: 0.4535 - combo_out_loss: 0.3293\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.4280 - main_out_loss: 0.4525 - combo_out_loss: 0.3302\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4309 - main_out_loss: 0.4566 - combo_out_loss: 0.3281\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4306 - main_out_loss: 0.4567 - combo_out_loss: 0.3259\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4332 - main_out_loss: 0.4592 - combo_out_loss: 0.3291\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4358 - main_out_loss: 0.4619 - combo_out_loss: 0.3314\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4339 - main_out_loss: 0.4596 - combo_out_loss: 0.3312\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4333 - main_out_loss: 0.4585 - combo_out_loss: 0.3328\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4334 - main_out_loss: 0.4592 - combo_out_loss: 0.3306\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4315 - main_out_loss: 0.4571 - combo_out_loss: 0.3293\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4323 - main_out_loss: 0.4582 - combo_out_loss: 0.3288\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4310 - main_out_loss: 0.4566 - combo_out_loss: 0.3285\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4313 - main_out_loss: 0.4567 - combo_out_loss: 0.3298\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4313 - main_out_loss: 0.4570 - combo_out_loss: 0.3283\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4316 - main_out_loss: 0.4574 - combo_out_loss: 0.3282\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4323 - main_out_loss: 0.4582 - combo_out_loss: 0.3288\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4314 - main_out_loss: 0.4574 - combo_out_loss: 0.3276\u001b[0m\n",
      "\u001b[31mEpoch 49/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4678 - main_out_loss: 0.5009 - combo_out_loss: 0.3353\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3910 - main_out_loss: 0.4166 - combo_out_loss: 0.2883\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3922 - main_out_loss: 0.4172 - combo_out_loss: 0.2922\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4001 - main_out_loss: 0.4250 - combo_out_loss: 0.3005\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4068 - main_out_loss: 0.4328 - combo_out_loss: 0.3029\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4021 - main_out_loss: 0.4268 - combo_out_loss: 0.3033\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4041 - main_out_loss: 0.4293 - combo_out_loss: 0.3034\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4064 - main_out_loss: 0.4315 - combo_out_loss: 0.3058\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4096 - main_out_loss: 0.4344 - combo_out_loss: 0.3107\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4126 - main_out_loss: 0.4367 - combo_out_loss: 0.3165\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4150 - main_out_loss: 0.4397 - combo_out_loss: 0.3165\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 0s - loss: 0.4116 - main_out_loss: 0.4359 - combo_out_loss: 0.3145\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4134 - main_out_loss: 0.4378 - combo_out_loss: 0.3157\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4170 - main_out_loss: 0.4412 - combo_out_loss: 0.3204\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4184 - main_out_loss: 0.4432 - combo_out_loss: 0.3193\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4182 - main_out_loss: 0.4425 - combo_out_loss: 0.3206\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4192 - main_out_loss: 0.4436 - combo_out_loss: 0.3214\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4185 - main_out_loss: 0.4430 - combo_out_loss: 0.3205\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4197 - main_out_loss: 0.4441 - combo_out_loss: 0.3220\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4190 - main_out_loss: 0.4430 - combo_out_loss: 0.3230\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4173 - main_out_loss: 0.4409 - combo_out_loss: 0.3229\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4188 - main_out_loss: 0.4427 - combo_out_loss: 0.3232\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4164 - main_out_loss: 0.4398 - combo_out_loss: 0.3228\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4188 - main_out_loss: 0.4425 - combo_out_loss: 0.3243\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4179 - main_out_loss: 0.4413 - combo_out_loss: 0.3243\u001b[0m\n",
      "\u001b[31mEpoch 50/100\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.3694 - main_out_loss: 0.3856 - combo_out_loss: 0.3045\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3994 - main_out_loss: 0.4208 - combo_out_loss: 0.3137\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4124 - main_out_loss: 0.4340 - combo_out_loss: 0.3264\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4184 - main_out_loss: 0.4426 - combo_out_loss: 0.3215\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4164 - main_out_loss: 0.4401 - combo_out_loss: 0.3219\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4181 - main_out_loss: 0.4407 - combo_out_loss: 0.3274\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4153 - main_out_loss: 0.4373 - combo_out_loss: 0.3269\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4219 - main_out_loss: 0.4443 - combo_out_loss: 0.3324\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4209 - main_out_loss: 0.4434 - combo_out_loss: 0.3311\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4210 - main_out_loss: 0.4439 - combo_out_loss: 0.3292\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4217 - main_out_loss: 0.4442 - combo_out_loss: 0.3317\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4192 - main_out_loss: 0.4417 - combo_out_loss: 0.3292\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4158 - main_out_loss: 0.4383 - combo_out_loss: 0.3259\u001b[0m\n",
      "\u001b[31m 864/1557 [===============>..............] - ETA: 0s - loss: 0.4145 - main_out_loss: 0.4372 - combo_out_loss: 0.3237\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4182 - main_out_loss: 0.4413 - combo_out_loss: 0.3259\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4156 - main_out_loss: 0.4383 - combo_out_loss: 0.3251\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4174 - main_out_loss: 0.4406 - combo_out_loss: 0.3248\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4177 - main_out_loss: 0.4413 - combo_out_loss: 0.3235\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4184 - main_out_loss: 0.4422 - combo_out_loss: 0.3232\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4188 - main_out_loss: 0.4424 - combo_out_loss: 0.3245\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4182 - main_out_loss: 0.4416 - combo_out_loss: 0.3246\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4175 - main_out_loss: 0.4412 - combo_out_loss: 0.3226\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4160 - main_out_loss: 0.4393 - combo_out_loss: 0.3227\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4155 - main_out_loss: 0.4391 - combo_out_loss: 0.3210\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4169 - main_out_loss: 0.4403 - combo_out_loss: 0.3232\u001b[0m\n",
      "\u001b[31mEpoch 51/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4141 - main_out_loss: 0.4449 - combo_out_loss: 0.2906\u001b[0m\n",
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.4283 - main_out_loss: 0.4588 - combo_out_loss: 0.3064\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4043 - main_out_loss: 0.4312 - combo_out_loss: 0.2967\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.4050 - main_out_loss: 0.4286 - combo_out_loss: 0.3105\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3956 - main_out_loss: 0.4179 - combo_out_loss: 0.3063\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3997 - main_out_loss: 0.4213 - combo_out_loss: 0.3131\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3968 - main_out_loss: 0.4192 - combo_out_loss: 0.3071\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3979 - main_out_loss: 0.4207 - combo_out_loss: 0.3071\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3940 - main_out_loss: 0.4160 - combo_out_loss: 0.3062\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3956 - main_out_loss: 0.4175 - combo_out_loss: 0.3078\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3964 - main_out_loss: 0.4189 - combo_out_loss: 0.3066\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4025 - main_out_loss: 0.4259 - combo_out_loss: 0.3088\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4008 - main_out_loss: 0.4246 - combo_out_loss: 0.3058\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4036 - main_out_loss: 0.4274 - combo_out_loss: 0.3084\u001b[0m\n",
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.4001 - main_out_loss: 0.4236 - combo_out_loss: 0.3063\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3999 - main_out_loss: 0.4233 - combo_out_loss: 0.3065\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4031 - main_out_loss: 0.4264 - combo_out_loss: 0.3098\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4047 - main_out_loss: 0.4279 - combo_out_loss: 0.3116\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4066 - main_out_loss: 0.4305 - combo_out_loss: 0.3112\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4046 - main_out_loss: 0.4277 - combo_out_loss: 0.3121\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4063 - main_out_loss: 0.4297 - combo_out_loss: 0.3130\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4075 - main_out_loss: 0.4311 - combo_out_loss: 0.3131\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.4074 - main_out_loss: 0.4307 - combo_out_loss: 0.3140\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4057 - main_out_loss: 0.4290 - combo_out_loss: 0.3127\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4058 - main_out_loss: 0.4289 - combo_out_loss: 0.3137\u001b[0m\n",
      "\u001b[31mEpoch 52/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3938 - main_out_loss: 0.4176 - combo_out_loss: 0.2985\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.4291 - main_out_loss: 0.4594 - combo_out_loss: 0.3079\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.4047 - main_out_loss: 0.4331 - combo_out_loss: 0.2914\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.4055 - main_out_loss: 0.4316 - combo_out_loss: 0.3009\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.4136 - main_out_loss: 0.4416 - combo_out_loss: 0.3016\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.4102 - main_out_loss: 0.4367 - combo_out_loss: 0.3040\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.4095 - main_out_loss: 0.4366 - combo_out_loss: 0.3013\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.4129 - main_out_loss: 0.4402 - combo_out_loss: 0.3037\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.4138 - main_out_loss: 0.4416 - combo_out_loss: 0.3025\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.4152 - main_out_loss: 0.4426 - combo_out_loss: 0.3052\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.4158 - main_out_loss: 0.4421 - combo_out_loss: 0.3103\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.4119 - main_out_loss: 0.4371 - combo_out_loss: 0.3110\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.4083 - main_out_loss: 0.4334 - combo_out_loss: 0.3079\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.4044 - main_out_loss: 0.4288 - combo_out_loss: 0.3070\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.4016 - main_out_loss: 0.4260 - combo_out_loss: 0.3041\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.4032 - main_out_loss: 0.4278 - combo_out_loss: 0.3045\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.4041 - main_out_loss: 0.4287 - combo_out_loss: 0.3057\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.4017 - main_out_loss: 0.4257 - combo_out_loss: 0.3057\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.4018 - main_out_loss: 0.4251 - combo_out_loss: 0.3087\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.4020 - main_out_loss: 0.4252 - combo_out_loss: 0.3088\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.4019 - main_out_loss: 0.4249 - combo_out_loss: 0.3098\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.4010 - main_out_loss: 0.4239 - combo_out_loss: 0.3093\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3997 - main_out_loss: 0.4224 - combo_out_loss: 0.3088\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.4027 - main_out_loss: 0.4260 - combo_out_loss: 0.3097\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.4019 - main_out_loss: 0.4246 - combo_out_loss: 0.3109\u001b[0m\n",
      "\u001b[31mEpoch 53/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 2s - loss: 0.3975 - main_out_loss: 0.4117 - combo_out_loss: 0.3408\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3987 - main_out_loss: 0.4225 - combo_out_loss: 0.3033\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3966 - main_out_loss: 0.4181 - combo_out_loss: 0.3108\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3821 - main_out_loss: 0.4020 - combo_out_loss: 0.3027\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.3852 - main_out_loss: 0.4057 - combo_out_loss: 0.3032\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3853 - main_out_loss: 0.4075 - combo_out_loss: 0.2966\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3899 - main_out_loss: 0.4124 - combo_out_loss: 0.3000\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3831 - main_out_loss: 0.4049 - combo_out_loss: 0.2961\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3840 - main_out_loss: 0.4059 - combo_out_loss: 0.2961\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3859 - main_out_loss: 0.4084 - combo_out_loss: 0.2960\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3860 - main_out_loss: 0.4082 - combo_out_loss: 0.2973\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3885 - main_out_loss: 0.4106 - combo_out_loss: 0.3000\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3875 - main_out_loss: 0.4102 - combo_out_loss: 0.2971\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3881 - main_out_loss: 0.4104 - combo_out_loss: 0.2988\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3908 - main_out_loss: 0.4133 - combo_out_loss: 0.3010\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3907 - main_out_loss: 0.4130 - combo_out_loss: 0.3016\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3923 - main_out_loss: 0.4143 - combo_out_loss: 0.3041\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3901 - main_out_loss: 0.4117 - combo_out_loss: 0.3038\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3870 - main_out_loss: 0.4086 - combo_out_loss: 0.3009\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3865 - main_out_loss: 0.4080 - combo_out_loss: 0.3004\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3866 - main_out_loss: 0.4080 - combo_out_loss: 0.3009\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3859 - main_out_loss: 0.4073 - combo_out_loss: 0.3004\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3838 - main_out_loss: 0.4049 - combo_out_loss: 0.2992\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3834 - main_out_loss: 0.4042 - combo_out_loss: 0.3002\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3837 - main_out_loss: 0.4045 - combo_out_loss: 0.3003\u001b[0m\n",
      "\u001b[31mEpoch 54/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3596 - main_out_loss: 0.3798 - combo_out_loss: 0.2789\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3612 - main_out_loss: 0.3847 - combo_out_loss: 0.2673\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3575 - main_out_loss: 0.3784 - combo_out_loss: 0.2738\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3716 - main_out_loss: 0.3912 - combo_out_loss: 0.2930\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3769 - main_out_loss: 0.3982 - combo_out_loss: 0.2918\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3685 - main_out_loss: 0.3902 - combo_out_loss: 0.2817\u001b[0m\n",
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.3708 - main_out_loss: 0.3926 - combo_out_loss: 0.2837\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3814 - main_out_loss: 0.4041 - combo_out_loss: 0.2908\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3833 - main_out_loss: 0.4063 - combo_out_loss: 0.2910\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3817 - main_out_loss: 0.4044 - combo_out_loss: 0.2908\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3796 - main_out_loss: 0.4017 - combo_out_loss: 0.2913\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3779 - main_out_loss: 0.3994 - combo_out_loss: 0.2916\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3808 - main_out_loss: 0.4024 - combo_out_loss: 0.2945\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3820 - main_out_loss: 0.4036 - combo_out_loss: 0.2958\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3797 - main_out_loss: 0.4009 - combo_out_loss: 0.2951\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3792 - main_out_loss: 0.4000 - combo_out_loss: 0.2962\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3774 - main_out_loss: 0.3978 - combo_out_loss: 0.2958\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3769 - main_out_loss: 0.3974 - combo_out_loss: 0.2950\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3774 - main_out_loss: 0.3976 - combo_out_loss: 0.2964\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3778 - main_out_loss: 0.3979 - combo_out_loss: 0.2972\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3789 - main_out_loss: 0.3990 - combo_out_loss: 0.2981\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3788 - main_out_loss: 0.3989 - combo_out_loss: 0.2981\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3778 - main_out_loss: 0.3981 - combo_out_loss: 0.2970\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3769 - main_out_loss: 0.3970 - combo_out_loss: 0.2964\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3765 - main_out_loss: 0.3966 - combo_out_loss: 0.2962\u001b[0m\n",
      "\u001b[31mEpoch 55/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3726 - main_out_loss: 0.3895 - combo_out_loss: 0.3048\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3798 - main_out_loss: 0.3982 - combo_out_loss: 0.3061\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3895 - main_out_loss: 0.4108 - combo_out_loss: 0.3040\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3718 - main_out_loss: 0.3917 - combo_out_loss: 0.2920\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3780 - main_out_loss: 0.3973 - combo_out_loss: 0.3005\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3807 - main_out_loss: 0.4021 - combo_out_loss: 0.2951\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3780 - main_out_loss: 0.3995 - combo_out_loss: 0.2922\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3716 - main_out_loss: 0.3913 - combo_out_loss: 0.2926\u001b[0m\n",
      "\u001b[31m 544/1557 [=========>....................] - ETA: 1s - loss: 0.3750 - main_out_loss: 0.3953 - combo_out_loss: 0.2934\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3766 - main_out_loss: 0.3963 - combo_out_loss: 0.2979\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3731 - main_out_loss: 0.3922 - combo_out_loss: 0.2970\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3726 - main_out_loss: 0.3914 - combo_out_loss: 0.2976\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3710 - main_out_loss: 0.3895 - combo_out_loss: 0.2966\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3687 - main_out_loss: 0.3871 - combo_out_loss: 0.2952\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3685 - main_out_loss: 0.3866 - combo_out_loss: 0.2961\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3677 - main_out_loss: 0.3855 - combo_out_loss: 0.2965\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3678 - main_out_loss: 0.3856 - combo_out_loss: 0.2964\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3693 - main_out_loss: 0.3871 - combo_out_loss: 0.2982\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3700 - main_out_loss: 0.3878 - combo_out_loss: 0.2989\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3690 - main_out_loss: 0.3870 - combo_out_loss: 0.2972\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3708 - main_out_loss: 0.3889 - combo_out_loss: 0.2986\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3706 - main_out_loss: 0.3886 - combo_out_loss: 0.2985\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3694 - main_out_loss: 0.3873 - combo_out_loss: 0.2975\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3692 - main_out_loss: 0.3873 - combo_out_loss: 0.2970\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3703 - main_out_loss: 0.3883 - combo_out_loss: 0.2979\u001b[0m\n",
      "\u001b[31mEpoch 56/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3255 - main_out_loss: 0.3447 - combo_out_loss: 0.2487\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3521 - main_out_loss: 0.3726 - combo_out_loss: 0.2700\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3536 - main_out_loss: 0.3716 - combo_out_loss: 0.2816\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3573 - main_out_loss: 0.3756 - combo_out_loss: 0.2839\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3552 - main_out_loss: 0.3744 - combo_out_loss: 0.2784\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3584 - main_out_loss: 0.3778 - combo_out_loss: 0.2804\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3585 - main_out_loss: 0.3786 - combo_out_loss: 0.2783\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3633 - main_out_loss: 0.3840 - combo_out_loss: 0.2807\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3618 - main_out_loss: 0.3818 - combo_out_loss: 0.2819\u001b[0m\n",
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.3585 - main_out_loss: 0.3782 - combo_out_loss: 0.2797\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3595 - main_out_loss: 0.3786 - combo_out_loss: 0.2833\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3575 - main_out_loss: 0.3759 - combo_out_loss: 0.2839\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3576 - main_out_loss: 0.3763 - combo_out_loss: 0.2829\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3603 - main_out_loss: 0.3788 - combo_out_loss: 0.2861\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3621 - main_out_loss: 0.3809 - combo_out_loss: 0.2869\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3644 - main_out_loss: 0.3839 - combo_out_loss: 0.2867\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3623 - main_out_loss: 0.3809 - combo_out_loss: 0.2879\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3662 - main_out_loss: 0.3851 - combo_out_loss: 0.2906\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3636 - main_out_loss: 0.3821 - combo_out_loss: 0.2899\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3634 - main_out_loss: 0.3819 - combo_out_loss: 0.2896\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3620 - main_out_loss: 0.3806 - combo_out_loss: 0.2879\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3604 - main_out_loss: 0.3789 - combo_out_loss: 0.2864\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3603 - main_out_loss: 0.3789 - combo_out_loss: 0.2861\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3603 - main_out_loss: 0.3788 - combo_out_loss: 0.2861\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3607 - main_out_loss: 0.3792 - combo_out_loss: 0.2866\u001b[0m\n",
      "\u001b[31mEpoch 57/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3509 - main_out_loss: 0.3688 - combo_out_loss: 0.2791\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3922 - main_out_loss: 0.4130 - combo_out_loss: 0.3089\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3535 - main_out_loss: 0.3703 - combo_out_loss: 0.2863\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3481 - main_out_loss: 0.3642 - combo_out_loss: 0.2838\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3477 - main_out_loss: 0.3645 - combo_out_loss: 0.2803\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3449 - main_out_loss: 0.3615 - combo_out_loss: 0.2783\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3388 - main_out_loss: 0.3540 - combo_out_loss: 0.2780\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3371 - main_out_loss: 0.3524 - combo_out_loss: 0.2760\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3437 - main_out_loss: 0.3597 - combo_out_loss: 0.2797\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3479 - main_out_loss: 0.3643 - combo_out_loss: 0.2824\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3482 - main_out_loss: 0.3645 - combo_out_loss: 0.2829\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 0s - loss: 0.3499 - main_out_loss: 0.3669 - combo_out_loss: 0.2815\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3471 - main_out_loss: 0.3636 - combo_out_loss: 0.2810\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3534 - main_out_loss: 0.3704 - combo_out_loss: 0.2850\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3558 - main_out_loss: 0.3733 - combo_out_loss: 0.2860\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3544 - main_out_loss: 0.3718 - combo_out_loss: 0.2848\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3558 - main_out_loss: 0.3740 - combo_out_loss: 0.2830\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3564 - main_out_loss: 0.3746 - combo_out_loss: 0.2839\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3567 - main_out_loss: 0.3743 - combo_out_loss: 0.2865\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3568 - main_out_loss: 0.3742 - combo_out_loss: 0.2871\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3562 - main_out_loss: 0.3734 - combo_out_loss: 0.2873\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3560 - main_out_loss: 0.3731 - combo_out_loss: 0.2873\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3539 - main_out_loss: 0.3708 - combo_out_loss: 0.2863\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3537 - main_out_loss: 0.3707 - combo_out_loss: 0.2860\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3523 - main_out_loss: 0.3692 - combo_out_loss: 0.2846\u001b[0m\n",
      "\u001b[31mEpoch 58/100\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.3352 - main_out_loss: 0.3524 - combo_out_loss: 0.2662\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3478 - main_out_loss: 0.3691 - combo_out_loss: 0.2627\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3529 - main_out_loss: 0.3751 - combo_out_loss: 0.2642\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3689 - main_out_loss: 0.3911 - combo_out_loss: 0.2804\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3782 - main_out_loss: 0.4001 - combo_out_loss: 0.2908\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3714 - main_out_loss: 0.3921 - combo_out_loss: 0.2885\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3667 - main_out_loss: 0.3866 - combo_out_loss: 0.2871\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3623 - main_out_loss: 0.3821 - combo_out_loss: 0.2833\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3612 - main_out_loss: 0.3809 - combo_out_loss: 0.2823\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3630 - main_out_loss: 0.3819 - combo_out_loss: 0.2875\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3606 - main_out_loss: 0.3792 - combo_out_loss: 0.2866\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3590 - main_out_loss: 0.3772 - combo_out_loss: 0.2860\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.3558 - main_out_loss: 0.3736 - combo_out_loss: 0.2845\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3549 - main_out_loss: 0.3720 - combo_out_loss: 0.2865\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3534 - main_out_loss: 0.3706 - combo_out_loss: 0.2848\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3547 - main_out_loss: 0.3720 - combo_out_loss: 0.2854\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3515 - main_out_loss: 0.3683 - combo_out_loss: 0.2845\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3501 - main_out_loss: 0.3666 - combo_out_loss: 0.2839\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3493 - main_out_loss: 0.3659 - combo_out_loss: 0.2831\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3532 - main_out_loss: 0.3698 - combo_out_loss: 0.2866\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3542 - main_out_loss: 0.3706 - combo_out_loss: 0.2884\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3558 - main_out_loss: 0.3723 - combo_out_loss: 0.2900\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3550 - main_out_loss: 0.3715 - combo_out_loss: 0.2888\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3546 - main_out_loss: 0.3710 - combo_out_loss: 0.2890\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3550 - main_out_loss: 0.3717 - combo_out_loss: 0.2883\u001b[0m\n",
      "\u001b[31mEpoch 59/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3595 - main_out_loss: 0.3837 - combo_out_loss: 0.2626\u001b[0m\n",
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.3454 - main_out_loss: 0.3638 - combo_out_loss: 0.2718\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3461 - main_out_loss: 0.3664 - combo_out_loss: 0.2646\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3436 - main_out_loss: 0.3633 - combo_out_loss: 0.2649\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3412 - main_out_loss: 0.3614 - combo_out_loss: 0.2601\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3363 - main_out_loss: 0.3543 - combo_out_loss: 0.2642\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3386 - main_out_loss: 0.3562 - combo_out_loss: 0.2680\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3395 - main_out_loss: 0.3567 - combo_out_loss: 0.2710\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3348 - main_out_loss: 0.3517 - combo_out_loss: 0.2671\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3320 - main_out_loss: 0.3488 - combo_out_loss: 0.2644\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3389 - main_out_loss: 0.3562 - combo_out_loss: 0.2698\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3408 - main_out_loss: 0.3580 - combo_out_loss: 0.2718\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3395 - main_out_loss: 0.3556 - combo_out_loss: 0.2748\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3373 - main_out_loss: 0.3532 - combo_out_loss: 0.2733\u001b[0m\n",
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.3395 - main_out_loss: 0.3553 - combo_out_loss: 0.2763\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3423 - main_out_loss: 0.3582 - combo_out_loss: 0.2789\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3434 - main_out_loss: 0.3592 - combo_out_loss: 0.2801\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3428 - main_out_loss: 0.3584 - combo_out_loss: 0.2805\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3448 - main_out_loss: 0.3603 - combo_out_loss: 0.2825\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3432 - main_out_loss: 0.3587 - combo_out_loss: 0.2813\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3434 - main_out_loss: 0.3586 - combo_out_loss: 0.2829\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3427 - main_out_loss: 0.3574 - combo_out_loss: 0.2840\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3431 - main_out_loss: 0.3578 - combo_out_loss: 0.2842\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3447 - main_out_loss: 0.3598 - combo_out_loss: 0.2840\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3442 - main_out_loss: 0.3593 - combo_out_loss: 0.2842\u001b[0m\n",
      "\u001b[31mEpoch 60/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3658 - main_out_loss: 0.3954 - combo_out_loss: 0.2477\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3432 - main_out_loss: 0.3660 - combo_out_loss: 0.2521\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3457 - main_out_loss: 0.3661 - combo_out_loss: 0.2639\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.3561 - main_out_loss: 0.3747 - combo_out_loss: 0.2818\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3570 - main_out_loss: 0.3756 - combo_out_loss: 0.2826\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3620 - main_out_loss: 0.3806 - combo_out_loss: 0.2878\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3606 - main_out_loss: 0.3777 - combo_out_loss: 0.2921\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3569 - main_out_loss: 0.3731 - combo_out_loss: 0.2922\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3479 - main_out_loss: 0.3632 - combo_out_loss: 0.2866\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3457 - main_out_loss: 0.3605 - combo_out_loss: 0.2866\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3421 - main_out_loss: 0.3561 - combo_out_loss: 0.2860\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3400 - main_out_loss: 0.3540 - combo_out_loss: 0.2840\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3382 - main_out_loss: 0.3524 - combo_out_loss: 0.2813\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3391 - main_out_loss: 0.3530 - combo_out_loss: 0.2835\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3382 - main_out_loss: 0.3524 - combo_out_loss: 0.2811\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3387 - main_out_loss: 0.3534 - combo_out_loss: 0.2803\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3388 - main_out_loss: 0.3533 - combo_out_loss: 0.2808\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3369 - main_out_loss: 0.3515 - combo_out_loss: 0.2788\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3377 - main_out_loss: 0.3521 - combo_out_loss: 0.2798\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3366 - main_out_loss: 0.3511 - combo_out_loss: 0.2787\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3358 - main_out_loss: 0.3503 - combo_out_loss: 0.2778\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3373 - main_out_loss: 0.3523 - combo_out_loss: 0.2775\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3364 - main_out_loss: 0.3514 - combo_out_loss: 0.2764\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3365 - main_out_loss: 0.3518 - combo_out_loss: 0.2752\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3360 - main_out_loss: 0.3512 - combo_out_loss: 0.2754\u001b[0m\n",
      "\u001b[31mEpoch 61/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3404 - main_out_loss: 0.3517 - combo_out_loss: 0.2949\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3689 - main_out_loss: 0.3907 - combo_out_loss: 0.2820\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3622 - main_out_loss: 0.3828 - combo_out_loss: 0.2798\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3623 - main_out_loss: 0.3814 - combo_out_loss: 0.2858\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.3519 - main_out_loss: 0.3683 - combo_out_loss: 0.2863\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3378 - main_out_loss: 0.3528 - combo_out_loss: 0.2774\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3284 - main_out_loss: 0.3431 - combo_out_loss: 0.2695\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3300 - main_out_loss: 0.3449 - combo_out_loss: 0.2706\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3307 - main_out_loss: 0.3457 - combo_out_loss: 0.2709\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3283 - main_out_loss: 0.3429 - combo_out_loss: 0.2698\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3297 - main_out_loss: 0.3443 - combo_out_loss: 0.2714\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3289 - main_out_loss: 0.3439 - combo_out_loss: 0.2687\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3293 - main_out_loss: 0.3442 - combo_out_loss: 0.2694\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3286 - main_out_loss: 0.3436 - combo_out_loss: 0.2686\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3260 - main_out_loss: 0.3411 - combo_out_loss: 0.2652\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3237 - main_out_loss: 0.3387 - combo_out_loss: 0.2636\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3236 - main_out_loss: 0.3384 - combo_out_loss: 0.2640\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3249 - main_out_loss: 0.3399 - combo_out_loss: 0.2651\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3240 - main_out_loss: 0.3387 - combo_out_loss: 0.2654\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3235 - main_out_loss: 0.3380 - combo_out_loss: 0.2657\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3232 - main_out_loss: 0.3375 - combo_out_loss: 0.2657\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3240 - main_out_loss: 0.3386 - combo_out_loss: 0.2656\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3240 - main_out_loss: 0.3383 - combo_out_loss: 0.2665\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3231 - main_out_loss: 0.3376 - combo_out_loss: 0.2652\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3231 - main_out_loss: 0.3373 - combo_out_loss: 0.2664\u001b[0m\n",
      "\u001b[31mEpoch 62/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3545 - main_out_loss: 0.3686 - combo_out_loss: 0.2978\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3293 - main_out_loss: 0.3436 - combo_out_loss: 0.2723\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3101 - main_out_loss: 0.3216 - combo_out_loss: 0.2643\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2992 - main_out_loss: 0.3107 - combo_out_loss: 0.2531\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3031 - main_out_loss: 0.3159 - combo_out_loss: 0.2522\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3063 - main_out_loss: 0.3201 - combo_out_loss: 0.2510\u001b[0m\n",
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.3100 - main_out_loss: 0.3242 - combo_out_loss: 0.2535\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3183 - main_out_loss: 0.3331 - combo_out_loss: 0.2589\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3191 - main_out_loss: 0.3334 - combo_out_loss: 0.2620\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3189 - main_out_loss: 0.3330 - combo_out_loss: 0.2626\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3203 - main_out_loss: 0.3344 - combo_out_loss: 0.2637\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3185 - main_out_loss: 0.3325 - combo_out_loss: 0.2623\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3179 - main_out_loss: 0.3322 - combo_out_loss: 0.2610\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3169 - main_out_loss: 0.3309 - combo_out_loss: 0.2606\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3182 - main_out_loss: 0.3317 - combo_out_loss: 0.2640\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3178 - main_out_loss: 0.3310 - combo_out_loss: 0.2650\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3179 - main_out_loss: 0.3315 - combo_out_loss: 0.2635\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3186 - main_out_loss: 0.3323 - combo_out_loss: 0.2640\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3212 - main_out_loss: 0.3350 - combo_out_loss: 0.2659\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3205 - main_out_loss: 0.3338 - combo_out_loss: 0.2673\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3220 - main_out_loss: 0.3356 - combo_out_loss: 0.2675\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3217 - main_out_loss: 0.3351 - combo_out_loss: 0.2680\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3222 - main_out_loss: 0.3355 - combo_out_loss: 0.2690\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3217 - main_out_loss: 0.3346 - combo_out_loss: 0.2704\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3200 - main_out_loss: 0.3327 - combo_out_loss: 0.2693\u001b[0m\n",
      "\u001b[31mEpoch 63/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2856 - main_out_loss: 0.2984 - combo_out_loss: 0.2342\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3209 - main_out_loss: 0.3363 - combo_out_loss: 0.2594\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3329 - main_out_loss: 0.3490 - combo_out_loss: 0.2684\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3256 - main_out_loss: 0.3393 - combo_out_loss: 0.2707\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3301 - main_out_loss: 0.3445 - combo_out_loss: 0.2723\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3341 - main_out_loss: 0.3496 - combo_out_loss: 0.2723\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3297 - main_out_loss: 0.3448 - combo_out_loss: 0.2696\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3275 - main_out_loss: 0.3419 - combo_out_loss: 0.2700\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 544/1557 [=========>....................] - ETA: 1s - loss: 0.3266 - main_out_loss: 0.3414 - combo_out_loss: 0.2673\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3214 - main_out_loss: 0.3353 - combo_out_loss: 0.2656\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3166 - main_out_loss: 0.3301 - combo_out_loss: 0.2625\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3152 - main_out_loss: 0.3285 - combo_out_loss: 0.2620\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3180 - main_out_loss: 0.3317 - combo_out_loss: 0.2630\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3173 - main_out_loss: 0.3305 - combo_out_loss: 0.2643\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.3174 - main_out_loss: 0.3305 - combo_out_loss: 0.2653\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.3205 - main_out_loss: 0.3340 - combo_out_loss: 0.2668\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.3205 - main_out_loss: 0.3336 - combo_out_loss: 0.2680\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3176 - main_out_loss: 0.3308 - combo_out_loss: 0.2648\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3188 - main_out_loss: 0.3321 - combo_out_loss: 0.2658\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3195 - main_out_loss: 0.3328 - combo_out_loss: 0.2664\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3203 - main_out_loss: 0.3334 - combo_out_loss: 0.2676\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3198 - main_out_loss: 0.3327 - combo_out_loss: 0.2681\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3182 - main_out_loss: 0.3310 - combo_out_loss: 0.2674\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3184 - main_out_loss: 0.3313 - combo_out_loss: 0.2670\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3180 - main_out_loss: 0.3309 - combo_out_loss: 0.2661\u001b[0m\n",
      "\u001b[31mEpoch 64/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3111 - main_out_loss: 0.3305 - combo_out_loss: 0.2336\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2877 - main_out_loss: 0.3019 - combo_out_loss: 0.2310\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2948 - main_out_loss: 0.3071 - combo_out_loss: 0.2458\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3028 - main_out_loss: 0.3130 - combo_out_loss: 0.2621\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2959 - main_out_loss: 0.3055 - combo_out_loss: 0.2572\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2929 - main_out_loss: 0.3034 - combo_out_loss: 0.2512\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2923 - main_out_loss: 0.3029 - combo_out_loss: 0.2496\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2940 - main_out_loss: 0.3052 - combo_out_loss: 0.2490\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2969 - main_out_loss: 0.3082 - combo_out_loss: 0.2517\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2990 - main_out_loss: 0.3108 - combo_out_loss: 0.2516\u001b[0m\n",
      "\u001b[31m 672/1557 [===========>..................] - ETA: 1s - loss: 0.2979 - main_out_loss: 0.3098 - combo_out_loss: 0.2504\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2989 - main_out_loss: 0.3109 - combo_out_loss: 0.2511\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2961 - main_out_loss: 0.3077 - combo_out_loss: 0.2498\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2976 - main_out_loss: 0.3096 - combo_out_loss: 0.2498\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2986 - main_out_loss: 0.3108 - combo_out_loss: 0.2496\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2983 - main_out_loss: 0.3101 - combo_out_loss: 0.2513\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2990 - main_out_loss: 0.3112 - combo_out_loss: 0.2506\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3009 - main_out_loss: 0.3126 - combo_out_loss: 0.2538\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.3038 - main_out_loss: 0.3161 - combo_out_loss: 0.2546\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3045 - main_out_loss: 0.3161 - combo_out_loss: 0.2583\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.3035 - main_out_loss: 0.3150 - combo_out_loss: 0.2573\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3044 - main_out_loss: 0.3159 - combo_out_loss: 0.2582\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.3046 - main_out_loss: 0.3161 - combo_out_loss: 0.2586\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.3057 - main_out_loss: 0.3175 - combo_out_loss: 0.2586\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.3056 - main_out_loss: 0.3171 - combo_out_loss: 0.2593\u001b[0m\n",
      "\u001b[31mEpoch 65/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2851 - main_out_loss: 0.2904 - combo_out_loss: 0.2643\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2814 - main_out_loss: 0.2922 - combo_out_loss: 0.2382\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2923 - main_out_loss: 0.3019 - combo_out_loss: 0.2540\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2899 - main_out_loss: 0.2955 - combo_out_loss: 0.2677\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3013 - main_out_loss: 0.3098 - combo_out_loss: 0.2672\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3005 - main_out_loss: 0.3101 - combo_out_loss: 0.2619\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3047 - main_out_loss: 0.3142 - combo_out_loss: 0.2665\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3138 - main_out_loss: 0.3242 - combo_out_loss: 0.2722\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3078 - main_out_loss: 0.3174 - combo_out_loss: 0.2694\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3038 - main_out_loss: 0.3133 - combo_out_loss: 0.2655\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3015 - main_out_loss: 0.3109 - combo_out_loss: 0.2638\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 0s - loss: 0.3012 - main_out_loss: 0.3108 - combo_out_loss: 0.2626\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2984 - main_out_loss: 0.3085 - combo_out_loss: 0.2581\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3002 - main_out_loss: 0.3103 - combo_out_loss: 0.2601\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2979 - main_out_loss: 0.3078 - combo_out_loss: 0.2587\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2993 - main_out_loss: 0.3092 - combo_out_loss: 0.2598\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2973 - main_out_loss: 0.3072 - combo_out_loss: 0.2580\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.3005 - main_out_loss: 0.3108 - combo_out_loss: 0.2596\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2996 - main_out_loss: 0.3097 - combo_out_loss: 0.2594\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.3002 - main_out_loss: 0.3102 - combo_out_loss: 0.2602\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2989 - main_out_loss: 0.3083 - combo_out_loss: 0.2615\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.3001 - main_out_loss: 0.3097 - combo_out_loss: 0.2617\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2991 - main_out_loss: 0.3085 - combo_out_loss: 0.2616\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2989 - main_out_loss: 0.3084 - combo_out_loss: 0.2608\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2990 - main_out_loss: 0.3087 - combo_out_loss: 0.2604\u001b[0m\n",
      "\u001b[31mEpoch 66/100\n",
      "\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.2538 - main_out_loss: 0.2717 - combo_out_loss: 0.1820\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2700 - main_out_loss: 0.2859 - combo_out_loss: 0.2068\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2764 - main_out_loss: 0.2923 - combo_out_loss: 0.2126\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2725 - main_out_loss: 0.2841 - combo_out_loss: 0.2262\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2692 - main_out_loss: 0.2792 - combo_out_loss: 0.2290\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2678 - main_out_loss: 0.2762 - combo_out_loss: 0.2345\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2729 - main_out_loss: 0.2821 - combo_out_loss: 0.2359\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2750 - main_out_loss: 0.2844 - combo_out_loss: 0.2373\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2800 - main_out_loss: 0.2885 - combo_out_loss: 0.2459\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2830 - main_out_loss: 0.2925 - combo_out_loss: 0.2449\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2845 - main_out_loss: 0.2936 - combo_out_loss: 0.2478\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2895 - main_out_loss: 0.2990 - combo_out_loss: 0.2512\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2921 - main_out_loss: 0.3021 - combo_out_loss: 0.2522\u001b[0m\n",
      "\u001b[31m 864/1557 [===============>..............] - ETA: 0s - loss: 0.2972 - main_out_loss: 0.3074 - combo_out_loss: 0.2562\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2946 - main_out_loss: 0.3049 - combo_out_loss: 0.2531\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2917 - main_out_loss: 0.3015 - combo_out_loss: 0.2525\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2903 - main_out_loss: 0.2992 - combo_out_loss: 0.2547\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2903 - main_out_loss: 0.2995 - combo_out_loss: 0.2537\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2908 - main_out_loss: 0.2999 - combo_out_loss: 0.2544\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2915 - main_out_loss: 0.3008 - combo_out_loss: 0.2544\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2928 - main_out_loss: 0.3020 - combo_out_loss: 0.2561\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2934 - main_out_loss: 0.3028 - combo_out_loss: 0.2557\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2947 - main_out_loss: 0.3043 - combo_out_loss: 0.2562\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2943 - main_out_loss: 0.3040 - combo_out_loss: 0.2557\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2954 - main_out_loss: 0.3052 - combo_out_loss: 0.2564\u001b[0m\n",
      "\u001b[31mEpoch 67/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.4676 - main_out_loss: 0.4960 - combo_out_loss: 0.3542\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3311 - main_out_loss: 0.3478 - combo_out_loss: 0.2643\u001b[0m\n",
      "\u001b[31m 160/1557 [==>...........................] - ETA: 1s - loss: 0.3129 - main_out_loss: 0.3281 - combo_out_loss: 0.2520\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.3065 - main_out_loss: 0.3202 - combo_out_loss: 0.2517\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.3060 - main_out_loss: 0.3186 - combo_out_loss: 0.2555\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.3090 - main_out_loss: 0.3219 - combo_out_loss: 0.2574\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.3105 - main_out_loss: 0.3229 - combo_out_loss: 0.2606\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.3088 - main_out_loss: 0.3205 - combo_out_loss: 0.2622\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.3026 - main_out_loss: 0.3133 - combo_out_loss: 0.2597\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.3015 - main_out_loss: 0.3122 - combo_out_loss: 0.2588\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.3088 - main_out_loss: 0.3201 - combo_out_loss: 0.2634\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.3066 - main_out_loss: 0.3177 - combo_out_loss: 0.2622\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.3030 - main_out_loss: 0.3141 - combo_out_loss: 0.2587\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.3007 - main_out_loss: 0.3110 - combo_out_loss: 0.2592\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2983 - main_out_loss: 0.3086 - combo_out_loss: 0.2574\u001b[0m\n",
      "\u001b[31m 992/1557 [==================>...........] - ETA: 0s - loss: 0.2989 - main_out_loss: 0.3090 - combo_out_loss: 0.2584\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2995 - main_out_loss: 0.3100 - combo_out_loss: 0.2576\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2987 - main_out_loss: 0.3089 - combo_out_loss: 0.2580\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2949 - main_out_loss: 0.3044 - combo_out_loss: 0.2570\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2955 - main_out_loss: 0.3046 - combo_out_loss: 0.2589\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2954 - main_out_loss: 0.3045 - combo_out_loss: 0.2591\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2955 - main_out_loss: 0.3048 - combo_out_loss: 0.2579\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2956 - main_out_loss: 0.3051 - combo_out_loss: 0.2575\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2960 - main_out_loss: 0.3056 - combo_out_loss: 0.2577\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2955 - main_out_loss: 0.3052 - combo_out_loss: 0.2565\u001b[0m\n",
      "\u001b[31mEpoch 68/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2256 - main_out_loss: 0.2239 - combo_out_loss: 0.2323\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2543 - main_out_loss: 0.2598 - combo_out_loss: 0.2321\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2917 - main_out_loss: 0.3000 - combo_out_loss: 0.2585\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.2926 - main_out_loss: 0.2993 - combo_out_loss: 0.2657\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2905 - main_out_loss: 0.2957 - combo_out_loss: 0.2696\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2847 - main_out_loss: 0.2915 - combo_out_loss: 0.2573\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2899 - main_out_loss: 0.2977 - combo_out_loss: 0.2586\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2932 - main_out_loss: 0.3014 - combo_out_loss: 0.2604\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2909 - main_out_loss: 0.2992 - combo_out_loss: 0.2576\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2933 - main_out_loss: 0.3029 - combo_out_loss: 0.2552\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2915 - main_out_loss: 0.3010 - combo_out_loss: 0.2536\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2885 - main_out_loss: 0.2979 - combo_out_loss: 0.2511\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2906 - main_out_loss: 0.2998 - combo_out_loss: 0.2538\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2904 - main_out_loss: 0.2994 - combo_out_loss: 0.2541\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2882 - main_out_loss: 0.2969 - combo_out_loss: 0.2532\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2859 - main_out_loss: 0.2941 - combo_out_loss: 0.2530\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2899 - main_out_loss: 0.2987 - combo_out_loss: 0.2549\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2907 - main_out_loss: 0.2994 - combo_out_loss: 0.2561\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2913 - main_out_loss: 0.3003 - combo_out_loss: 0.2553\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2900 - main_out_loss: 0.2988 - combo_out_loss: 0.2549\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2902 - main_out_loss: 0.2990 - combo_out_loss: 0.2550\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2890 - main_out_loss: 0.2978 - combo_out_loss: 0.2535\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2881 - main_out_loss: 0.2970 - combo_out_loss: 0.2527\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2898 - main_out_loss: 0.2988 - combo_out_loss: 0.2536\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2917 - main_out_loss: 0.3010 - combo_out_loss: 0.2541\u001b[0m\n",
      "\u001b[31mEpoch 69/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 2s - loss: 0.2967 - main_out_loss: 0.3147 - combo_out_loss: 0.2249\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2990 - main_out_loss: 0.3167 - combo_out_loss: 0.2281\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2769 - main_out_loss: 0.2894 - combo_out_loss: 0.2272\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2785 - main_out_loss: 0.2876 - combo_out_loss: 0.2419\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2902 - main_out_loss: 0.2984 - combo_out_loss: 0.2574\u001b[0m\n",
      "\u001b[31m 352/1557 [=====>........................] - ETA: 1s - loss: 0.2864 - main_out_loss: 0.2953 - combo_out_loss: 0.2508\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2871 - main_out_loss: 0.2953 - combo_out_loss: 0.2541\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2869 - main_out_loss: 0.2951 - combo_out_loss: 0.2543\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2859 - main_out_loss: 0.2938 - combo_out_loss: 0.2541\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2825 - main_out_loss: 0.2900 - combo_out_loss: 0.2525\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2829 - main_out_loss: 0.2904 - combo_out_loss: 0.2532\n",
      " 736/1557 [=============>................] - ETA: 1s - loss: 0.2838 - main_out_loss: 0.2903 - combo_out_loss: 0.2582\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2858 - main_out_loss: 0.2918 - combo_out_loss: 0.2618\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2863 - main_out_loss: 0.2931 - combo_out_loss: 0.2594\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2863 - main_out_loss: 0.2936 - combo_out_loss: 0.2571\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2860 - main_out_loss: 0.2942 - combo_out_loss: 0.2533\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2835 - main_out_loss: 0.2919 - combo_out_loss: 0.2497\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2839 - main_out_loss: 0.2923 - combo_out_loss: 0.2500\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2839 - main_out_loss: 0.2919 - combo_out_loss: 0.2518\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2827 - main_out_loss: 0.2909 - combo_out_loss: 0.2503\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2851 - main_out_loss: 0.2934 - combo_out_loss: 0.2521\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2877 - main_out_loss: 0.2962 - combo_out_loss: 0.2536\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2863 - main_out_loss: 0.2951 - combo_out_loss: 0.2515\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2862 - main_out_loss: 0.2950 - combo_out_loss: 0.2509\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2865 - main_out_loss: 0.2953 - combo_out_loss: 0.2510\u001b[0m\n",
      "\u001b[31mEpoch 70/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2906 - main_out_loss: 0.3030 - combo_out_loss: 0.2412\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2723 - main_out_loss: 0.2763 - combo_out_loss: 0.2564\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2751 - main_out_loss: 0.2818 - combo_out_loss: 0.2481\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2697 - main_out_loss: 0.2752 - combo_out_loss: 0.2474\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2715 - main_out_loss: 0.2775 - combo_out_loss: 0.2474\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2748 - main_out_loss: 0.2819 - combo_out_loss: 0.2465\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2759 - main_out_loss: 0.2838 - combo_out_loss: 0.2442\u001b[0m\n",
      "\u001b[31m 480/1557 [========>.....................] - ETA: 1s - loss: 0.2762 - main_out_loss: 0.2841 - combo_out_loss: 0.2447\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2759 - main_out_loss: 0.2827 - combo_out_loss: 0.2487\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2789 - main_out_loss: 0.2854 - combo_out_loss: 0.2530\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2820 - main_out_loss: 0.2893 - combo_out_loss: 0.2530\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2805 - main_out_loss: 0.2881 - combo_out_loss: 0.2501\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2801 - main_out_loss: 0.2877 - combo_out_loss: 0.2497\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2781 - main_out_loss: 0.2857 - combo_out_loss: 0.2481\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2751 - main_out_loss: 0.2824 - combo_out_loss: 0.2457\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2734 - main_out_loss: 0.2808 - combo_out_loss: 0.2442\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2719 - main_out_loss: 0.2793 - combo_out_loss: 0.2421\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2753 - main_out_loss: 0.2830 - combo_out_loss: 0.2443\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2760 - main_out_loss: 0.2837 - combo_out_loss: 0.2455\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2762 - main_out_loss: 0.2837 - combo_out_loss: 0.2462\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2755 - main_out_loss: 0.2833 - combo_out_loss: 0.2446\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2783 - main_out_loss: 0.2864 - combo_out_loss: 0.2458\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2778 - main_out_loss: 0.2861 - combo_out_loss: 0.2449\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2780 - main_out_loss: 0.2862 - combo_out_loss: 0.2452\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2778 - main_out_loss: 0.2856 - combo_out_loss: 0.2464\u001b[0m\n",
      "\u001b[31mEpoch 71/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2619 - main_out_loss: 0.2652 - combo_out_loss: 0.2487\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.3041 - main_out_loss: 0.3148 - combo_out_loss: 0.2612\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.3197 - main_out_loss: 0.3340 - combo_out_loss: 0.2623\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2960 - main_out_loss: 0.3075 - combo_out_loss: 0.2498\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2828 - main_out_loss: 0.2932 - combo_out_loss: 0.2412\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2729 - main_out_loss: 0.2817 - combo_out_loss: 0.2377\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2781 - main_out_loss: 0.2875 - combo_out_loss: 0.2402\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2882 - main_out_loss: 0.2983 - combo_out_loss: 0.2475\u001b[0m\n",
      "\u001b[31m 544/1557 [=========>....................] - ETA: 1s - loss: 0.2897 - main_out_loss: 0.3001 - combo_out_loss: 0.2482\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2824 - main_out_loss: 0.2921 - combo_out_loss: 0.2435\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2825 - main_out_loss: 0.2916 - combo_out_loss: 0.2464\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2803 - main_out_loss: 0.2889 - combo_out_loss: 0.2460\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2816 - main_out_loss: 0.2894 - combo_out_loss: 0.2503\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2875 - main_out_loss: 0.2958 - combo_out_loss: 0.2545\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2899 - main_out_loss: 0.2986 - combo_out_loss: 0.2553\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2884 - main_out_loss: 0.2970 - combo_out_loss: 0.2540\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2858 - main_out_loss: 0.2942 - combo_out_loss: 0.2521\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2859 - main_out_loss: 0.2944 - combo_out_loss: 0.2519\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2867 - main_out_loss: 0.2955 - combo_out_loss: 0.2513\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2876 - main_out_loss: 0.2967 - combo_out_loss: 0.2513\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2867 - main_out_loss: 0.2956 - combo_out_loss: 0.2511\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2869 - main_out_loss: 0.2956 - combo_out_loss: 0.2519\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2857 - main_out_loss: 0.2942 - combo_out_loss: 0.2513\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2852 - main_out_loss: 0.2937 - combo_out_loss: 0.2509\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2843 - main_out_loss: 0.2928 - combo_out_loss: 0.2503\u001b[0m\n",
      "\u001b[31mEpoch 72/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2840 - main_out_loss: 0.3020 - combo_out_loss: 0.2121\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2670 - main_out_loss: 0.2781 - combo_out_loss: 0.2228\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2671 - main_out_loss: 0.2767 - combo_out_loss: 0.2287\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2729 - main_out_loss: 0.2841 - combo_out_loss: 0.2282\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2785 - main_out_loss: 0.2901 - combo_out_loss: 0.2319\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2721 - main_out_loss: 0.2824 - combo_out_loss: 0.2311\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2735 - main_out_loss: 0.2833 - combo_out_loss: 0.2344\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2749 - main_out_loss: 0.2845 - combo_out_loss: 0.2369\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2777 - main_out_loss: 0.2874 - combo_out_loss: 0.2388\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2756 - main_out_loss: 0.2854 - combo_out_loss: 0.2363\u001b[0m\n",
      "\u001b[31m 672/1557 [===========>..................] - ETA: 1s - loss: 0.2770 - main_out_loss: 0.2868 - combo_out_loss: 0.2382\n",
      " 736/1557 [=============>................] - ETA: 1s - loss: 0.2775 - main_out_loss: 0.2869 - combo_out_loss: 0.2398\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2793 - main_out_loss: 0.2888 - combo_out_loss: 0.2413\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2778 - main_out_loss: 0.2872 - combo_out_loss: 0.2405\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2774 - main_out_loss: 0.2865 - combo_out_loss: 0.2411\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2762 - main_out_loss: 0.2852 - combo_out_loss: 0.2403\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2745 - main_out_loss: 0.2832 - combo_out_loss: 0.2400\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2737 - main_out_loss: 0.2822 - combo_out_loss: 0.2395\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2748 - main_out_loss: 0.2831 - combo_out_loss: 0.2414\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2749 - main_out_loss: 0.2829 - combo_out_loss: 0.2431\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2747 - main_out_loss: 0.2828 - combo_out_loss: 0.2424\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2727 - main_out_loss: 0.2806 - combo_out_loss: 0.2413\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2755 - main_out_loss: 0.2834 - combo_out_loss: 0.2443\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2751 - main_out_loss: 0.2828 - combo_out_loss: 0.2445\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2738 - main_out_loss: 0.2812 - combo_out_loss: 0.2439\u001b[0m\n",
      "\u001b[31mEpoch 73/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2991 - main_out_loss: 0.3086 - combo_out_loss: 0.2607\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2750 - main_out_loss: 0.2835 - combo_out_loss: 0.2411\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2725 - main_out_loss: 0.2807 - combo_out_loss: 0.2394\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2762 - main_out_loss: 0.2837 - combo_out_loss: 0.2463\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2777 - main_out_loss: 0.2854 - combo_out_loss: 0.2470\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2799 - main_out_loss: 0.2867 - combo_out_loss: 0.2525\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2797 - main_out_loss: 0.2869 - combo_out_loss: 0.2511\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2769 - main_out_loss: 0.2841 - combo_out_loss: 0.2478\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2789 - main_out_loss: 0.2857 - combo_out_loss: 0.2513\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2769 - main_out_loss: 0.2840 - combo_out_loss: 0.2486\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2721 - main_out_loss: 0.2786 - combo_out_loss: 0.2459\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2752 - main_out_loss: 0.2821 - combo_out_loss: 0.2476\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.2790 - main_out_loss: 0.2864 - combo_out_loss: 0.2495\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2803 - main_out_loss: 0.2880 - combo_out_loss: 0.2494\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2767 - main_out_loss: 0.2842 - combo_out_loss: 0.2467\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2752 - main_out_loss: 0.2829 - combo_out_loss: 0.2443\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2738 - main_out_loss: 0.2816 - combo_out_loss: 0.2427\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2755 - main_out_loss: 0.2834 - combo_out_loss: 0.2435\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2743 - main_out_loss: 0.2819 - combo_out_loss: 0.2441\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2741 - main_out_loss: 0.2816 - combo_out_loss: 0.2443\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2726 - main_out_loss: 0.2799 - combo_out_loss: 0.2431\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2722 - main_out_loss: 0.2798 - combo_out_loss: 0.2420\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2735 - main_out_loss: 0.2811 - combo_out_loss: 0.2428\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2737 - main_out_loss: 0.2816 - combo_out_loss: 0.2421\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2725 - main_out_loss: 0.2802 - combo_out_loss: 0.2415\u001b[0m\n",
      "\u001b[31mEpoch 74/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2250 - main_out_loss: 0.2199 - combo_out_loss: 0.2453\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.2622 - main_out_loss: 0.2657 - combo_out_loss: 0.2481\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2636 - main_out_loss: 0.2688 - combo_out_loss: 0.2430\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2653 - main_out_loss: 0.2710 - combo_out_loss: 0.2424\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2724 - main_out_loss: 0.2799 - combo_out_loss: 0.2426\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2709 - main_out_loss: 0.2806 - combo_out_loss: 0.2322\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2666 - main_out_loss: 0.2760 - combo_out_loss: 0.2291\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2664 - main_out_loss: 0.2737 - combo_out_loss: 0.2372\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2646 - main_out_loss: 0.2717 - combo_out_loss: 0.2363\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2603 - main_out_loss: 0.2665 - combo_out_loss: 0.2352\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2603 - main_out_loss: 0.2664 - combo_out_loss: 0.2359\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2605 - main_out_loss: 0.2664 - combo_out_loss: 0.2369\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2592 - main_out_loss: 0.2650 - combo_out_loss: 0.2358\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2624 - main_out_loss: 0.2685 - combo_out_loss: 0.2380\u001b[0m\n",
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.2596 - main_out_loss: 0.2661 - combo_out_loss: 0.2337\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2588 - main_out_loss: 0.2649 - combo_out_loss: 0.2342\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2593 - main_out_loss: 0.2657 - combo_out_loss: 0.2339\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2603 - main_out_loss: 0.2667 - combo_out_loss: 0.2351\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2599 - main_out_loss: 0.2660 - combo_out_loss: 0.2354\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2603 - main_out_loss: 0.2664 - combo_out_loss: 0.2359\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2602 - main_out_loss: 0.2661 - combo_out_loss: 0.2366\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2607 - main_out_loss: 0.2668 - combo_out_loss: 0.2366\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2610 - main_out_loss: 0.2672 - combo_out_loss: 0.2363\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2601 - main_out_loss: 0.2662 - combo_out_loss: 0.2360\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2621 - main_out_loss: 0.2682 - combo_out_loss: 0.2375\u001b[0m\n",
      "\u001b[31mEpoch 75/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2637 - main_out_loss: 0.2650 - combo_out_loss: 0.2584\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2638 - main_out_loss: 0.2664 - combo_out_loss: 0.2536\u001b[0m\n",
      "\u001b[31m 160/1557 [==>...........................] - ETA: 1s - loss: 0.2675 - main_out_loss: 0.2752 - combo_out_loss: 0.2366\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2668 - main_out_loss: 0.2725 - combo_out_loss: 0.2440\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2768 - main_out_loss: 0.2841 - combo_out_loss: 0.2477\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2862 - main_out_loss: 0.2933 - combo_out_loss: 0.2579\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2815 - main_out_loss: 0.2880 - combo_out_loss: 0.2551\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2822 - main_out_loss: 0.2900 - combo_out_loss: 0.2509\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2824 - main_out_loss: 0.2904 - combo_out_loss: 0.2507\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2810 - main_out_loss: 0.2887 - combo_out_loss: 0.2504\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2762 - main_out_loss: 0.2837 - combo_out_loss: 0.2464\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2737 - main_out_loss: 0.2806 - combo_out_loss: 0.2464\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2708 - main_out_loss: 0.2775 - combo_out_loss: 0.2437\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2670 - main_out_loss: 0.2736 - combo_out_loss: 0.2405\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2672 - main_out_loss: 0.2736 - combo_out_loss: 0.2413\u001b[0m\n",
      "\u001b[31m 992/1557 [==================>...........] - ETA: 0s - loss: 0.2681 - main_out_loss: 0.2746 - combo_out_loss: 0.2419\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2645 - main_out_loss: 0.2709 - combo_out_loss: 0.2388\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2624 - main_out_loss: 0.2686 - combo_out_loss: 0.2377\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2668 - main_out_loss: 0.2729 - combo_out_loss: 0.2423\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2653 - main_out_loss: 0.2714 - combo_out_loss: 0.2408\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2656 - main_out_loss: 0.2719 - combo_out_loss: 0.2405\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2657 - main_out_loss: 0.2721 - combo_out_loss: 0.2399\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2657 - main_out_loss: 0.2719 - combo_out_loss: 0.2409\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2644 - main_out_loss: 0.2706 - combo_out_loss: 0.2397\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2646 - main_out_loss: 0.2706 - combo_out_loss: 0.2404\u001b[0m\n",
      "\u001b[31mEpoch 76/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2418 - main_out_loss: 0.2484 - combo_out_loss: 0.2158\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2652 - main_out_loss: 0.2684 - combo_out_loss: 0.2524\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2636 - main_out_loss: 0.2700 - combo_out_loss: 0.2379\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2538 - main_out_loss: 0.2599 - combo_out_loss: 0.2294\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.2513 - main_out_loss: 0.2576 - combo_out_loss: 0.2259\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2491 - main_out_loss: 0.2541 - combo_out_loss: 0.2288\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2565 - main_out_loss: 0.2620 - combo_out_loss: 0.2343\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2608 - main_out_loss: 0.2659 - combo_out_loss: 0.2403\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2577 - main_out_loss: 0.2626 - combo_out_loss: 0.2379\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2536 - main_out_loss: 0.2584 - combo_out_loss: 0.2342\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2556 - main_out_loss: 0.2606 - combo_out_loss: 0.2354\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2536 - main_out_loss: 0.2580 - combo_out_loss: 0.2361\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2540 - main_out_loss: 0.2588 - combo_out_loss: 0.2349\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2578 - main_out_loss: 0.2632 - combo_out_loss: 0.2366\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2634 - main_out_loss: 0.2689 - combo_out_loss: 0.2411\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2626 - main_out_loss: 0.2686 - combo_out_loss: 0.2387\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2611 - main_out_loss: 0.2667 - combo_out_loss: 0.2387\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2594 - main_out_loss: 0.2647 - combo_out_loss: 0.2384\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2605 - main_out_loss: 0.2657 - combo_out_loss: 0.2395\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2605 - main_out_loss: 0.2659 - combo_out_loss: 0.2391\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2578 - main_out_loss: 0.2624 - combo_out_loss: 0.2392\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2579 - main_out_loss: 0.2621 - combo_out_loss: 0.2409\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2576 - main_out_loss: 0.2615 - combo_out_loss: 0.2422\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2560 - main_out_loss: 0.2599 - combo_out_loss: 0.2406\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2571 - main_out_loss: 0.2613 - combo_out_loss: 0.2404\u001b[0m\n",
      "\u001b[31mEpoch 77/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2180 - main_out_loss: 0.2276 - combo_out_loss: 0.1795\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2315 - main_out_loss: 0.2321 - combo_out_loss: 0.2293\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2464 - main_out_loss: 0.2494 - combo_out_loss: 0.2345\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2485 - main_out_loss: 0.2521 - combo_out_loss: 0.2342\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2524 - main_out_loss: 0.2562 - combo_out_loss: 0.2371\u001b[0m\n",
      "\u001b[31m 352/1557 [=====>........................] - ETA: 1s - loss: 0.2470 - main_out_loss: 0.2509 - combo_out_loss: 0.2315\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2479 - main_out_loss: 0.2525 - combo_out_loss: 0.2297\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2454 - main_out_loss: 0.2493 - combo_out_loss: 0.2298\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2459 - main_out_loss: 0.2496 - combo_out_loss: 0.2310\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2474 - main_out_loss: 0.2510 - combo_out_loss: 0.2329\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2462 - main_out_loss: 0.2494 - combo_out_loss: 0.2331\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2490 - main_out_loss: 0.2521 - combo_out_loss: 0.2366\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2468 - main_out_loss: 0.2501 - combo_out_loss: 0.2336\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2468 - main_out_loss: 0.2501 - combo_out_loss: 0.2335\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2480 - main_out_loss: 0.2520 - combo_out_loss: 0.2323\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2489 - main_out_loss: 0.2531 - combo_out_loss: 0.2321\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2481 - main_out_loss: 0.2522 - combo_out_loss: 0.2319\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2496 - main_out_loss: 0.2537 - combo_out_loss: 0.2334\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2493 - main_out_loss: 0.2534 - combo_out_loss: 0.2326\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2481 - main_out_loss: 0.2519 - combo_out_loss: 0.2329\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2474 - main_out_loss: 0.2513 - combo_out_loss: 0.2316\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2478 - main_out_loss: 0.2519 - combo_out_loss: 0.2313\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2477 - main_out_loss: 0.2518 - combo_out_loss: 0.2313\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2506 - main_out_loss: 0.2548 - combo_out_loss: 0.2335\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2493 - main_out_loss: 0.2532 - combo_out_loss: 0.2337\u001b[0m\n",
      "\u001b[31mEpoch 78/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2897 - main_out_loss: 0.2975 - combo_out_loss: 0.2585\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2630 - main_out_loss: 0.2674 - combo_out_loss: 0.2456\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2488 - main_out_loss: 0.2510 - combo_out_loss: 0.2404\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2484 - main_out_loss: 0.2512 - combo_out_loss: 0.2371\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2517 - main_out_loss: 0.2536 - combo_out_loss: 0.2441\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2498 - main_out_loss: 0.2527 - combo_out_loss: 0.2380\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2484 - main_out_loss: 0.2511 - combo_out_loss: 0.2377\u001b[0m\n",
      "\u001b[31m 480/1557 [========>.....................] - ETA: 1s - loss: 0.2510 - main_out_loss: 0.2529 - combo_out_loss: 0.2431\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2494 - main_out_loss: 0.2511 - combo_out_loss: 0.2428\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2450 - main_out_loss: 0.2470 - combo_out_loss: 0.2373\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2466 - main_out_loss: 0.2494 - combo_out_loss: 0.2353\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2517 - main_out_loss: 0.2553 - combo_out_loss: 0.2372\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2509 - main_out_loss: 0.2545 - combo_out_loss: 0.2364\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2496 - main_out_loss: 0.2531 - combo_out_loss: 0.2357\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2475 - main_out_loss: 0.2509 - combo_out_loss: 0.2337\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2509 - main_out_loss: 0.2548 - combo_out_loss: 0.2354\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2507 - main_out_loss: 0.2544 - combo_out_loss: 0.2361\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2504 - main_out_loss: 0.2544 - combo_out_loss: 0.2345\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2492 - main_out_loss: 0.2530 - combo_out_loss: 0.2340\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2475 - main_out_loss: 0.2510 - combo_out_loss: 0.2334\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2484 - main_out_loss: 0.2520 - combo_out_loss: 0.2339\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2494 - main_out_loss: 0.2530 - combo_out_loss: 0.2351\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2509 - main_out_loss: 0.2547 - combo_out_loss: 0.2358\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2499 - main_out_loss: 0.2539 - combo_out_loss: 0.2340\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2512 - main_out_loss: 0.2556 - combo_out_loss: 0.2337\u001b[0m\n",
      "\u001b[31mEpoch 79/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3189 - main_out_loss: 0.3302 - combo_out_loss: 0.2739\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2581 - main_out_loss: 0.2624 - combo_out_loss: 0.2406\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2575 - main_out_loss: 0.2629 - combo_out_loss: 0.2358\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2542 - main_out_loss: 0.2609 - combo_out_loss: 0.2271\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2597 - main_out_loss: 0.2662 - combo_out_loss: 0.2337\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2517 - main_out_loss: 0.2575 - combo_out_loss: 0.2285\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2527 - main_out_loss: 0.2577 - combo_out_loss: 0.2330\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2518 - main_out_loss: 0.2566 - combo_out_loss: 0.2326\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2517 - main_out_loss: 0.2565 - combo_out_loss: 0.2324\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.2501 - main_out_loss: 0.2551 - combo_out_loss: 0.2298\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2507 - main_out_loss: 0.2559 - combo_out_loss: 0.2302\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2517 - main_out_loss: 0.2570 - combo_out_loss: 0.2301\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2541 - main_out_loss: 0.2599 - combo_out_loss: 0.2309\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2518 - main_out_loss: 0.2571 - combo_out_loss: 0.2306\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2508 - main_out_loss: 0.2556 - combo_out_loss: 0.2312\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2499 - main_out_loss: 0.2543 - combo_out_loss: 0.2320\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2508 - main_out_loss: 0.2556 - combo_out_loss: 0.2313\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2510 - main_out_loss: 0.2559 - combo_out_loss: 0.2317\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2492 - main_out_loss: 0.2539 - combo_out_loss: 0.2306\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2474 - main_out_loss: 0.2517 - combo_out_loss: 0.2303\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2486 - main_out_loss: 0.2532 - combo_out_loss: 0.2303\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2492 - main_out_loss: 0.2538 - combo_out_loss: 0.2309\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2481 - main_out_loss: 0.2528 - combo_out_loss: 0.2295\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2474 - main_out_loss: 0.2521 - combo_out_loss: 0.2285\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2487 - main_out_loss: 0.2534 - combo_out_loss: 0.2297\u001b[0m\n",
      "\u001b[31mEpoch 80/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2380 - main_out_loss: 0.2358 - combo_out_loss: 0.2467\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2342 - main_out_loss: 0.2387 - combo_out_loss: 0.2162\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2386 - main_out_loss: 0.2453 - combo_out_loss: 0.2115\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2554 - main_out_loss: 0.2641 - combo_out_loss: 0.2207\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2582 - main_out_loss: 0.2646 - combo_out_loss: 0.2324\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2552 - main_out_loss: 0.2626 - combo_out_loss: 0.2257\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2514 - main_out_loss: 0.2578 - combo_out_loss: 0.2255\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2527 - main_out_loss: 0.2596 - combo_out_loss: 0.2250\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2566 - main_out_loss: 0.2630 - combo_out_loss: 0.2310\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2531 - main_out_loss: 0.2589 - combo_out_loss: 0.2300\u001b[0m\n",
      "\u001b[31m 672/1557 [===========>..................] - ETA: 1s - loss: 0.2523 - main_out_loss: 0.2577 - combo_out_loss: 0.2306\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2538 - main_out_loss: 0.2590 - combo_out_loss: 0.2326\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2541 - main_out_loss: 0.2599 - combo_out_loss: 0.2310\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2546 - main_out_loss: 0.2603 - combo_out_loss: 0.2315\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2540 - main_out_loss: 0.2597 - combo_out_loss: 0.2311\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2534 - main_out_loss: 0.2591 - combo_out_loss: 0.2307\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2517 - main_out_loss: 0.2571 - combo_out_loss: 0.2300\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2504 - main_out_loss: 0.2559 - combo_out_loss: 0.2282\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2506 - main_out_loss: 0.2560 - combo_out_loss: 0.2292\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2503 - main_out_loss: 0.2556 - combo_out_loss: 0.2291\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2485 - main_out_loss: 0.2534 - combo_out_loss: 0.2288\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2515 - main_out_loss: 0.2567 - combo_out_loss: 0.2309\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2512 - main_out_loss: 0.2566 - combo_out_loss: 0.2294\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2522 - main_out_loss: 0.2574 - combo_out_loss: 0.2315\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2511 - main_out_loss: 0.2562 - combo_out_loss: 0.2305\u001b[0m\n",
      "\u001b[31mEpoch 81/100\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.2019 - main_out_loss: 0.2068 - combo_out_loss: 0.1821\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2501 - main_out_loss: 0.2529 - combo_out_loss: 0.2390\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2452 - main_out_loss: 0.2487 - combo_out_loss: 0.2310\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2436 - main_out_loss: 0.2464 - combo_out_loss: 0.2320\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2414 - main_out_loss: 0.2435 - combo_out_loss: 0.2333\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2373 - main_out_loss: 0.2399 - combo_out_loss: 0.2269\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2404 - main_out_loss: 0.2429 - combo_out_loss: 0.2305\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2410 - main_out_loss: 0.2424 - combo_out_loss: 0.2353\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2410 - main_out_loss: 0.2432 - combo_out_loss: 0.2321\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2430 - main_out_loss: 0.2464 - combo_out_loss: 0.2295\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2457 - main_out_loss: 0.2494 - combo_out_loss: 0.2311\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2450 - main_out_loss: 0.2486 - combo_out_loss: 0.2305\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.2433 - main_out_loss: 0.2466 - combo_out_loss: 0.2304\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2457 - main_out_loss: 0.2495 - combo_out_loss: 0.2306\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2460 - main_out_loss: 0.2492 - combo_out_loss: 0.2329\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2441 - main_out_loss: 0.2471 - combo_out_loss: 0.2323\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2453 - main_out_loss: 0.2489 - combo_out_loss: 0.2310\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2441 - main_out_loss: 0.2471 - combo_out_loss: 0.2319\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2433 - main_out_loss: 0.2464 - combo_out_loss: 0.2308\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2418 - main_out_loss: 0.2448 - combo_out_loss: 0.2295\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2406 - main_out_loss: 0.2436 - combo_out_loss: 0.2285\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2396 - main_out_loss: 0.2425 - combo_out_loss: 0.2281\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2388 - main_out_loss: 0.2418 - combo_out_loss: 0.2265\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2394 - main_out_loss: 0.2422 - combo_out_loss: 0.2283\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2390 - main_out_loss: 0.2416 - combo_out_loss: 0.2285\u001b[0m\n",
      "\u001b[31mEpoch 82/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2204 - main_out_loss: 0.2273 - combo_out_loss: 0.1928\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.2207 - main_out_loss: 0.2256 - combo_out_loss: 0.2009\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2465 - main_out_loss: 0.2525 - combo_out_loss: 0.2225\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2551 - main_out_loss: 0.2629 - combo_out_loss: 0.2242\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2449 - main_out_loss: 0.2498 - combo_out_loss: 0.2253\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2493 - main_out_loss: 0.2538 - combo_out_loss: 0.2310\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2501 - main_out_loss: 0.2549 - combo_out_loss: 0.2307\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2441 - main_out_loss: 0.2489 - combo_out_loss: 0.2249\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2446 - main_out_loss: 0.2503 - combo_out_loss: 0.2221\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2446 - main_out_loss: 0.2495 - combo_out_loss: 0.2252\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2447 - main_out_loss: 0.2495 - combo_out_loss: 0.2255\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2477 - main_out_loss: 0.2529 - combo_out_loss: 0.2268\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2468 - main_out_loss: 0.2521 - combo_out_loss: 0.2259\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2492 - main_out_loss: 0.2543 - combo_out_loss: 0.2287\u001b[0m\n",
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.2485 - main_out_loss: 0.2530 - combo_out_loss: 0.2306\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2475 - main_out_loss: 0.2521 - combo_out_loss: 0.2294\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2459 - main_out_loss: 0.2502 - combo_out_loss: 0.2289\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2451 - main_out_loss: 0.2493 - combo_out_loss: 0.2281\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2464 - main_out_loss: 0.2505 - combo_out_loss: 0.2298\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2465 - main_out_loss: 0.2506 - combo_out_loss: 0.2299\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2477 - main_out_loss: 0.2518 - combo_out_loss: 0.2312\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2468 - main_out_loss: 0.2509 - combo_out_loss: 0.2305\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2467 - main_out_loss: 0.2508 - combo_out_loss: 0.2302\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2470 - main_out_loss: 0.2510 - combo_out_loss: 0.2309\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2464 - main_out_loss: 0.2503 - combo_out_loss: 0.2305\u001b[0m\n",
      "\u001b[31mEpoch 83/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2116 - main_out_loss: 0.2166 - combo_out_loss: 0.1916\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2221 - main_out_loss: 0.2241 - combo_out_loss: 0.2142\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2221 - main_out_loss: 0.2248 - combo_out_loss: 0.2111\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.2304 - main_out_loss: 0.2335 - combo_out_loss: 0.2182\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2228 - main_out_loss: 0.2246 - combo_out_loss: 0.2155\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2177 - main_out_loss: 0.2200 - combo_out_loss: 0.2086\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2169 - main_out_loss: 0.2192 - combo_out_loss: 0.2078\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2192 - main_out_loss: 0.2213 - combo_out_loss: 0.2111\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2204 - main_out_loss: 0.2228 - combo_out_loss: 0.2109\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2223 - main_out_loss: 0.2248 - combo_out_loss: 0.2121\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2246 - main_out_loss: 0.2277 - combo_out_loss: 0.2124\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2247 - main_out_loss: 0.2276 - combo_out_loss: 0.2132\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2288 - main_out_loss: 0.2319 - combo_out_loss: 0.2165\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2320 - main_out_loss: 0.2353 - combo_out_loss: 0.2189\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2330 - main_out_loss: 0.2366 - combo_out_loss: 0.2183\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2339 - main_out_loss: 0.2373 - combo_out_loss: 0.2202\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2334 - main_out_loss: 0.2363 - combo_out_loss: 0.2221\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2328 - main_out_loss: 0.2353 - combo_out_loss: 0.2226\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2326 - main_out_loss: 0.2351 - combo_out_loss: 0.2224\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2333 - main_out_loss: 0.2359 - combo_out_loss: 0.2227\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2349 - main_out_loss: 0.2376 - combo_out_loss: 0.2240\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2361 - main_out_loss: 0.2390 - combo_out_loss: 0.2245\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2365 - main_out_loss: 0.2396 - combo_out_loss: 0.2240\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2370 - main_out_loss: 0.2399 - combo_out_loss: 0.2258\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2367 - main_out_loss: 0.2397 - combo_out_loss: 0.2248\u001b[0m\n",
      "\u001b[31mEpoch 84/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.3008 - main_out_loss: 0.3068 - combo_out_loss: 0.2770\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2610 - main_out_loss: 0.2684 - combo_out_loss: 0.2312\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2503 - main_out_loss: 0.2551 - combo_out_loss: 0.2313\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2594 - main_out_loss: 0.2671 - combo_out_loss: 0.2287\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.2585 - main_out_loss: 0.2654 - combo_out_loss: 0.2308\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2572 - main_out_loss: 0.2639 - combo_out_loss: 0.2305\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2578 - main_out_loss: 0.2636 - combo_out_loss: 0.2345\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2517 - main_out_loss: 0.2570 - combo_out_loss: 0.2307\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2533 - main_out_loss: 0.2580 - combo_out_loss: 0.2347\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2534 - main_out_loss: 0.2587 - combo_out_loss: 0.2323\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2491 - main_out_loss: 0.2545 - combo_out_loss: 0.2275\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2448 - main_out_loss: 0.2496 - combo_out_loss: 0.2257\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2460 - main_out_loss: 0.2513 - combo_out_loss: 0.2245\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2427 - main_out_loss: 0.2475 - combo_out_loss: 0.2235\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2425 - main_out_loss: 0.2471 - combo_out_loss: 0.2242\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2399 - main_out_loss: 0.2440 - combo_out_loss: 0.2235\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2387 - main_out_loss: 0.2428 - combo_out_loss: 0.2225\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2362 - main_out_loss: 0.2400 - combo_out_loss: 0.2212\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2364 - main_out_loss: 0.2400 - combo_out_loss: 0.2222\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2369 - main_out_loss: 0.2406 - combo_out_loss: 0.2220\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2366 - main_out_loss: 0.2400 - combo_out_loss: 0.2231\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2361 - main_out_loss: 0.2396 - combo_out_loss: 0.2221\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2335 - main_out_loss: 0.2368 - combo_out_loss: 0.2205\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2344 - main_out_loss: 0.2378 - combo_out_loss: 0.2209\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2335 - main_out_loss: 0.2368 - combo_out_loss: 0.2206\u001b[0m\n",
      "\u001b[31mEpoch 85/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 2s - loss: 0.2185 - main_out_loss: 0.2220 - combo_out_loss: 0.2047\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2135 - main_out_loss: 0.2152 - combo_out_loss: 0.2068\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2201 - main_out_loss: 0.2198 - combo_out_loss: 0.2210\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2189 - main_out_loss: 0.2184 - combo_out_loss: 0.2206\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2150 - main_out_loss: 0.2132 - combo_out_loss: 0.2224\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2146 - main_out_loss: 0.2129 - combo_out_loss: 0.2218\u001b[0m\n",
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.2196 - main_out_loss: 0.2189 - combo_out_loss: 0.2224\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2172 - main_out_loss: 0.2148 - combo_out_loss: 0.2270\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2169 - main_out_loss: 0.2147 - combo_out_loss: 0.2258\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2133 - main_out_loss: 0.2111 - combo_out_loss: 0.2223\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2159 - main_out_loss: 0.2138 - combo_out_loss: 0.2239\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2201 - main_out_loss: 0.2192 - combo_out_loss: 0.2240\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2235 - main_out_loss: 0.2230 - combo_out_loss: 0.2254\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2237 - main_out_loss: 0.2236 - combo_out_loss: 0.2241\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2230 - main_out_loss: 0.2233 - combo_out_loss: 0.2219\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2223 - main_out_loss: 0.2229 - combo_out_loss: 0.2201\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2236 - main_out_loss: 0.2245 - combo_out_loss: 0.2199\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2245 - main_out_loss: 0.2257 - combo_out_loss: 0.2200\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2252 - main_out_loss: 0.2267 - combo_out_loss: 0.2193\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2253 - main_out_loss: 0.2268 - combo_out_loss: 0.2192\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2259 - main_out_loss: 0.2275 - combo_out_loss: 0.2196\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2263 - main_out_loss: 0.2280 - combo_out_loss: 0.2194\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2260 - main_out_loss: 0.2278 - combo_out_loss: 0.2190\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2266 - main_out_loss: 0.2285 - combo_out_loss: 0.2189\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2271 - main_out_loss: 0.2291 - combo_out_loss: 0.2191\u001b[0m\n",
      "\u001b[31mEpoch 86/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2406 - main_out_loss: 0.2311 - combo_out_loss: 0.2787\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2474 - main_out_loss: 0.2344 - combo_out_loss: 0.2995\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2533 - main_out_loss: 0.2486 - combo_out_loss: 0.2722\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2512 - main_out_loss: 0.2486 - combo_out_loss: 0.2618\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2394 - main_out_loss: 0.2369 - combo_out_loss: 0.2492\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2361 - main_out_loss: 0.2331 - combo_out_loss: 0.2482\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2320 - main_out_loss: 0.2301 - combo_out_loss: 0.2396\u001b[0m\n",
      "\u001b[31m 480/1557 [========>.....................] - ETA: 1s - loss: 0.2374 - main_out_loss: 0.2356 - combo_out_loss: 0.2449\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2310 - main_out_loss: 0.2295 - combo_out_loss: 0.2370\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2323 - main_out_loss: 0.2313 - combo_out_loss: 0.2360\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2350 - main_out_loss: 0.2355 - combo_out_loss: 0.2330\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2342 - main_out_loss: 0.2350 - combo_out_loss: 0.2306\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2300 - main_out_loss: 0.2304 - combo_out_loss: 0.2285\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2286 - main_out_loss: 0.2296 - combo_out_loss: 0.2249\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2293 - main_out_loss: 0.2303 - combo_out_loss: 0.2250\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2291 - main_out_loss: 0.2301 - combo_out_loss: 0.2253\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2283 - main_out_loss: 0.2289 - combo_out_loss: 0.2258\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2282 - main_out_loss: 0.2288 - combo_out_loss: 0.2256\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2289 - main_out_loss: 0.2301 - combo_out_loss: 0.2242\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2272 - main_out_loss: 0.2283 - combo_out_loss: 0.2225\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2265 - main_out_loss: 0.2274 - combo_out_loss: 0.2229\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2252 - main_out_loss: 0.2258 - combo_out_loss: 0.2226\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2244 - main_out_loss: 0.2251 - combo_out_loss: 0.2216\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2259 - main_out_loss: 0.2271 - combo_out_loss: 0.2211\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2258 - main_out_loss: 0.2271 - combo_out_loss: 0.2204\u001b[0m\n",
      "\u001b[31mEpoch 87/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2718 - main_out_loss: 0.2855 - combo_out_loss: 0.2170\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2652 - main_out_loss: 0.2739 - combo_out_loss: 0.2308\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2740 - main_out_loss: 0.2837 - combo_out_loss: 0.2349\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2581 - main_out_loss: 0.2663 - combo_out_loss: 0.2254\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2404 - main_out_loss: 0.2466 - combo_out_loss: 0.2155\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2349 - main_out_loss: 0.2398 - combo_out_loss: 0.2152\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2388 - main_out_loss: 0.2438 - combo_out_loss: 0.2190\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2431 - main_out_loss: 0.2476 - combo_out_loss: 0.2253\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2436 - main_out_loss: 0.2486 - combo_out_loss: 0.2234\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.2397 - main_out_loss: 0.2440 - combo_out_loss: 0.2225\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2367 - main_out_loss: 0.2407 - combo_out_loss: 0.2206\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2351 - main_out_loss: 0.2380 - combo_out_loss: 0.2236\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2337 - main_out_loss: 0.2366 - combo_out_loss: 0.2221\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2314 - main_out_loss: 0.2344 - combo_out_loss: 0.2196\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2306 - main_out_loss: 0.2338 - combo_out_loss: 0.2177\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2304 - main_out_loss: 0.2334 - combo_out_loss: 0.2184\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2275 - main_out_loss: 0.2303 - combo_out_loss: 0.2165\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2290 - main_out_loss: 0.2322 - combo_out_loss: 0.2165\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2269 - main_out_loss: 0.2293 - combo_out_loss: 0.2172\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2295 - main_out_loss: 0.2322 - combo_out_loss: 0.2187\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2294 - main_out_loss: 0.2321 - combo_out_loss: 0.2187\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2305 - main_out_loss: 0.2332 - combo_out_loss: 0.2198\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2318 - main_out_loss: 0.2346 - combo_out_loss: 0.2204\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2324 - main_out_loss: 0.2354 - combo_out_loss: 0.2202\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2312 - main_out_loss: 0.2342 - combo_out_loss: 0.2192\u001b[0m\n",
      "\u001b[31mEpoch 88/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2004 - main_out_loss: 0.1940 - combo_out_loss: 0.2258\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2059 - main_out_loss: 0.2034 - combo_out_loss: 0.2161\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2302 - main_out_loss: 0.2314 - combo_out_loss: 0.2253\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2258 - main_out_loss: 0.2251 - combo_out_loss: 0.2287\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2284 - main_out_loss: 0.2295 - combo_out_loss: 0.2237\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2248 - main_out_loss: 0.2265 - combo_out_loss: 0.2181\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2238 - main_out_loss: 0.2251 - combo_out_loss: 0.2188\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2224 - main_out_loss: 0.2233 - combo_out_loss: 0.2190\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2226 - main_out_loss: 0.2232 - combo_out_loss: 0.2201\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2260 - main_out_loss: 0.2271 - combo_out_loss: 0.2212\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2239 - main_out_loss: 0.2257 - combo_out_loss: 0.2168\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 0s - loss: 0.2248 - main_out_loss: 0.2260 - combo_out_loss: 0.2197\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2223 - main_out_loss: 0.2237 - combo_out_loss: 0.2171\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2229 - main_out_loss: 0.2246 - combo_out_loss: 0.2158\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2225 - main_out_loss: 0.2243 - combo_out_loss: 0.2155\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2210 - main_out_loss: 0.2230 - combo_out_loss: 0.2131\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2228 - main_out_loss: 0.2250 - combo_out_loss: 0.2140\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2244 - main_out_loss: 0.2266 - combo_out_loss: 0.2159\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2263 - main_out_loss: 0.2287 - combo_out_loss: 0.2167\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2251 - main_out_loss: 0.2274 - combo_out_loss: 0.2160\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2256 - main_out_loss: 0.2275 - combo_out_loss: 0.2178\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2261 - main_out_loss: 0.2280 - combo_out_loss: 0.2181\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2258 - main_out_loss: 0.2279 - combo_out_loss: 0.2175\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2271 - main_out_loss: 0.2293 - combo_out_loss: 0.2183\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2267 - main_out_loss: 0.2288 - combo_out_loss: 0.2183\u001b[0m\n",
      "\u001b[31mEpoch 89/100\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.2111 - main_out_loss: 0.2101 - combo_out_loss: 0.2148\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2092 - main_out_loss: 0.2063 - combo_out_loss: 0.2207\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2095 - main_out_loss: 0.2102 - combo_out_loss: 0.2064\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2157 - main_out_loss: 0.2172 - combo_out_loss: 0.2098\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2073 - main_out_loss: 0.2079 - combo_out_loss: 0.2046\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2071 - main_out_loss: 0.2081 - combo_out_loss: 0.2032\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2053 - main_out_loss: 0.2045 - combo_out_loss: 0.2086\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2076 - main_out_loss: 0.2064 - combo_out_loss: 0.2121\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2058 - main_out_loss: 0.2047 - combo_out_loss: 0.2103\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2051 - main_out_loss: 0.2033 - combo_out_loss: 0.2123\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2049 - main_out_loss: 0.2031 - combo_out_loss: 0.2120\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2065 - main_out_loss: 0.2057 - combo_out_loss: 0.2098\u001b[0m\n",
      "\u001b[31m 800/1557 [==============>...............] - ETA: 0s - loss: 0.2079 - main_out_loss: 0.2071 - combo_out_loss: 0.2111\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2092 - main_out_loss: 0.2082 - combo_out_loss: 0.2131\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2128 - main_out_loss: 0.2121 - combo_out_loss: 0.2154\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2116 - main_out_loss: 0.2113 - combo_out_loss: 0.2129\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2121 - main_out_loss: 0.2119 - combo_out_loss: 0.2130\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2120 - main_out_loss: 0.2120 - combo_out_loss: 0.2118\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2112 - main_out_loss: 0.2111 - combo_out_loss: 0.2118\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2118 - main_out_loss: 0.2119 - combo_out_loss: 0.2111\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2112 - main_out_loss: 0.2114 - combo_out_loss: 0.2104\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2128 - main_out_loss: 0.2132 - combo_out_loss: 0.2111\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2154 - main_out_loss: 0.2161 - combo_out_loss: 0.2125\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2182 - main_out_loss: 0.2192 - combo_out_loss: 0.2144\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2168 - main_out_loss: 0.2176 - combo_out_loss: 0.2136\u001b[0m\n",
      "\u001b[31mEpoch 90/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.1957 - main_out_loss: 0.1900 - combo_out_loss: 0.2183\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.2108 - main_out_loss: 0.2145 - combo_out_loss: 0.1959\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2211 - main_out_loss: 0.2238 - combo_out_loss: 0.2104\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2192 - main_out_loss: 0.2215 - combo_out_loss: 0.2100\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2241 - main_out_loss: 0.2276 - combo_out_loss: 0.2103\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2240 - main_out_loss: 0.2268 - combo_out_loss: 0.2127\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2231 - main_out_loss: 0.2262 - combo_out_loss: 0.2109\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2219 - main_out_loss: 0.2251 - combo_out_loss: 0.2092\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2196 - main_out_loss: 0.2222 - combo_out_loss: 0.2093\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2226 - main_out_loss: 0.2257 - combo_out_loss: 0.2103\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2312 - main_out_loss: 0.2351 - combo_out_loss: 0.2159\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2343 - main_out_loss: 0.2383 - combo_out_loss: 0.2184\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2355 - main_out_loss: 0.2394 - combo_out_loss: 0.2201\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2337 - main_out_loss: 0.2380 - combo_out_loss: 0.2167\u001b[0m\n",
      "\u001b[31m 928/1557 [================>.............] - ETA: 0s - loss: 0.2331 - main_out_loss: 0.2369 - combo_out_loss: 0.2181\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2329 - main_out_loss: 0.2367 - combo_out_loss: 0.2177\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2315 - main_out_loss: 0.2350 - combo_out_loss: 0.2175\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2298 - main_out_loss: 0.2332 - combo_out_loss: 0.2162\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2296 - main_out_loss: 0.2325 - combo_out_loss: 0.2178\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2302 - main_out_loss: 0.2334 - combo_out_loss: 0.2174\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2319 - main_out_loss: 0.2352 - combo_out_loss: 0.2186\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2330 - main_out_loss: 0.2362 - combo_out_loss: 0.2205\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2325 - main_out_loss: 0.2355 - combo_out_loss: 0.2207\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2328 - main_out_loss: 0.2359 - combo_out_loss: 0.2206\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2322 - main_out_loss: 0.2353 - combo_out_loss: 0.2197\u001b[0m\n",
      "\u001b[31mEpoch 91/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2334 - main_out_loss: 0.2143 - combo_out_loss: 0.3096\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2344 - main_out_loss: 0.2314 - combo_out_loss: 0.2464\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2142 - main_out_loss: 0.2102 - combo_out_loss: 0.2300\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.2077 - main_out_loss: 0.2042 - combo_out_loss: 0.2221\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2130 - main_out_loss: 0.2109 - combo_out_loss: 0.2216\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2105 - main_out_loss: 0.2089 - combo_out_loss: 0.2170\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2129 - main_out_loss: 0.2111 - combo_out_loss: 0.2201\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2122 - main_out_loss: 0.2111 - combo_out_loss: 0.2167\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2131 - main_out_loss: 0.2121 - combo_out_loss: 0.2172\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2129 - main_out_loss: 0.2123 - combo_out_loss: 0.2154\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2133 - main_out_loss: 0.2129 - combo_out_loss: 0.2147\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2139 - main_out_loss: 0.2141 - combo_out_loss: 0.2132\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2142 - main_out_loss: 0.2138 - combo_out_loss: 0.2158\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2180 - main_out_loss: 0.2180 - combo_out_loss: 0.2182\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2180 - main_out_loss: 0.2185 - combo_out_loss: 0.2163\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2149 - main_out_loss: 0.2152 - combo_out_loss: 0.2136\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2117 - main_out_loss: 0.2112 - combo_out_loss: 0.2137\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2135 - main_out_loss: 0.2130 - combo_out_loss: 0.2155\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2151 - main_out_loss: 0.2150 - combo_out_loss: 0.2153\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2145 - main_out_loss: 0.2145 - combo_out_loss: 0.2144\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2127 - main_out_loss: 0.2126 - combo_out_loss: 0.2134\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2128 - main_out_loss: 0.2126 - combo_out_loss: 0.2134\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2121 - main_out_loss: 0.2118 - combo_out_loss: 0.2131\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2140 - main_out_loss: 0.2140 - combo_out_loss: 0.2141\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2136 - main_out_loss: 0.2137 - combo_out_loss: 0.2131\u001b[0m\n",
      "\u001b[31mEpoch 92/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2848 - main_out_loss: 0.2875 - combo_out_loss: 0.2742\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2608 - main_out_loss: 0.2675 - combo_out_loss: 0.2341\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2337 - main_out_loss: 0.2383 - combo_out_loss: 0.2156\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2182 - main_out_loss: 0.2217 - combo_out_loss: 0.2041\u001b[0m\n",
      "\u001b[31m 288/1557 [====>.........................] - ETA: 1s - loss: 0.2192 - main_out_loss: 0.2221 - combo_out_loss: 0.2074\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2165 - main_out_loss: 0.2189 - combo_out_loss: 0.2069\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2136 - main_out_loss: 0.2154 - combo_out_loss: 0.2063\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2106 - main_out_loss: 0.2128 - combo_out_loss: 0.2022\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2115 - main_out_loss: 0.2135 - combo_out_loss: 0.2035\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2099 - main_out_loss: 0.2112 - combo_out_loss: 0.2044\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2077 - main_out_loss: 0.2081 - combo_out_loss: 0.2060\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2095 - main_out_loss: 0.2098 - combo_out_loss: 0.2081\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2091 - main_out_loss: 0.2096 - combo_out_loss: 0.2070\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2130 - main_out_loss: 0.2138 - combo_out_loss: 0.2098\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2117 - main_out_loss: 0.2121 - combo_out_loss: 0.2099\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2128 - main_out_loss: 0.2130 - combo_out_loss: 0.2118\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2132 - main_out_loss: 0.2137 - combo_out_loss: 0.2112\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2123 - main_out_loss: 0.2130 - combo_out_loss: 0.2098\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2141 - main_out_loss: 0.2153 - combo_out_loss: 0.2090\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2134 - main_out_loss: 0.2149 - combo_out_loss: 0.2076\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2151 - main_out_loss: 0.2168 - combo_out_loss: 0.2081\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2132 - main_out_loss: 0.2149 - combo_out_loss: 0.2065\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2148 - main_out_loss: 0.2164 - combo_out_loss: 0.2082\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2136 - main_out_loss: 0.2148 - combo_out_loss: 0.2087\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2137 - main_out_loss: 0.2145 - combo_out_loss: 0.2106\u001b[0m\n",
      "\u001b[31mEpoch 93/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2170 - main_out_loss: 0.2216 - combo_out_loss: 0.1984\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2185 - main_out_loss: 0.2220 - combo_out_loss: 0.2048\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2149 - main_out_loss: 0.2179 - combo_out_loss: 0.2027\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2126 - main_out_loss: 0.2149 - combo_out_loss: 0.2031\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2210 - main_out_loss: 0.2234 - combo_out_loss: 0.2117\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2157 - main_out_loss: 0.2180 - combo_out_loss: 0.2065\u001b[0m\n",
      "\u001b[31m 416/1557 [=======>......................] - ETA: 1s - loss: 0.2229 - main_out_loss: 0.2247 - combo_out_loss: 0.2158\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2258 - main_out_loss: 0.2283 - combo_out_loss: 0.2157\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2246 - main_out_loss: 0.2271 - combo_out_loss: 0.2144\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2194 - main_out_loss: 0.2210 - combo_out_loss: 0.2130\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2201 - main_out_loss: 0.2218 - combo_out_loss: 0.2132\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2193 - main_out_loss: 0.2214 - combo_out_loss: 0.2110\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2185 - main_out_loss: 0.2207 - combo_out_loss: 0.2096\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2187 - main_out_loss: 0.2213 - combo_out_loss: 0.2083\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2187 - main_out_loss: 0.2214 - combo_out_loss: 0.2082\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2189 - main_out_loss: 0.2215 - combo_out_loss: 0.2087\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2212 - main_out_loss: 0.2241 - combo_out_loss: 0.2098\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2189 - main_out_loss: 0.2219 - combo_out_loss: 0.2072\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2185 - main_out_loss: 0.2213 - combo_out_loss: 0.2076\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2179 - main_out_loss: 0.2206 - combo_out_loss: 0.2069\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2197 - main_out_loss: 0.2220 - combo_out_loss: 0.2104\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2175 - main_out_loss: 0.2192 - combo_out_loss: 0.2106\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2154 - main_out_loss: 0.2167 - combo_out_loss: 0.2104\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2171 - main_out_loss: 0.2185 - combo_out_loss: 0.2116\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2162 - main_out_loss: 0.2174 - combo_out_loss: 0.2115\u001b[0m\n",
      "\u001b[31mEpoch 94/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.1716 - main_out_loss: 0.1735 - combo_out_loss: 0.1643\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2227 - main_out_loss: 0.2279 - combo_out_loss: 0.2018\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2294 - main_out_loss: 0.2353 - combo_out_loss: 0.2058\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2311 - main_out_loss: 0.2357 - combo_out_loss: 0.2131\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2255 - main_out_loss: 0.2288 - combo_out_loss: 0.2126\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2284 - main_out_loss: 0.2306 - combo_out_loss: 0.2196\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2241 - main_out_loss: 0.2265 - combo_out_loss: 0.2143\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2250 - main_out_loss: 0.2279 - combo_out_loss: 0.2137\u001b[0m\n",
      "\u001b[31m 544/1557 [=========>....................] - ETA: 1s - loss: 0.2200 - main_out_loss: 0.2223 - combo_out_loss: 0.2108\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2156 - main_out_loss: 0.2167 - combo_out_loss: 0.2113\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2161 - main_out_loss: 0.2179 - combo_out_loss: 0.2090\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2163 - main_out_loss: 0.2172 - combo_out_loss: 0.2125\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2149 - main_out_loss: 0.2161 - combo_out_loss: 0.2103\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2155 - main_out_loss: 0.2168 - combo_out_loss: 0.2106\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2145 - main_out_loss: 0.2159 - combo_out_loss: 0.2089\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2144 - main_out_loss: 0.2151 - combo_out_loss: 0.2116\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2126 - main_out_loss: 0.2133 - combo_out_loss: 0.2100\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2124 - main_out_loss: 0.2130 - combo_out_loss: 0.2102\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2110 - main_out_loss: 0.2116 - combo_out_loss: 0.2088\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2095 - main_out_loss: 0.2095 - combo_out_loss: 0.2094\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2087 - main_out_loss: 0.2086 - combo_out_loss: 0.2088\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2090 - main_out_loss: 0.2091 - combo_out_loss: 0.2085\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2071 - main_out_loss: 0.2067 - combo_out_loss: 0.2084\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2055 - main_out_loss: 0.2053 - combo_out_loss: 0.2065\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2050 - main_out_loss: 0.2048 - combo_out_loss: 0.2060\u001b[0m\n",
      "\u001b[31mEpoch 95/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.2019 - main_out_loss: 0.2045 - combo_out_loss: 0.1916\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2230 - main_out_loss: 0.2263 - combo_out_loss: 0.2101\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2143 - main_out_loss: 0.2158 - combo_out_loss: 0.2079\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2197 - main_out_loss: 0.2234 - combo_out_loss: 0.2052\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2128 - main_out_loss: 0.2150 - combo_out_loss: 0.2041\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2182 - main_out_loss: 0.2214 - combo_out_loss: 0.2054\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2224 - main_out_loss: 0.2252 - combo_out_loss: 0.2111\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2237 - main_out_loss: 0.2257 - combo_out_loss: 0.2157\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2210 - main_out_loss: 0.2226 - combo_out_loss: 0.2143\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 608/1557 [==========>...................] - ETA: 1s - loss: 0.2192 - main_out_loss: 0.2208 - combo_out_loss: 0.2126\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2205 - main_out_loss: 0.2220 - combo_out_loss: 0.2145\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2206 - main_out_loss: 0.2218 - combo_out_loss: 0.2158\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2188 - main_out_loss: 0.2198 - combo_out_loss: 0.2146\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2203 - main_out_loss: 0.2222 - combo_out_loss: 0.2125\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2197 - main_out_loss: 0.2219 - combo_out_loss: 0.2110\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2180 - main_out_loss: 0.2197 - combo_out_loss: 0.2109\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2186 - main_out_loss: 0.2205 - combo_out_loss: 0.2110\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2181 - main_out_loss: 0.2202 - combo_out_loss: 0.2094\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2167 - main_out_loss: 0.2188 - combo_out_loss: 0.2086\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2152 - main_out_loss: 0.2172 - combo_out_loss: 0.2075\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2129 - main_out_loss: 0.2145 - combo_out_loss: 0.2068\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2145 - main_out_loss: 0.2164 - combo_out_loss: 0.2073\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2155 - main_out_loss: 0.2174 - combo_out_loss: 0.2082\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2151 - main_out_loss: 0.2168 - combo_out_loss: 0.2080\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2143 - main_out_loss: 0.2160 - combo_out_loss: 0.2073\u001b[0m\n",
      "\u001b[31mEpoch 96/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.1552 - main_out_loss: 0.1456 - combo_out_loss: 0.1935\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.2160 - main_out_loss: 0.2178 - combo_out_loss: 0.2088\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2217 - main_out_loss: 0.2259 - combo_out_loss: 0.2049\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2214 - main_out_loss: 0.2260 - combo_out_loss: 0.2031\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2304 - main_out_loss: 0.2367 - combo_out_loss: 0.2051\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2299 - main_out_loss: 0.2346 - combo_out_loss: 0.2109\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2224 - main_out_loss: 0.2250 - combo_out_loss: 0.2120\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2164 - main_out_loss: 0.2191 - combo_out_loss: 0.2056\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2160 - main_out_loss: 0.2190 - combo_out_loss: 0.2041\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2112 - main_out_loss: 0.2140 - combo_out_loss: 0.1999\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2141 - main_out_loss: 0.2163 - combo_out_loss: 0.2055\u001b[0m\n",
      "\u001b[31m 736/1557 [=============>................] - ETA: 0s - loss: 0.2147 - main_out_loss: 0.2168 - combo_out_loss: 0.2062\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2127 - main_out_loss: 0.2149 - combo_out_loss: 0.2042\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2119 - main_out_loss: 0.2137 - combo_out_loss: 0.2046\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2111 - main_out_loss: 0.2122 - combo_out_loss: 0.2065\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2117 - main_out_loss: 0.2129 - combo_out_loss: 0.2069\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2101 - main_out_loss: 0.2107 - combo_out_loss: 0.2075\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2088 - main_out_loss: 0.2090 - combo_out_loss: 0.2081\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2084 - main_out_loss: 0.2078 - combo_out_loss: 0.2110\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2084 - main_out_loss: 0.2077 - combo_out_loss: 0.2112\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2086 - main_out_loss: 0.2080 - combo_out_loss: 0.2111\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2105 - main_out_loss: 0.2103 - combo_out_loss: 0.2114\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2103 - main_out_loss: 0.2100 - combo_out_loss: 0.2114\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2098 - main_out_loss: 0.2097 - combo_out_loss: 0.2105\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2086 - main_out_loss: 0.2085 - combo_out_loss: 0.2090\u001b[0m\n",
      "\u001b[31mEpoch 97/100\n",
      "\u001b[0m\n",
      "\u001b[31m  32/1557 [..............................] - ETA: 1s - loss: 0.1909 - main_out_loss: 0.1900 - combo_out_loss: 0.1945\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.1890 - main_out_loss: 0.1886 - combo_out_loss: 0.1909\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.2019 - main_out_loss: 0.2039 - combo_out_loss: 0.1937\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.2050 - main_out_loss: 0.2088 - combo_out_loss: 0.1898\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.2085 - main_out_loss: 0.2110 - combo_out_loss: 0.1986\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.2095 - main_out_loss: 0.2125 - combo_out_loss: 0.1972\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2067 - main_out_loss: 0.2101 - combo_out_loss: 0.1932\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.2043 - main_out_loss: 0.2063 - combo_out_loss: 0.1961\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2079 - main_out_loss: 0.2096 - combo_out_loss: 0.2011\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2063 - main_out_loss: 0.2082 - combo_out_loss: 0.1986\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2092 - main_out_loss: 0.2109 - combo_out_loss: 0.2022\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2134 - main_out_loss: 0.2157 - combo_out_loss: 0.2043\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2131 - main_out_loss: 0.2150 - combo_out_loss: 0.2054\u001b[0m\n",
      "\u001b[31m 864/1557 [===============>..............] - ETA: 0s - loss: 0.2129 - main_out_loss: 0.2148 - combo_out_loss: 0.2054\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2129 - main_out_loss: 0.2149 - combo_out_loss: 0.2049\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2135 - main_out_loss: 0.2155 - combo_out_loss: 0.2055\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2125 - main_out_loss: 0.2140 - combo_out_loss: 0.2064\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2117 - main_out_loss: 0.2129 - combo_out_loss: 0.2073\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2133 - main_out_loss: 0.2147 - combo_out_loss: 0.2077\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2147 - main_out_loss: 0.2164 - combo_out_loss: 0.2081\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2131 - main_out_loss: 0.2144 - combo_out_loss: 0.2080\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2119 - main_out_loss: 0.2130 - combo_out_loss: 0.2077\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2111 - main_out_loss: 0.2120 - combo_out_loss: 0.2077\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2109 - main_out_loss: 0.2118 - combo_out_loss: 0.2072\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2116 - main_out_loss: 0.2127 - combo_out_loss: 0.2074\u001b[0m\n",
      "\u001b[31mEpoch 98/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.1554 - main_out_loss: 0.1415 - combo_out_loss: 0.2109\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  96/1557 [>.............................] - ETA: 1s - loss: 0.1739 - main_out_loss: 0.1739 - combo_out_loss: 0.1737\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.1679 - main_out_loss: 0.1643 - combo_out_loss: 0.1822\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.1741 - main_out_loss: 0.1694 - combo_out_loss: 0.1931\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.1805 - main_out_loss: 0.1762 - combo_out_loss: 0.1975\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.1872 - main_out_loss: 0.1835 - combo_out_loss: 0.2018\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.1816 - main_out_loss: 0.1775 - combo_out_loss: 0.1981\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.1849 - main_out_loss: 0.1807 - combo_out_loss: 0.2017\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.1828 - main_out_loss: 0.1790 - combo_out_loss: 0.1980\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.1827 - main_out_loss: 0.1792 - combo_out_loss: 0.1966\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.1828 - main_out_loss: 0.1793 - combo_out_loss: 0.1968\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.1861 - main_out_loss: 0.1824 - combo_out_loss: 0.2007\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.1861 - main_out_loss: 0.1826 - combo_out_loss: 0.2001\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.1895 - main_out_loss: 0.1863 - combo_out_loss: 0.2023\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.1891 - main_out_loss: 0.1858 - combo_out_loss: 0.2022\u001b[0m\n",
      "\u001b[31m 992/1557 [==================>...........] - ETA: 0s - loss: 0.1918 - main_out_loss: 0.1889 - combo_out_loss: 0.2033\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.1927 - main_out_loss: 0.1900 - combo_out_loss: 0.2033\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.1943 - main_out_loss: 0.1919 - combo_out_loss: 0.2041\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.1973 - main_out_loss: 0.1950 - combo_out_loss: 0.2066\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.1963 - main_out_loss: 0.1941 - combo_out_loss: 0.2052\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.1979 - main_out_loss: 0.1961 - combo_out_loss: 0.2053\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.1993 - main_out_loss: 0.1976 - combo_out_loss: 0.2061\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2001 - main_out_loss: 0.1982 - combo_out_loss: 0.2079\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2000 - main_out_loss: 0.1978 - combo_out_loss: 0.2086\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2008 - main_out_loss: 0.1987 - combo_out_loss: 0.2090\u001b[0m\n",
      "\u001b[31mEpoch 99/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.1684 - main_out_loss: 0.1577 - combo_out_loss: 0.2112\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.1685 - main_out_loss: 0.1656 - combo_out_loss: 0.1805\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.1772 - main_out_loss: 0.1723 - combo_out_loss: 0.1966\u001b[0m\n",
      "\u001b[31m 224/1557 [===>..........................] - ETA: 1s - loss: 0.1847 - main_out_loss: 0.1803 - combo_out_loss: 0.2023\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.1976 - main_out_loss: 0.1947 - combo_out_loss: 0.2095\n",
      " 352/1557 [=====>........................] - ETA: 1s - loss: 0.1952 - main_out_loss: 0.1933 - combo_out_loss: 0.2030\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.1964 - main_out_loss: 0.1948 - combo_out_loss: 0.2030\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.1980 - main_out_loss: 0.1951 - combo_out_loss: 0.2097\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.2003 - main_out_loss: 0.1982 - combo_out_loss: 0.2089\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.2010 - main_out_loss: 0.1995 - combo_out_loss: 0.2073\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.2037 - main_out_loss: 0.2022 - combo_out_loss: 0.2098\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.2055 - main_out_loss: 0.2043 - combo_out_loss: 0.2102\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.2098 - main_out_loss: 0.2093 - combo_out_loss: 0.2122\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.2076 - main_out_loss: 0.2066 - combo_out_loss: 0.2113\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.2066 - main_out_loss: 0.2057 - combo_out_loss: 0.2104\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.2050 - main_out_loss: 0.2040 - combo_out_loss: 0.2089\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.2070 - main_out_loss: 0.2068 - combo_out_loss: 0.2078\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.2064 - main_out_loss: 0.2065 - combo_out_loss: 0.2060\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.2081 - main_out_loss: 0.2082 - combo_out_loss: 0.2075\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.2089 - main_out_loss: 0.2091 - combo_out_loss: 0.2083\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.2081 - main_out_loss: 0.2083 - combo_out_loss: 0.2076\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.2080 - main_out_loss: 0.2083 - combo_out_loss: 0.2071\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.2084 - main_out_loss: 0.2089 - combo_out_loss: 0.2064\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.2089 - main_out_loss: 0.2093 - combo_out_loss: 0.2076\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.2092 - main_out_loss: 0.2095 - combo_out_loss: 0.2080\u001b[0m\n",
      "\u001b[31mEpoch 100/100\n",
      "\n",
      "  32/1557 [..............................] - ETA: 1s - loss: 0.1967 - main_out_loss: 0.1964 - combo_out_loss: 0.1981\n",
      "  96/1557 [>.............................] - ETA: 1s - loss: 0.1721 - main_out_loss: 0.1655 - combo_out_loss: 0.1986\n",
      " 160/1557 [==>...........................] - ETA: 1s - loss: 0.1902 - main_out_loss: 0.1828 - combo_out_loss: 0.2198\n",
      " 224/1557 [===>..........................] - ETA: 1s - loss: 0.1992 - main_out_loss: 0.1943 - combo_out_loss: 0.2187\n",
      " 288/1557 [====>.........................] - ETA: 1s - loss: 0.1988 - main_out_loss: 0.1931 - combo_out_loss: 0.2219\u001b[0m\n",
      "\u001b[31m 352/1557 [=====>........................] - ETA: 1s - loss: 0.1965 - main_out_loss: 0.1919 - combo_out_loss: 0.2150\n",
      " 416/1557 [=======>......................] - ETA: 1s - loss: 0.2019 - main_out_loss: 0.1976 - combo_out_loss: 0.2187\n",
      " 480/1557 [========>.....................] - ETA: 1s - loss: 0.1964 - main_out_loss: 0.1916 - combo_out_loss: 0.2153\n",
      " 544/1557 [=========>....................] - ETA: 1s - loss: 0.1955 - main_out_loss: 0.1915 - combo_out_loss: 0.2114\n",
      " 608/1557 [==========>...................] - ETA: 1s - loss: 0.1968 - main_out_loss: 0.1942 - combo_out_loss: 0.2069\n",
      " 672/1557 [===========>..................] - ETA: 1s - loss: 0.1979 - main_out_loss: 0.1954 - combo_out_loss: 0.2076\n",
      " 736/1557 [=============>................] - ETA: 0s - loss: 0.1994 - main_out_loss: 0.1976 - combo_out_loss: 0.2067\n",
      " 800/1557 [==============>...............] - ETA: 0s - loss: 0.1984 - main_out_loss: 0.1965 - combo_out_loss: 0.2059\n",
      " 864/1557 [===============>..............] - ETA: 0s - loss: 0.1953 - main_out_loss: 0.1935 - combo_out_loss: 0.2026\n",
      " 928/1557 [================>.............] - ETA: 0s - loss: 0.1952 - main_out_loss: 0.1935 - combo_out_loss: 0.2019\n",
      " 992/1557 [==================>...........] - ETA: 0s - loss: 0.1964 - main_out_loss: 0.1946 - combo_out_loss: 0.2034\u001b[0m\n",
      "\u001b[31m1056/1557 [===================>..........] - ETA: 0s - loss: 0.1966 - main_out_loss: 0.1952 - combo_out_loss: 0.2021\u001b[0m\n",
      "\u001b[31m1120/1557 [====================>.........] - ETA: 0s - loss: 0.1964 - main_out_loss: 0.1951 - combo_out_loss: 0.2017\u001b[0m\n",
      "\u001b[31m1184/1557 [=====================>........] - ETA: 0s - loss: 0.1975 - main_out_loss: 0.1966 - combo_out_loss: 0.2014\u001b[0m\n",
      "\u001b[31m1248/1557 [=======================>......] - ETA: 0s - loss: 0.1962 - main_out_loss: 0.1952 - combo_out_loss: 0.2001\u001b[0m\n",
      "\u001b[31m1312/1557 [========================>.....] - ETA: 0s - loss: 0.1951 - main_out_loss: 0.1940 - combo_out_loss: 0.1994\u001b[0m\n",
      "\u001b[31m1376/1557 [=========================>....] - ETA: 0s - loss: 0.1952 - main_out_loss: 0.1940 - combo_out_loss: 0.1999\u001b[0m\n",
      "\u001b[31m1440/1557 [==========================>...] - ETA: 0s - loss: 0.1957 - main_out_loss: 0.1942 - combo_out_loss: 0.2017\u001b[0m\n",
      "\u001b[31m1504/1557 [===========================>..] - ETA: 0s - loss: 0.1948 - main_out_loss: 0.1933 - combo_out_loss: 0.2008\u001b[0m\n",
      "\u001b[31m1557/1557 [==============================] - 2s 1ms/step - loss: 0.1953 - main_out_loss: 0.1937 - combo_out_loss: 0.2016\u001b[0m\n",
      "\u001b[31mTraining complete.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n",
      "Billable seconds: 257\n"
     ]
    }
   ],
   "source": [
    "# Instantiate estimator with container image of artifact and backend EC2 instance(s)  \n",
    "rnn = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "# Train the model\n",
    "rnn.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: rnn-forecast009-2018-07-26-23-40-34-329\n",
      "INFO:sagemaker:Creating endpoint with name rnn-forecast009-2018-07-26-23-33-55-313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# Create an endpoint on a web server\n",
    "predictor = rnn.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model to forecast future trends of stock values \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Prepare a few test samples (non-overlapping time windows in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and covariates \n",
    "target = 'STOCKA'     \n",
    "covariates = ['STOCKB'] \n",
    "\n",
    "# Define time spans for each sample\n",
    "lag = 22\n",
    "horiz = 10\n",
    "\n",
    "# Download test data file created during training in current path\n",
    "df = pd.read_csv('./testdata.csv')\n",
    "sam1 = df[df.symbol == target]\n",
    "sam2 = df[df.symbol == covariates[0]]\n",
    "\n",
    "# From test set, create 4 non-overlapping time series that span both lag and horizon\n",
    "span = lag + horiz + 1 \n",
    "for i in range(0,4):\n",
    "    j = i + 1\n",
    "    start = span * i\n",
    "    end = span * j\n",
    "    sam = pd.concat([sam1[start:end],sam2[start:end]],axis=0)\n",
    "    sam.to_csv('./testdata/test' + str(j) + '.csv',index=0)\n",
    "# Upload test data files to S3\n",
    "testdata_loc = sess.upload_data('./testdata', key_prefix='testdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Produce forecast for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data files and use model to make predictions (if error message, check S3 read permission for files in testdata)\n",
    "f = []\n",
    "pred = []\n",
    "for k in range(0,4):\n",
    "    f.append('https://s3.amazonaws.com/' + testdata_loc[5:] + '/test' + str(k+1) + '.csv') # Avoid s3fs issue\n",
    "    pred.append(predictor.predict(f[k]).decode('utf-8')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Evaluate and vizualize performance for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1, Day of forecast: 2016-05-24, MAE = 10.0\n",
      "Sample 2, Day of forecast: 2016-07-12, MAE = 24.0\n",
      "Sample 3, Day of forecast: 2016-08-26, MAE = 14.0\n",
      "Sample 4, Day of forecast: 2016-10-13, MAE = 15.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c0e9fa518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop over each sample of test data and compare observed vs. forecasted horizons\n",
    "# Note news data was not available after 7/1/2016, so only first sample uses this feature\n",
    "\n",
    "plt.figure(0,figsize=(16,10))\n",
    "\n",
    "for k in range(0,4):\n",
    "\n",
    "    # Read forecasted data \n",
    "    df = pd.read_csv(StringIO(pred[k]), header=None, index_col = 0)\n",
    "    fcst = df.as_matrix()\n",
    "\n",
    "    # Read observed data\n",
    "    df = pd.read_csv(f[k]) \n",
    "    odf = df[df.symbol == target]\n",
    "    odf[\"adjclose\"] = odf.close \n",
    "    odf.drop(['close','symbol'], 1, inplace=True)\n",
    "    obs = odf.as_matrix()\n",
    "\n",
    "    # Find overlaping horizons in observed data \n",
    "    lags = []\n",
    "    horizons = []\n",
    "    dates = []\n",
    "    nsample = len(obs) - lag - horiz  \n",
    "    for i in range(nsample):\n",
    "        lags.append(obs[i: i + lag , -1])\n",
    "        horizons.append(obs[i + lag : i + lag + horiz, -1])\n",
    "        dates.append(obs[i + lag : i + lag + horiz, 0])\n",
    "    lags = np.array(lags)\n",
    "    horizons = np.array(horizons)\n",
    "    dates = np.array(dates)\n",
    "    \n",
    "    # Save sample 1 references for benchmark studies\n",
    "    if(k == 0): \n",
    "        fcst1 = fcst\n",
    "        horizons1 = horizons\n",
    "        dates1 = dates\n",
    "\n",
    "    # Compute MAE\n",
    "    s = fcst.shape\n",
    "    sum = 0\n",
    "    for i in range(s[0]):\n",
    "        dif = abs(fcst[i,0] - horizons[0,i])\n",
    "        sum += dif\n",
    "    mae = sum / s[0]\n",
    "    print('Sample ', k+1, ', Day of forecast: ', dates[0][0], ', MAE = ',round(mae), sep = '')\n",
    "\n",
    "    # Plot observed vs. forecasted horizons\n",
    "    xax = np.array([])\n",
    "    xax = [np.append(xax,i) for i in range(1,horiz+1)]\n",
    "    plt.subplot('22' + str(k+1))\n",
    "    mpl.rcParams['font.size']=14\n",
    "    plt.plot(xax,fcst[:],color='#FF9900',marker='s', label=\"Fcst\",linewidth=5,markersize=10)\n",
    "    plt.plot(xax,horizons[0,:],color='#A9A9A9',marker='s', label=\"Obs\",linewidth=5,markersize=10)\n",
    "    plt.xlabel('Time (days)')\n",
    "    plt.ylabel('Stock value ($)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Day: '+ dates[0][0],loc='right')\n",
    "    miny = round(min(horizons[0,:])/10)*10 - 50\n",
    "    maxy = miny + 121\n",
    "    plt.ylim(miny,maxy)\n",
    "    plt.yticks(np.arange(miny,maxy,20))\n",
    "    # plt.xticks(xax, dates)\n",
    "\n",
    "plt.savefig('results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance benchmark analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Compare with performance of ARIMAX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c0e96b898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Vizualize time series trends (auto-correlations)\n",
    "\n",
    "# Let us look at the entire dataset\n",
    "file = './inputdata/stockprices.csv'\n",
    "d = pd.read_csv(file, index_col = 0)\n",
    "\n",
    "# Select covariates of interest and plot ACF for each\n",
    "data = d[d.symbol == target]\n",
    "\n",
    "# Plot Auto-correlatoin and partial auto-correlation functions \n",
    "acf_clo = acf(data['close'].diff().iloc[1:], nlags=10) # check past 2 weeks\n",
    "acf_vol = acf(data['volume'].diff().iloc[1:], nlags=10) \n",
    "pacf_clo = pacf(data['close'].iloc[:], nlags=10, method='ols')\n",
    "pacf_vol = pacf(data['volume'].iloc[:], nlags=10, method='ols')\n",
    "plt.figure(1,figsize=(16,5))\n",
    "\n",
    "plt.subplot(121) \n",
    "plt.plot(acf_vol,linestyle='--',color='black', label=\"Volume ACF\",linewidth=2, markersize = 5)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(data)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(data)),linestyle='--',color='gray')\n",
    "plt.plot(acf_clo,color='#A9A9A9',marker='s',label=\"Stock value ACF\",linewidth=5, markersize = 10)\n",
    "plt.xlim(-0.5,10.5); plt.ylim(-0.5,1.1)\n",
    "plt.xlabel('Lag (days)'); plt.legend(loc='upper right'); plt.title('Autocorrelation',loc='right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(pacf_vol,linestyle='--',color='black', label=\"Volume PACF\",linewidth=2, markersize = 5)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(data)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(data)),linestyle='--',color='gray')\n",
    "plt.plot(pacf_clo,color='#A9A9A9',marker='s',label=\"Stock value PACF\",linewidth=5, markersize = 10)\n",
    "plt.xlim(-0.5,10.5); plt.ylim(-0.5,1.1)\n",
    "plt.xlabel('Lag (days)'); plt.legend(loc='upper right'); plt.title('Partial Autocorrelation',loc='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./acf_pacf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyflux in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numdifftools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux)\n",
      "Requirement already satisfied: patsy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux)\n",
      "Requirement already satisfied: algopy>=0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from numdifftools->pyflux)\n",
      "Requirement already satisfied: setuptools>=9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from numdifftools->pyflux)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from patsy->pyflux)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas->pyflux)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas->pyflux)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install pyflux # Install pyflux that contains ARIMA with exogenous variables (ARIMAx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting covariate time lines, please be patient\n",
      "--- Done ---\n",
      "Grid search for ARIMA hyper-parameters (p,d,q)\n",
      "(p,q) = (2,2)\n",
      "MAE = 136.0\n",
      "(p,q) = (2,3)\n",
      "MAE = 22.0\n",
      "(p,q) = (2,4)\n",
      "MAE = 81.0\n",
      "(p,q) = (2,5)\n",
      "MAE = 120.0\n",
      "(p,q) = (3,2)\n",
      "MAE = 8.0\n",
      "(p,q) = (3,3)\n",
      "MAE = 10.0\n",
      "(p,q) = (3,4)\n",
      "MAE = 21.0\n",
      "(p,q) = (3,5)\n",
      "MAE = 66.0\n",
      "(p,q) = (4,2)\n",
      "MAE = 94.0\n",
      "(p,q) = (4,3)\n",
      "MAE = 92.0\n",
      "(p,q) = (4,4)\n",
      "MAE = 15.0\n",
      "(p,q) = (4,5)\n",
      "MAE = 35.0\n",
      "(p,q) = (5,2)\n",
      "MAE = 5.0\n",
      "(p,q) = (5,3)\n",
      "MAE = 77.0\n",
      "(p,q) = (5,4)\n",
      "MAE = 74.0\n",
      "(p,q) = (5,5)\n",
      "MAE = 23.0\n",
      "--- Done ---\n",
      "Produce a forecast with chosen (p,d,q)\n",
      "Normal ARIMAX(3,0,3)                                                                                      \n",
      "======================================================= ==================================================\n",
      "Dependent Variable: close                               Method: MLE                                       \n",
      "Start Date: 2010-01-07                                  Log Likelihood: -25623.4156                       \n",
      "End Date: 2016-05-24                                    AIC: 51270.8312                                   \n",
      "Number of observations: 1606                            BIC: 51335.4092                                   \n",
      "==========================================================================================================\n",
      "Latent Variable                          Estimate   Std Error  z        P>|z|    95% C.I.                 \n",
      "======================================== ========== ========== ======== ======== =========================\n",
      "AR(1)                                    0.3646     0.0175     20.8052  0.0      (0.3302 | 0.3989)        \n",
      "AR(2)                                    0.3438     0.0208     16.5509  0.0      (0.3031 | 0.3845)        \n",
      "AR(3)                                    0.3353     0.0147     22.8293  0.0      (0.3065 | 0.3641)        \n",
      "MA(1)                                    0.3784     0.0126     29.9757  0.0      (0.3537 | 0.4032)        \n",
      "MA(2)                                    0.336      0.0142     23.6052  0.0      (0.3081 | 0.3639)        \n",
      "MA(3)                                    0.3186     0.0028     114.1329 0.0      (0.3131 | 0.3241)        \n",
      "Beta 1                                   -0.0008    0.3438     -0.0023  0.9982   (-0.6746 | 0.673)        \n",
      "Beta volume                              0.0        0.0        8.2704   0.0      (0.0 | 0.0)              \n",
      "Beta STOCKBclose                         -0.0309    0.0017     -18.1658 0.0      (-0.0342 | -0.0275)      \n",
      "Beta STOCKBvolume                        0.0        0.0        2.2321   0.0256   (0.0 | 0.0)              \n",
      "Beta s                                   0.0        0.0418     0.0007   0.9994   (-0.0818 | 0.0819)       \n",
      "Normal Scale                             1.6401                                                           \n",
      "==========================================================================================================\n",
      "Forecasted:                   close\n",
      "date                  \n",
      "2016-05-11  706.489649\n",
      "2016-05-12  707.696774\n",
      "2016-05-13  715.543846\n",
      "2016-05-16  718.922866\n",
      "2016-05-17  723.173168\n",
      "2016-05-18  728.611850\n",
      "2016-05-19  733.472381\n",
      "2016-05-20  738.635685\n",
      "2016-05-23  744.020211\n",
      "2016-05-24  748.990342\n",
      "Observed:  [706.3216189658151 705.4624399659621 718.8932927601668 707.2947926159261\n",
      " 726.4835317756862 714.6745181486232 723.9255701536003 722.8790451892575\n",
      " 724.5534665133741 728.6536240571036]\n",
      "--- Done ---\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "import pyflux as pf\n",
    "\n",
    "# Download all data files created during training (training, test, sentiment) in current path\n",
    "# Benchmarking only on first sampled time series because news data not avaiulable after 7/1/2016\n",
    "trainfile = './traindata.csv'\n",
    "testfile = f[0]\n",
    "sentimentfile = './sentiment.csv'\n",
    "d1 = pd.read_csv(trainfile, index_col = 0)\n",
    "d2 = pd.read_csv(testfile, index_col = 0)\n",
    "d3 = pd.read_csv(sentimentfile, index_col = 0)\n",
    "\n",
    "# Select covariates of interest\n",
    "traindata = d1[d1.symbol == target]\n",
    "testdata = d2[d2.symbol == target]\n",
    "for covariate in covariates: # for now it replaces covariate, so to refine later\n",
    "    dummy1 = d1[d1.symbol == covariate]\n",
    "    dummy2 = d2[d2.symbol == covariate]\n",
    "    feat = covariate + 'close'\n",
    "    traindata[feat] = dummy1['close']\n",
    "    testdata[feat] = dummy2['close']    \n",
    "    feat = covariate + 'volume'\n",
    "    traindata[feat] = dummy1['volume']\n",
    "    testdata[feat] = dummy2['volume']\n",
    "    \n",
    "traindata.drop(['open','low','high','symbol'], 1, inplace=True) \n",
    "testdata.drop(['open','low','high','symbol'], 1, inplace=True) \n",
    "\n",
    "alldata = pd.concat([traindata,testdata],axis=0) # Seems it sees the test data, but I keep it because dates were weirdly shifted in past in predict step otherwise\n",
    "\n",
    "# Add market news sentiment data\n",
    "news = d3[d3.index <= alldata.index[-1]] # test data contains just one series so need to adjust sentiment series \n",
    "full = pd.concat([alldata,news],axis=1)\n",
    "news = news[news.index >= testdata.index[0]]\n",
    "testdata_s = pd.concat([testdata,news],axis=1)\n",
    "\n",
    "# Shift all covariate by horizon span to regress target on past (not future) of covariates = assume we don't know the future of covariate\n",
    "print('Shifting covariate time lines, please be patient')\n",
    "size = full.shape\n",
    "s = size[0] - horiz\n",
    "for i in range(0,s):\n",
    "    for j in range(0,len(full.columns)):\n",
    "        if j > 0: # Only shift covariates ('close' is in first column) \n",
    "            full.iloc[i,j] = full.iloc[i+horiz,j]  \n",
    "# Delete last span since it's redundant now\n",
    "full = full.iloc[0:s,:]  \n",
    "\n",
    "size = testdata_s.shape\n",
    "s = size[0] - horiz\n",
    "# Shift all covariate by horizon span to regress target on past of covariate = assume we don't know the future of covariate\n",
    "for i in range(0,s):\n",
    "    for j in range(0,len(testdata_s.columns)):\n",
    "        if j > 0: # Only shift covariates ('close' is in first column) \n",
    "            testdata_s.iloc[i,j] = testdata_s.iloc[i+horiz,j]  \n",
    "# Delete last span since it's redundant now\n",
    "testdata_s = testdata_s.iloc[0:s,:]  # Only keep exogenous variables for ARIMAX\n",
    "print('--- Done ---')\n",
    "\n",
    "# Grid search over hyper-parameters p, d, q\n",
    "print('Grid search for ARIMA hyper-parameters (p,d,q)')\n",
    "for p in range(2,6):\n",
    "    for q in range(2,6):\n",
    "        print('(p,q) = (', p,',',q,')',sep = '')\n",
    "        d=0\n",
    "        arimaxmodel = pf.ARIMAX(data=full, formula='close~1+volume+STOCKBclose+STOCKBvolume+s', \n",
    "                            ar=p, ma=q, integ=d) #, family=pf.Normal())\n",
    "        results = arimaxmodel.fit(\"MLE\")\n",
    "        # results.summary()\n",
    "        afcst = arimaxmodel.predict(h=horiz, oos_data=testdata_s[-horiz:]) # only exogenous variables are taken from oos_data in ARIMAx\n",
    "\n",
    "        #print('Forecasted: ',afcst)\n",
    "        #print('Observed: ', horizons[0,:])\n",
    "\n",
    "        # Get RMSE and MAE\n",
    "        s = afcst.shape\n",
    "        sum = 0\n",
    "        for i in range(s[0]):\n",
    "            dif = abs(afcst.iloc[i,0] - horizons1[0,i])\n",
    "            # print('step ',i,': ',round(dif), sep = '')\n",
    "            sum += dif\n",
    "        mae = sum / s[0]\n",
    "        print('MAE = ',round(mae), sep = '')\n",
    "print('--- Done ---')\n",
    "\n",
    "# Re-run ARIMAx with best (p,q)\n",
    "print('Produce a forecast with chosen (p,d,q)')\n",
    "p=3\n",
    "q=3\n",
    "d=0\n",
    "arimaxmodel = pf.ARIMAX(data=full, formula='close~1+volume+STOCKBclose+STOCKBvolume+s', \n",
    "                ar=p, ma=q, integ=d) #, family=pf.Normal())\n",
    "results = arimaxmodel.fit(\"MLE\")\n",
    "results.summary()\n",
    "afcst = arimaxmodel.predict(h=horiz, oos_data=testdata_s[-horiz:]) \n",
    "print('Forecasted: ',afcst)\n",
    "print('Observed: ', horizons1[0,:])\n",
    "print('--- Done ---')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Compare with performance of DeepAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: DeeparFinance-2018-07-26-23-21-04-610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:52 INFO 139979114559296] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:52 INFO 139979114559296] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'dropout_rate': u'0.1', u'mini_batch_size': u'32', u'learning_rate': u'0.001', u'num_layers': u'5', u'prediction_length': u'10', u'epochs': u'100', u'embedding_dimension': u'10', u'time_freq': u'D', u'context_length': u'22', u'num_cells': u'100', u'cardinality': u'3', u'likelihood': u'gaussian', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:52 INFO 139979114559296] Final configuration: {u'dropout_rate': u'0.1', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_layers': u'5', u'epochs': u'100', u'embedding_dimension': u'10', u'num_cells': u'100', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'gaussian', u'num_dynamic_feat': u'auto', u'cardinality': u'3', u'_num_gpus': u'auto', u'prediction_length': u'10', u'time_freq': u'D', u'context_length': u'22', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:52 INFO 139979114559296] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:52 INFO 139979114559296] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:52 INFO 139979114559296] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Training set statistics:\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Real time series\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] number of time series: 30\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] number of observations: 4827\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] mean target length: 160\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] min/mean/max target: -3.13000011444/243.79538004/777.452331543\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] mean abs(target): 243.948183022\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] contains missing values: no\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Small number of time series. Doing 10 number of passes over dataset per epoch.\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Test set statistics:\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Real time series\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] number of time series: 30\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] number of observations: 270\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] mean target length: 9\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] min/mean/max target: -2.19000005722/241.47780436/721.465026855\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] mean abs(target): 241.607804358\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] contains missing values: no\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] nvidia-smi took: 0.0251820087433 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Create Store: local\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 111.68313026428223, \"sum\": 111.68313026428223, \"min\": 111.68313026428223}}, \"EndTime\": 1532647493.148679, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647493.03485}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 284.82794761657715, \"sum\": 284.82794761657715, \"min\": 284.82794761657715}}, \"EndTime\": 1532647493.31977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647493.148741}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:53 INFO 139979114559296] Epoch[0] Batch[0] avg_epoch_loss=9.034881\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] Epoch[0] Batch[5] avg_epoch_loss=6.111659\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] Epoch[0] Batch [5]#011Speed: 248.61 samples/sec#011loss=6.111659\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] Epoch[0] Batch[10] avg_epoch_loss=5.695360\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] Epoch[0] Batch [10]#011Speed: 246.70 samples/sec#011loss=5.195802\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] processed a total of 334 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"update.time\": {\"count\": 1, \"max\": 1639.308214187622, \"sum\": 1639.308214187622, \"min\": 1639.308214187622}}, \"EndTime\": 1532647494.959226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647493.319833}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=203.73108729 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:54 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_ce3c9132-8f65-4440-b88f-1ec03c12dfff-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.761106491088867, \"sum\": 22.761106491088867, \"min\": 22.761106491088867}}, \"EndTime\": 1532647494.982449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647494.959302}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:55 INFO 139979114559296] Epoch[1] Batch[0] avg_epoch_loss=4.423985\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:55 INFO 139979114559296] Epoch[1] Batch[5] avg_epoch_loss=4.465476\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:55 INFO 139979114559296] Epoch[1] Batch [5]#011Speed: 245.59 samples/sec#011loss=4.465476\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] Epoch[1] Batch[10] avg_epoch_loss=4.435691\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] Epoch[1] Batch [10]#011Speed: 255.58 samples/sec#011loss=4.399949\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] processed a total of 336 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1500.3740787506104, \"sum\": 1500.3740787506104, \"min\": 1500.3740787506104}}, \"EndTime\": 1532647496.482924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647494.982505}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=223.928494716 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_7f39664d-0283-4f59-bab3-a8d11c72dc7c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 30.906200408935547, \"sum\": 30.906200408935547, \"min\": 30.906200408935547}}, \"EndTime\": 1532647496.514267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647496.482997}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:56 INFO 139979114559296] Epoch[2] Batch[0] avg_epoch_loss=4.385714\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:57 INFO 139979114559296] Epoch[2] Batch[5] avg_epoch_loss=4.274063\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:57 INFO 139979114559296] Epoch[2] Batch [5]#011Speed: 247.43 samples/sec#011loss=4.274063\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:57 INFO 139979114559296] processed a total of 314 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1421.7209815979004, \"sum\": 1421.7209815979004, \"min\": 1421.7209815979004}}, \"EndTime\": 1532647497.9361, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647496.514328}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:57 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=220.840904544 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:57 INFO 139979114559296] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:57 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:57 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_8aa1e3bb-b4b0-4c2a-a243-9e0e0605cd11-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.769990921020508, \"sum\": 31.769990921020508, \"min\": 31.769990921020508}}, \"EndTime\": 1532647497.968308, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647497.936183}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:58 INFO 139979114559296] Epoch[3] Batch[0] avg_epoch_loss=4.125422\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:58 INFO 139979114559296] Epoch[3] Batch[5] avg_epoch_loss=3.674176\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:58 INFO 139979114559296] Epoch[3] Batch [5]#011Speed: 252.47 samples/sec#011loss=3.674176\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] Epoch[3] Batch[10] avg_epoch_loss=3.944433\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] Epoch[3] Batch [10]#011Speed: 251.04 samples/sec#011loss=4.268741\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] processed a total of 331 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1506.2389373779297, \"sum\": 1506.2389373779297, \"min\": 1506.2389373779297}}, \"EndTime\": 1532647499.474666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647497.968376}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=219.737034377 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_7de59946-58e1-4200-9f58-b0e412537217-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.042098999023438, \"sum\": 31.042098999023438, \"min\": 31.042098999023438}}, \"EndTime\": 1532647499.506148, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647499.47474}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:24:59 INFO 139979114559296] Epoch[4] Batch[0] avg_epoch_loss=6.567143\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:00 INFO 139979114559296] Epoch[4] Batch[5] avg_epoch_loss=5.227417\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:00 INFO 139979114559296] Epoch[4] Batch [5]#011Speed: 237.95 samples/sec#011loss=5.227417\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] Epoch[4] Batch[10] avg_epoch_loss=4.759077\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] Epoch[4] Batch [10]#011Speed: 243.47 samples/sec#011loss=4.197068\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] processed a total of 341 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1563.6169910430908, \"sum\": 1563.6169910430908, \"min\": 1563.6169910430908}}, \"EndTime\": 1532647501.06988, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647499.50621}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=218.069167617 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] Epoch[5] Batch[0] avg_epoch_loss=4.442435\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] Epoch[5] Batch[5] avg_epoch_loss=4.959462\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:01 INFO 139979114559296] Epoch[5] Batch [5]#011Speed: 239.93 samples/sec#011loss=4.959462\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:02 INFO 139979114559296] processed a total of 314 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1433.7880611419678, \"sum\": 1433.7880611419678, \"min\": 1433.7880611419678}}, \"EndTime\": 1532647502.504035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647501.06995}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:02 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=218.986087604 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:02 INFO 139979114559296] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:02 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:02 INFO 139979114559296] Epoch[6] Batch[0] avg_epoch_loss=5.253386\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:03 INFO 139979114559296] Epoch[6] Batch[5] avg_epoch_loss=4.821742\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:03 INFO 139979114559296] Epoch[6] Batch [5]#011Speed: 248.67 samples/sec#011loss=4.821742\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:03 INFO 139979114559296] processed a total of 312 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1365.2970790863037, \"sum\": 1365.2970790863037, \"min\": 1365.2970790863037}}, \"EndTime\": 1532647503.869767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647502.504095}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:03 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=228.500943689 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:03 INFO 139979114559296] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:03 INFO 139979114559296] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:04 INFO 139979114559296] Epoch[7] Batch[0] avg_epoch_loss=3.866260\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:04 INFO 139979114559296] Epoch[7] Batch[5] avg_epoch_loss=4.407284\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:04 INFO 139979114559296] Epoch[7] Batch [5]#011Speed: 249.39 samples/sec#011loss=4.407284\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:05 INFO 139979114559296] processed a total of 312 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1418.9000129699707, \"sum\": 1418.9000129699707, \"min\": 1418.9000129699707}}, \"EndTime\": 1532647505.289088, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647503.869831}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:05 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=219.871279929 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:05 INFO 139979114559296] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:05 INFO 139979114559296] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:05 INFO 139979114559296] Epoch[8] Batch[0] avg_epoch_loss=3.776031\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] Epoch[8] Batch[5] avg_epoch_loss=4.027073\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] Epoch[8] Batch [5]#011Speed: 235.17 samples/sec#011loss=4.027073\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] processed a total of 313 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1385.908842086792, \"sum\": 1385.908842086792, \"min\": 1385.908842086792}}, \"EndTime\": 1532647506.67539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647505.289155}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=225.824999953 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_ee4c815f-f692-4f03-a833-c95d3d34c53b-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.04996681213379, \"sum\": 31.04996681213379, \"min\": 31.04996681213379}}, \"EndTime\": 1532647506.70687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647506.675473}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:06 INFO 139979114559296] Epoch[9] Batch[0] avg_epoch_loss=4.082995\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:07 INFO 139979114559296] Epoch[9] Batch[5] avg_epoch_loss=4.007420\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:07 INFO 139979114559296] Epoch[9] Batch [5]#011Speed: 250.17 samples/sec#011loss=4.007420\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] Epoch[9] Batch[10] avg_epoch_loss=3.899362\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] Epoch[9] Batch [10]#011Speed: 249.43 samples/sec#011loss=3.769691\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] processed a total of 342 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1520.474910736084, \"sum\": 1520.474910736084, \"min\": 1520.474910736084}}, \"EndTime\": 1532647508.22746, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647506.706935}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=224.914028536 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_ce5a9b90-801e-4b84-8b9e-d08d31d6db05-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 27.200937271118164, \"sum\": 27.200937271118164, \"min\": 27.200937271118164}}, \"EndTime\": 1532647508.255121, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647508.227533}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:08 INFO 139979114559296] Epoch[10] Batch[0] avg_epoch_loss=3.288111\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] Epoch[10] Batch[5] avg_epoch_loss=3.713873\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] Epoch[10] Batch [5]#011Speed: 244.31 samples/sec#011loss=3.713873\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] processed a total of 318 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1370.021104812622, \"sum\": 1370.021104812622, \"min\": 1370.021104812622}}, \"EndTime\": 1532647509.62525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647508.255179}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=232.09475421 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_e4407a71-09f0-4bfe-87d6-22464a459ae2-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.90016746520996, \"sum\": 31.90016746520996, \"min\": 31.90016746520996}}, \"EndTime\": 1532647509.657576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647509.625324}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:09 INFO 139979114559296] Epoch[11] Batch[0] avg_epoch_loss=4.439308\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:10 INFO 139979114559296] Epoch[11] Batch[5] avg_epoch_loss=3.572998\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:10 INFO 139979114559296] Epoch[11] Batch [5]#011Speed: 253.98 samples/sec#011loss=3.572998\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] processed a total of 317 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1387.4170780181885, \"sum\": 1387.4170780181885, \"min\": 1387.4170780181885}}, \"EndTime\": 1532647511.045148, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647509.657648}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=228.461551335 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_98effd82-8f09-4659-b797-58633b55b460-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.843982696533203, \"sum\": 20.843982696533203, \"min\": 20.843982696533203}}, \"EndTime\": 1532647511.066588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647511.045208}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] Epoch[12] Batch[0] avg_epoch_loss=3.461146\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] Epoch[12] Batch[5] avg_epoch_loss=3.377252\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:11 INFO 139979114559296] Epoch[12] Batch [5]#011Speed: 246.75 samples/sec#011loss=3.377252\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:12 INFO 139979114559296] processed a total of 307 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1379.9190521240234, \"sum\": 1379.9190521240234, \"min\": 1379.9190521240234}}, \"EndTime\": 1532647512.446621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647511.066649}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:12 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=222.458791739 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:12 INFO 139979114559296] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:12 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:12 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_5eeec6db-b622-4ea6-9d43-d52ff249e56c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.579017639160156, \"sum\": 31.579017639160156, \"min\": 31.579017639160156}}, \"EndTime\": 1532647512.478628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647512.446698}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:12 INFO 139979114559296] Epoch[13] Batch[0] avg_epoch_loss=9.274599\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:13 INFO 139979114559296] Epoch[13] Batch[5] avg_epoch_loss=5.608869\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:13 INFO 139979114559296] Epoch[13] Batch [5]#011Speed: 248.66 samples/sec#011loss=5.608869\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:13 INFO 139979114559296] processed a total of 284 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1244.399070739746, \"sum\": 1244.399070739746, \"min\": 1244.399070739746}}, \"EndTime\": 1532647513.723152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647512.478698}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:13 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=228.204636998 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:13 INFO 139979114559296] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:13 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:13 INFO 139979114559296] Epoch[14] Batch[0] avg_epoch_loss=5.367581\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:14 INFO 139979114559296] Epoch[14] Batch[5] avg_epoch_loss=4.874129\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:14 INFO 139979114559296] Epoch[14] Batch [5]#011Speed: 248.33 samples/sec#011loss=4.874129\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:15 INFO 139979114559296] Epoch[14] Batch[10] avg_epoch_loss=4.361242\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:15 INFO 139979114559296] Epoch[14] Batch [10]#011Speed: 249.20 samples/sec#011loss=3.745777\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:15 INFO 139979114559296] processed a total of 325 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1497.9190826416016, \"sum\": 1497.9190826416016, \"min\": 1497.9190826416016}}, \"EndTime\": 1532647515.221452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647513.723212}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:15 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=216.952329174 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:15 INFO 139979114559296] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:15 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:15 INFO 139979114559296] Epoch[15] Batch[0] avg_epoch_loss=4.668295\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:16 INFO 139979114559296] Epoch[15] Batch[5] avg_epoch_loss=4.334892\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:16 INFO 139979114559296] Epoch[15] Batch [5]#011Speed: 244.02 samples/sec#011loss=4.334892\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:16 INFO 139979114559296] processed a total of 316 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1422.0361709594727, \"sum\": 1422.0361709594727, \"min\": 1422.0361709594727}}, \"EndTime\": 1532647516.64387, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647515.221525}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:16 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=222.195335407 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:16 INFO 139979114559296] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:16 INFO 139979114559296] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:16 INFO 139979114559296] Epoch[16] Batch[0] avg_epoch_loss=4.881527\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:17 INFO 139979114559296] Epoch[16] Batch[5] avg_epoch_loss=4.272170\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:17 INFO 139979114559296] Epoch[16] Batch [5]#011Speed: 244.27 samples/sec#011loss=4.272170\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:18 INFO 139979114559296] processed a total of 297 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1401.5212059020996, \"sum\": 1401.5212059020996, \"min\": 1401.5212059020996}}, \"EndTime\": 1532647518.045815, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647516.643968}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:18 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=211.896593381 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:18 INFO 139979114559296] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:18 INFO 139979114559296] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:18 INFO 139979114559296] Epoch[17] Batch[0] avg_epoch_loss=3.455544\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:18 INFO 139979114559296] Epoch[17] Batch[5] avg_epoch_loss=4.290712\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:18 INFO 139979114559296] Epoch[17] Batch [5]#011Speed: 249.70 samples/sec#011loss=4.290712\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:19 INFO 139979114559296] Epoch[17] Batch[10] avg_epoch_loss=3.951891\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:19 INFO 139979114559296] Epoch[17] Batch [10]#011Speed: 252.92 samples/sec#011loss=3.545305\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:19 INFO 139979114559296] processed a total of 332 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1498.236894607544, \"sum\": 1498.236894607544, \"min\": 1498.236894607544}}, \"EndTime\": 1532647519.544421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647518.045887}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:19 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=221.578386691 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:19 INFO 139979114559296] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:19 INFO 139979114559296] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:19 INFO 139979114559296] Epoch[18] Batch[0] avg_epoch_loss=3.628349\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:20 INFO 139979114559296] Epoch[18] Batch[5] avg_epoch_loss=3.843013\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:20 INFO 139979114559296] Epoch[18] Batch [5]#011Speed: 253.76 samples/sec#011loss=3.843013\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:25:20 INFO 139979114559296] processed a total of 304 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1367.4030303955078, \"sum\": 1367.4030303955078, \"min\": 1367.4030303955078}}, \"EndTime\": 1532647520.912216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647519.544491}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:20 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=222.304121524 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:20 INFO 139979114559296] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:20 INFO 139979114559296] loss did not improve for 6 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:21 INFO 139979114559296] Epoch[19] Batch[0] avg_epoch_loss=3.310697\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:21 INFO 139979114559296] Epoch[19] Batch[5] avg_epoch_loss=3.544168\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:21 INFO 139979114559296] Epoch[19] Batch [5]#011Speed: 249.54 samples/sec#011loss=3.544168\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:22 INFO 139979114559296] Epoch[19] Batch[10] avg_epoch_loss=3.611414\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:22 INFO 139979114559296] Epoch[19] Batch [10]#011Speed: 254.52 samples/sec#011loss=3.692110\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:22 INFO 139979114559296] processed a total of 341 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1498.5918998718262, \"sum\": 1498.5918998718262, \"min\": 1498.5918998718262}}, \"EndTime\": 1532647522.411258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647520.912276}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:22 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=227.530685894 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:22 INFO 139979114559296] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:22 INFO 139979114559296] loss did not improve for 7 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:22 INFO 139979114559296] Epoch[20] Batch[0] avg_epoch_loss=3.551476\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:23 INFO 139979114559296] Epoch[20] Batch[5] avg_epoch_loss=3.377629\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:23 INFO 139979114559296] Epoch[20] Batch [5]#011Speed: 249.44 samples/sec#011loss=3.377629\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:23 INFO 139979114559296] processed a total of 301 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1395.7228660583496, \"sum\": 1395.7228660583496, \"min\": 1395.7228660583496}}, \"EndTime\": 1532647523.8074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647522.411331}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:23 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=215.639961678 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:23 INFO 139979114559296] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:23 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:23 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_237260ad-2f17-4c3b-a7cc-f2222e13e98d-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.528099060058594, \"sum\": 23.528099060058594, \"min\": 23.528099060058594}}, \"EndTime\": 1532647523.83151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647523.807464}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:24 INFO 139979114559296] Epoch[21] Batch[0] avg_epoch_loss=3.276238\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:24 INFO 139979114559296] Epoch[21] Batch[5] avg_epoch_loss=4.238965\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:24 INFO 139979114559296] Epoch[21] Batch [5]#011Speed: 255.83 samples/sec#011loss=4.238965\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:25 INFO 139979114559296] Epoch[21] Batch[10] avg_epoch_loss=3.890251\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:25 INFO 139979114559296] Epoch[21] Batch [10]#011Speed: 242.68 samples/sec#011loss=3.471794\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:25 INFO 139979114559296] processed a total of 333 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1491.1439418792725, \"sum\": 1491.1439418792725, \"min\": 1491.1439418792725}}, \"EndTime\": 1532647525.322789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647523.831571}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:25 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=223.301414644 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:25 INFO 139979114559296] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:25 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:25 INFO 139979114559296] Epoch[22] Batch[0] avg_epoch_loss=3.985705\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] Epoch[22] Batch[5] avg_epoch_loss=3.536364\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] Epoch[22] Batch [5]#011Speed: 242.92 samples/sec#011loss=3.536364\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] Epoch[22] Batch[10] avg_epoch_loss=3.434103\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] Epoch[22] Batch [10]#011Speed: 250.17 samples/sec#011loss=3.311389\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] processed a total of 359 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1639.3589973449707, \"sum\": 1639.3589973449707, \"min\": 1639.3589973449707}}, \"EndTime\": 1532647526.96258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647525.322846}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=218.973191345 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:26 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:27 INFO 139979114559296] Epoch[23] Batch[0] avg_epoch_loss=3.722595\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:27 INFO 139979114559296] Epoch[23] Batch[5] avg_epoch_loss=3.354486\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:27 INFO 139979114559296] Epoch[23] Batch [5]#011Speed: 243.63 samples/sec#011loss=3.354486\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:28 INFO 139979114559296] processed a total of 310 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1400.561809539795, \"sum\": 1400.561809539795, \"min\": 1400.561809539795}}, \"EndTime\": 1532647528.363518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647526.962655}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:28 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=221.322041815 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:28 INFO 139979114559296] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:28 INFO 139979114559296] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:28 INFO 139979114559296] Epoch[24] Batch[0] avg_epoch_loss=3.107939\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] Epoch[24] Batch[5] avg_epoch_loss=3.209343\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] Epoch[24] Batch [5]#011Speed: 249.80 samples/sec#011loss=3.209343\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] Epoch[24] Batch[10] avg_epoch_loss=3.344777\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] Epoch[24] Batch [10]#011Speed: 247.22 samples/sec#011loss=3.507297\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] processed a total of 345 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1527.9250144958496, \"sum\": 1527.9250144958496, \"min\": 1527.9250144958496}}, \"EndTime\": 1532647529.891836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647528.363595}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=225.781377433 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:29 INFO 139979114559296] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:30 INFO 139979114559296] Epoch[25] Batch[0] avg_epoch_loss=3.519124\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:30 INFO 139979114559296] Epoch[25] Batch[5] avg_epoch_loss=3.203533\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:30 INFO 139979114559296] Epoch[25] Batch [5]#011Speed: 254.08 samples/sec#011loss=3.203533\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:25:31 INFO 139979114559296] processed a total of 318 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1366.3330078125, \"sum\": 1366.3330078125, \"min\": 1366.3330078125}}, \"EndTime\": 1532647531.258592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647529.891904}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:31 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=232.71676395 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:31 INFO 139979114559296] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:31 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:31 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_b830770b-682c-4393-91cd-5f438c19fd99-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.18586540222168, \"sum\": 31.18586540222168, \"min\": 31.18586540222168}}, \"EndTime\": 1532647531.290328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647531.258689}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:31 INFO 139979114559296] Epoch[26] Batch[0] avg_epoch_loss=2.717103\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] Epoch[26] Batch[5] avg_epoch_loss=3.394854\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] Epoch[26] Batch [5]#011Speed: 235.56 samples/sec#011loss=3.394854\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] Epoch[26] Batch[10] avg_epoch_loss=3.434556\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] Epoch[26] Batch [10]#011Speed: 240.93 samples/sec#011loss=3.482199\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] processed a total of 353 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1682.7211380004883, \"sum\": 1682.7211380004883, \"min\": 1682.7211380004883}}, \"EndTime\": 1532647532.973163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647531.29039}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=209.767433874 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:32 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:33 INFO 139979114559296] Epoch[27] Batch[0] avg_epoch_loss=3.168737\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:33 INFO 139979114559296] Epoch[27] Batch[5] avg_epoch_loss=3.391544\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:33 INFO 139979114559296] Epoch[27] Batch [5]#011Speed: 246.24 samples/sec#011loss=3.391544\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:34 INFO 139979114559296] processed a total of 317 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1362.1129989624023, \"sum\": 1362.1129989624023, \"min\": 1362.1129989624023}}, \"EndTime\": 1532647534.33568, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647532.973223}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:34 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=232.707183605 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:34 INFO 139979114559296] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:34 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:34 INFO 139979114559296] Epoch[28] Batch[0] avg_epoch_loss=3.693230\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] Epoch[28] Batch[5] avg_epoch_loss=3.220289\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] Epoch[28] Batch [5]#011Speed: 246.25 samples/sec#011loss=3.220289\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] Epoch[28] Batch[10] avg_epoch_loss=3.282546\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] Epoch[28] Batch [10]#011Speed: 240.06 samples/sec#011loss=3.357254\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] processed a total of 321 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1552.3700714111328, \"sum\": 1552.3700714111328, \"min\": 1552.3700714111328}}, \"EndTime\": 1532647535.888443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647534.335757}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=206.766490836 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:35 INFO 139979114559296] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:36 INFO 139979114559296] Epoch[29] Batch[0] avg_epoch_loss=3.314634\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:36 INFO 139979114559296] Epoch[29] Batch[5] avg_epoch_loss=3.194028\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:36 INFO 139979114559296] Epoch[29] Batch [5]#011Speed: 250.71 samples/sec#011loss=3.194028\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:37 INFO 139979114559296] processed a total of 315 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1355.294942855835, \"sum\": 1355.294942855835, \"min\": 1355.294942855835}}, \"EndTime\": 1532647537.244174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647535.888511}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:37 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=232.402518281 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:37 INFO 139979114559296] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:37 INFO 139979114559296] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:37 INFO 139979114559296] Epoch[30] Batch[0] avg_epoch_loss=3.183424\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:38 INFO 139979114559296] Epoch[30] Batch[5] avg_epoch_loss=3.286554\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:38 INFO 139979114559296] Epoch[30] Batch [5]#011Speed: 239.53 samples/sec#011loss=3.286554\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:38 INFO 139979114559296] processed a total of 316 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1418.382167816162, \"sum\": 1418.382167816162, \"min\": 1418.382167816162}}, \"EndTime\": 1532647538.66303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647537.24425}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:38 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=222.764699713 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:38 INFO 139979114559296] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:38 INFO 139979114559296] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:38 INFO 139979114559296] Epoch[31] Batch[0] avg_epoch_loss=3.721353\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:39 INFO 139979114559296] Epoch[31] Batch[5] avg_epoch_loss=3.383723\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:39 INFO 139979114559296] Epoch[31] Batch [5]#011Speed: 255.88 samples/sec#011loss=3.383723\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:40 INFO 139979114559296] Epoch[31] Batch[10] avg_epoch_loss=3.419362\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:40 INFO 139979114559296] Epoch[31] Batch [10]#011Speed: 248.02 samples/sec#011loss=3.462128\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:40 INFO 139979114559296] processed a total of 349 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1513.7619972229004, \"sum\": 1513.7619972229004, \"min\": 1513.7619972229004}}, \"EndTime\": 1532647540.177318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647538.663149}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:40 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=230.534986364 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:40 INFO 139979114559296] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:40 INFO 139979114559296] loss did not improve for 6 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:40 INFO 139979114559296] Epoch[32] Batch[0] avg_epoch_loss=3.145633\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] Epoch[32] Batch[5] avg_epoch_loss=3.191475\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] Epoch[32] Batch [5]#011Speed: 245.42 samples/sec#011loss=3.191475\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] processed a total of 311 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1433.1300258636475, \"sum\": 1433.1300258636475, \"min\": 1433.1300258636475}}, \"EndTime\": 1532647541.610821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647540.177392}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=216.992363347 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_bf2a4ba0-5090-4352-91e6-746b732e2928-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 24.08885955810547, \"sum\": 24.08885955810547, \"min\": 24.08885955810547}}, \"EndTime\": 1532647541.635376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647541.610885}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:41 INFO 139979114559296] Epoch[33] Batch[0] avg_epoch_loss=2.872182\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:42 INFO 139979114559296] Epoch[33] Batch[5] avg_epoch_loss=3.022909\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:42 INFO 139979114559296] Epoch[33] Batch [5]#011Speed: 254.41 samples/sec#011loss=3.022909\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] Epoch[33] Batch[10] avg_epoch_loss=3.159337\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] Epoch[33] Batch [10]#011Speed: 247.89 samples/sec#011loss=3.323049\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] processed a total of 338 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1537.1119976043701, \"sum\": 1537.1119976043701, \"min\": 1537.1119976043701}}, \"EndTime\": 1532647543.172618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647541.635445}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=219.876554262 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_ed0344e1-90f5-48a7-8498-86bf66367de8-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 30.824899673461914, \"sum\": 30.824899673461914, \"min\": 30.824899673461914}}, \"EndTime\": 1532647543.203841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647543.172691}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:43 INFO 139979114559296] Epoch[34] Batch[0] avg_epoch_loss=3.159506\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] Epoch[34] Batch[5] avg_epoch_loss=3.192442\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] Epoch[34] Batch [5]#011Speed: 250.15 samples/sec#011loss=3.192442\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] Epoch[34] Batch[10] avg_epoch_loss=3.181266\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] Epoch[34] Batch [10]#011Speed: 255.82 samples/sec#011loss=3.167856\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] processed a total of 322 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1498.2798099517822, \"sum\": 1498.2798099517822, \"min\": 1498.2798099517822}}, \"EndTime\": 1532647544.702229, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647543.203901}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=214.897773478 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:44 INFO 139979114559296] Epoch[35] Batch[0] avg_epoch_loss=3.237042\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:45 INFO 139979114559296] Epoch[35] Batch[5] avg_epoch_loss=3.180632\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:45 INFO 139979114559296] Epoch[35] Batch [5]#011Speed: 255.87 samples/sec#011loss=3.180632\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:25:46 INFO 139979114559296] Epoch[35] Batch[10] avg_epoch_loss=3.207572\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:46 INFO 139979114559296] Epoch[35] Batch [10]#011Speed: 249.42 samples/sec#011loss=3.239900\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:46 INFO 139979114559296] processed a total of 329 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1486.9539737701416, \"sum\": 1486.9539737701416, \"min\": 1486.9539737701416}}, \"EndTime\": 1532647546.189548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647544.702303}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:46 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=221.239526593 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:46 INFO 139979114559296] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:46 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:46 INFO 139979114559296] Epoch[36] Batch[0] avg_epoch_loss=3.643813\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] Epoch[36] Batch[5] avg_epoch_loss=2.969648\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] Epoch[36] Batch [5]#011Speed: 250.62 samples/sec#011loss=2.969648\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] processed a total of 316 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1386.0409259796143, \"sum\": 1386.0409259796143, \"min\": 1386.0409259796143}}, \"EndTime\": 1532647547.575968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647546.189636}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=227.970869129 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_8722df9f-5505-4cb2-aae5-973a96691ba0-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.56100082397461, \"sum\": 23.56100082397461, \"min\": 23.56100082397461}}, \"EndTime\": 1532647547.599971, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647547.576031}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:47 INFO 139979114559296] Epoch[37] Batch[0] avg_epoch_loss=2.691846\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:48 INFO 139979114559296] Epoch[37] Batch[5] avg_epoch_loss=3.177383\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:48 INFO 139979114559296] Epoch[37] Batch [5]#011Speed: 254.74 samples/sec#011loss=3.177383\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] Epoch[37] Batch[10] avg_epoch_loss=2.971925\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] Epoch[37] Batch [10]#011Speed: 243.64 samples/sec#011loss=2.725376\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] processed a total of 321 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1546.0329055786133, \"sum\": 1546.0329055786133, \"min\": 1546.0329055786133}}, \"EndTime\": 1532647549.146119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647547.600035}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=207.614189675 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_17778438-def3-49f3-8b25-58564f9dc29a-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 28.222084045410156, \"sum\": 28.222084045410156, \"min\": 28.222084045410156}}, \"EndTime\": 1532647549.174793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647549.146186}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:49 INFO 139979114559296] Epoch[38] Batch[0] avg_epoch_loss=2.903771\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] Epoch[38] Batch[5] avg_epoch_loss=2.974287\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] Epoch[38] Batch [5]#011Speed: 249.21 samples/sec#011loss=2.974287\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] processed a total of 309 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1370.0251579284668, \"sum\": 1370.0251579284668, \"min\": 1370.0251579284668}}, \"EndTime\": 1532647550.544927, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647549.17485}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=225.525053652 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_16b0df8a-4bb6-4c51-a745-bb29c1662278-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 30.80582618713379, \"sum\": 30.80582618713379, \"min\": 30.80582618713379}}, \"EndTime\": 1532647550.576169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647550.545002}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:50 INFO 139979114559296] Epoch[39] Batch[0] avg_epoch_loss=3.105645\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:51 INFO 139979114559296] Epoch[39] Batch[5] avg_epoch_loss=3.280498\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:51 INFO 139979114559296] Epoch[39] Batch [5]#011Speed: 247.19 samples/sec#011loss=3.280498\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] Epoch[39] Batch[10] avg_epoch_loss=3.044226\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] Epoch[39] Batch [10]#011Speed: 248.70 samples/sec#011loss=2.760700\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] processed a total of 330 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1506.3109397888184, \"sum\": 1506.3109397888184, \"min\": 1506.3109397888184}}, \"EndTime\": 1532647552.082593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647550.576227}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=219.062566522 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] Epoch[40] Batch[0] avg_epoch_loss=3.339720\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] Epoch[40] Batch[5] avg_epoch_loss=3.327877\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:52 INFO 139979114559296] Epoch[40] Batch [5]#011Speed: 249.36 samples/sec#011loss=3.327877\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:53 INFO 139979114559296] processed a total of 315 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1351.1600494384766, \"sum\": 1351.1600494384766, \"min\": 1351.1600494384766}}, \"EndTime\": 1532647553.434159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647552.082664}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:53 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=233.113834642 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:53 INFO 139979114559296] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:53 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:53 INFO 139979114559296] Epoch[41] Batch[0] avg_epoch_loss=2.806483\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] Epoch[41] Batch[5] avg_epoch_loss=2.974174\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] Epoch[41] Batch [5]#011Speed: 248.35 samples/sec#011loss=2.974174\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] Epoch[41] Batch[10] avg_epoch_loss=3.206020\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] Epoch[41] Batch [10]#011Speed: 250.85 samples/sec#011loss=3.484236\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] processed a total of 331 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1517.6670551300049, \"sum\": 1517.6670551300049, \"min\": 1517.6670551300049}}, \"EndTime\": 1532647554.952217, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647553.434234}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=218.0823819 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:54 INFO 139979114559296] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:55 INFO 139979114559296] Epoch[42] Batch[0] avg_epoch_loss=3.318556\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:55 INFO 139979114559296] Epoch[42] Batch[5] avg_epoch_loss=3.105816\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:55 INFO 139979114559296] Epoch[42] Batch [5]#011Speed: 247.04 samples/sec#011loss=3.105816\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:25:56 INFO 139979114559296] processed a total of 311 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1368.332862854004, \"sum\": 1368.332862854004, \"min\": 1368.332862854004}}, \"EndTime\": 1532647556.320938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647554.952291}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:56 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=227.268593053 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:56 INFO 139979114559296] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:56 INFO 139979114559296] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:56 INFO 139979114559296] Epoch[43] Batch[0] avg_epoch_loss=3.089889\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] Epoch[43] Batch[5] avg_epoch_loss=3.097956\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] Epoch[43] Batch [5]#011Speed: 238.18 samples/sec#011loss=3.097956\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] Epoch[43] Batch[10] avg_epoch_loss=3.205720\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] Epoch[43] Batch [10]#011Speed: 222.90 samples/sec#011loss=3.335036\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] processed a total of 324 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1631.221055984497, \"sum\": 1631.221055984497, \"min\": 1631.221055984497}}, \"EndTime\": 1532647557.952834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647556.320998}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=198.609728607 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:57 INFO 139979114559296] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:58 INFO 139979114559296] Epoch[44] Batch[0] avg_epoch_loss=6.486947\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:58 INFO 139979114559296] Epoch[44] Batch[5] avg_epoch_loss=4.289501\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:58 INFO 139979114559296] Epoch[44] Batch [5]#011Speed: 247.13 samples/sec#011loss=4.289501\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:59 INFO 139979114559296] processed a total of 292 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1366.119146347046, \"sum\": 1366.119146347046, \"min\": 1366.119146347046}}, \"EndTime\": 1532647559.319362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647557.952913}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:59 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=213.727755626 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:59 INFO 139979114559296] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:59 INFO 139979114559296] loss did not improve for 6 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:25:59 INFO 139979114559296] Epoch[45] Batch[0] avg_epoch_loss=3.407556\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] Epoch[45] Batch[5] avg_epoch_loss=3.522715\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] Epoch[45] Batch [5]#011Speed: 248.66 samples/sec#011loss=3.522715\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] Epoch[45] Batch[10] avg_epoch_loss=3.425573\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] Epoch[45] Batch [10]#011Speed: 251.18 samples/sec#011loss=3.309004\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] processed a total of 326 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1485.2690696716309, \"sum\": 1485.2690696716309, \"min\": 1485.2690696716309}}, \"EndTime\": 1532647560.805031, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647559.319425}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=219.472186112 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:00 INFO 139979114559296] loss did not improve for 7 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:01 INFO 139979114559296] Epoch[46] Batch[0] avg_epoch_loss=3.516912\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:01 INFO 139979114559296] Epoch[46] Batch[5] avg_epoch_loss=3.520876\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:01 INFO 139979114559296] Epoch[46] Batch [5]#011Speed: 244.65 samples/sec#011loss=3.520876\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:02 INFO 139979114559296] processed a total of 306 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1388.3190155029297, \"sum\": 1388.3190155029297, \"min\": 1388.3190155029297}}, \"EndTime\": 1532647562.193773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647560.805106}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:02 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=220.391247315 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:02 INFO 139979114559296] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:02 INFO 139979114559296] loss did not improve for 8 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:02 INFO 139979114559296] Epoch[47] Batch[0] avg_epoch_loss=2.706182\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] Epoch[47] Batch[5] avg_epoch_loss=2.963400\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] Epoch[47] Batch [5]#011Speed: 242.29 samples/sec#011loss=2.963400\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] Epoch[47] Batch[10] avg_epoch_loss=3.067924\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] Epoch[47] Batch [10]#011Speed: 252.81 samples/sec#011loss=3.193352\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] processed a total of 350 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1501.0080337524414, \"sum\": 1501.0080337524414, \"min\": 1501.0080337524414}}, \"EndTime\": 1532647563.695343, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647562.193857}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=233.159708463 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] loss did not improve for 9 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:03 INFO 139979114559296] Epoch[48] Batch[0] avg_epoch_loss=2.983341\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:04 INFO 139979114559296] Epoch[48] Batch[5] avg_epoch_loss=2.926365\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:04 INFO 139979114559296] Epoch[48] Batch [5]#011Speed: 237.48 samples/sec#011loss=2.926365\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] processed a total of 316 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1416.8519973754883, \"sum\": 1416.8519973754883, \"min\": 1416.8519973754883}}, \"EndTime\": 1532647565.112587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647563.695414}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=223.012308919 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_a539dbe5-6e7f-4ca7-83b9-4fdf8a9af2d5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.947093963623047, \"sum\": 25.947093963623047, \"min\": 25.947093963623047}}, \"EndTime\": 1532647565.138954, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647565.112661}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] Epoch[49] Batch[0] avg_epoch_loss=3.766169\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] Epoch[49] Batch[5] avg_epoch_loss=3.607415\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:05 INFO 139979114559296] Epoch[49] Batch [5]#011Speed: 248.52 samples/sec#011loss=3.607415\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:06 INFO 139979114559296] processed a total of 307 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1372.6260662078857, \"sum\": 1372.6260662078857, \"min\": 1372.6260662078857}}, \"EndTime\": 1532647566.511716, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647565.139021}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:06 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=223.640810633 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:06 INFO 139979114559296] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:06 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:06 INFO 139979114559296] Epoch[50] Batch[0] avg_epoch_loss=3.805734\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:07 INFO 139979114559296] Epoch[50] Batch[5] avg_epoch_loss=3.329249\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:07 INFO 139979114559296] Epoch[50] Batch [5]#011Speed: 248.80 samples/sec#011loss=3.329249\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:07 INFO 139979114559296] processed a total of 305 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1398.4520435333252, \"sum\": 1398.4520435333252, \"min\": 1398.4520435333252}}, \"EndTime\": 1532647567.910609, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647566.511792}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:07 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=218.054497656 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:07 INFO 139979114559296] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:07 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:08 INFO 139979114559296] Epoch[51] Batch[0] avg_epoch_loss=3.117346\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:08 INFO 139979114559296] Epoch[51] Batch[5] avg_epoch_loss=3.233022\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:08 INFO 139979114559296] Epoch[51] Batch [5]#011Speed: 256.22 samples/sec#011loss=3.233022\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:09 INFO 139979114559296] processed a total of 304 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1346.1568355560303, \"sum\": 1346.1568355560303, \"min\": 1346.1568355560303}}, \"EndTime\": 1532647569.257391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647567.910693}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:09 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=225.811912489 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:09 INFO 139979114559296] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:09 INFO 139979114559296] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:09 INFO 139979114559296] Epoch[52] Batch[0] avg_epoch_loss=2.934622\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] Epoch[52] Batch[5] avg_epoch_loss=3.128029\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] Epoch[52] Batch [5]#011Speed: 249.90 samples/sec#011loss=3.128029\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] Epoch[52] Batch[10] avg_epoch_loss=2.983740\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] Epoch[52] Batch [10]#011Speed: 254.44 samples/sec#011loss=2.810593\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] processed a total of 329 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1491.9819831848145, \"sum\": 1491.9819831848145, \"min\": 1491.9819831848145}}, \"EndTime\": 1532647570.749781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647569.257451}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=220.495802765 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:10 INFO 139979114559296] Epoch[53] Batch[0] avg_epoch_loss=3.106603\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:11 INFO 139979114559296] Epoch[53] Batch[5] avg_epoch_loss=2.974421\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:11 INFO 139979114559296] Epoch[53] Batch [5]#011Speed: 244.17 samples/sec#011loss=2.974421\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:12 INFO 139979114559296] processed a total of 312 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1391.7510509490967, \"sum\": 1391.7510509490967, \"min\": 1391.7510509490967}}, \"EndTime\": 1532647572.141922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647570.749856}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:12 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=224.160320993 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:12 INFO 139979114559296] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:12 INFO 139979114559296] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:12 INFO 139979114559296] Epoch[54] Batch[0] avg_epoch_loss=3.127062\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] Epoch[54] Batch[5] avg_epoch_loss=3.109237\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] Epoch[54] Batch [5]#011Speed: 250.64 samples/sec#011loss=3.109237\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] Epoch[54] Batch[10] avg_epoch_loss=3.143299\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] Epoch[54] Batch [10]#011Speed: 255.45 samples/sec#011loss=3.184173\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] processed a total of 338 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1497.5569248199463, \"sum\": 1497.5569248199463, \"min\": 1497.5569248199463}}, \"EndTime\": 1532647573.639843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647572.141997}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=225.686923345 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] loss did not improve for 6 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:13 INFO 139979114559296] Epoch[55] Batch[0] avg_epoch_loss=2.881275\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:14 INFO 139979114559296] Epoch[55] Batch[5] avg_epoch_loss=3.098820\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:14 INFO 139979114559296] Epoch[55] Batch [5]#011Speed: 243.49 samples/sec#011loss=3.098820\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] Epoch[55] Batch[10] avg_epoch_loss=2.926244\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] Epoch[55] Batch [10]#011Speed: 250.20 samples/sec#011loss=2.719153\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] processed a total of 334 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1534.7380638122559, \"sum\": 1534.7380638122559, \"min\": 1534.7380638122559}}, \"EndTime\": 1532647575.174965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647573.6399}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=217.608593388 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_9d34a437-0329-4a04-8354-8f38e99a5f52-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 26.076078414916992, \"sum\": 26.076078414916992, \"min\": 26.076078414916992}}, \"EndTime\": 1532647575.201472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647575.175056}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:15 INFO 139979114559296] Epoch[56] Batch[0] avg_epoch_loss=3.185640\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:26:16 INFO 139979114559296] Epoch[56] Batch[5] avg_epoch_loss=3.072548\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:16 INFO 139979114559296] Epoch[56] Batch [5]#011Speed: 247.25 samples/sec#011loss=3.072548\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:16 INFO 139979114559296] processed a total of 317 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1380.4230690002441, \"sum\": 1380.4230690002441, \"min\": 1380.4230690002441}}, \"EndTime\": 1532647576.582002, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647575.201531}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:16 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=229.621619755 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:16 INFO 139979114559296] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:16 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:16 INFO 139979114559296] Epoch[57] Batch[0] avg_epoch_loss=2.791850\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:17 INFO 139979114559296] Epoch[57] Batch[5] avg_epoch_loss=3.072649\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:17 INFO 139979114559296] Epoch[57] Batch [5]#011Speed: 253.40 samples/sec#011loss=3.072649\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] Epoch[57] Batch[10] avg_epoch_loss=2.981424\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] Epoch[57] Batch [10]#011Speed: 248.32 samples/sec#011loss=2.871955\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] processed a total of 332 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1556.2310218811035, \"sum\": 1556.2310218811035, \"min\": 1556.2310218811035}}, \"EndTime\": 1532647578.138607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647576.582077}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=213.32073812 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] Epoch[58] Batch[0] avg_epoch_loss=2.766963\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] Epoch[58] Batch[5] avg_epoch_loss=2.887496\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:18 INFO 139979114559296] Epoch[58] Batch [5]#011Speed: 251.67 samples/sec#011loss=2.887496\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:19 INFO 139979114559296] processed a total of 310 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1345.771074295044, \"sum\": 1345.771074295044, \"min\": 1345.771074295044}}, \"EndTime\": 1532647579.484775, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647578.138684}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:19 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=230.332238685 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:19 INFO 139979114559296] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:19 INFO 139979114559296] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:19 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/state_343f13ff-a83d-4081-8fc0-562f27fc4c99-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 31.074047088623047, \"sum\": 31.074047088623047, \"min\": 31.074047088623047}}, \"EndTime\": 1532647579.516267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647579.48485}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:19 INFO 139979114559296] Epoch[59] Batch[0] avg_epoch_loss=3.036542\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:20 INFO 139979114559296] Epoch[59] Batch[5] avg_epoch_loss=3.188854\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:20 INFO 139979114559296] Epoch[59] Batch [5]#011Speed: 248.51 samples/sec#011loss=3.188854\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] Epoch[59] Batch[10] avg_epoch_loss=3.010351\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] Epoch[59] Batch [10]#011Speed: 251.13 samples/sec#011loss=2.796146\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] processed a total of 340 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1505.6450366973877, \"sum\": 1505.6450366973877, \"min\": 1505.6450366973877}}, \"EndTime\": 1532647581.022017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647579.516328}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=225.798530475 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] loss did not improve for 1 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] Epoch[60] Batch[0] avg_epoch_loss=2.636869\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] Epoch[60] Batch[5] avg_epoch_loss=2.929294\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:21 INFO 139979114559296] Epoch[60] Batch [5]#011Speed: 223.33 samples/sec#011loss=2.929294\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:22 INFO 139979114559296] processed a total of 316 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1432.4018955230713, \"sum\": 1432.4018955230713, \"min\": 1432.4018955230713}}, \"EndTime\": 1532647582.454846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647581.022109}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:22 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=220.590926014 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:22 INFO 139979114559296] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:22 INFO 139979114559296] loss did not improve for 2 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:22 INFO 139979114559296] Epoch[61] Batch[0] avg_epoch_loss=3.134847\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] Epoch[61] Batch[5] avg_epoch_loss=3.180405\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] Epoch[61] Batch [5]#011Speed: 251.47 samples/sec#011loss=3.180405\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] Epoch[61] Batch[10] avg_epoch_loss=3.221759\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] Epoch[61] Batch [10]#011Speed: 251.93 samples/sec#011loss=3.271384\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] processed a total of 324 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1506.2229633331299, \"sum\": 1506.2229633331299, \"min\": 1506.2229633331299}}, \"EndTime\": 1532647583.961528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647582.454922}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=215.093023488 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:23 INFO 139979114559296] loss did not improve for 3 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:24 INFO 139979114559296] Epoch[62] Batch[0] avg_epoch_loss=3.171430\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:24 INFO 139979114559296] Epoch[62] Batch[5] avg_epoch_loss=3.111461\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:24 INFO 139979114559296] Epoch[62] Batch [5]#011Speed: 251.92 samples/sec#011loss=3.111461\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:25 INFO 139979114559296] processed a total of 304 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1351.8288135528564, \"sum\": 1351.8288135528564, \"min\": 1351.8288135528564}}, \"EndTime\": 1532647585.313766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647583.96159}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:25 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=224.862024306 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:25 INFO 139979114559296] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:25 INFO 139979114559296] loss did not improve for 4 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:25 INFO 139979114559296] Epoch[63] Batch[0] avg_epoch_loss=2.611132\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:26 INFO 139979114559296] Epoch[63] Batch[5] avg_epoch_loss=2.981926\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:26 INFO 139979114559296] Epoch[63] Batch [5]#011Speed: 248.43 samples/sec#011loss=2.981926\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:26 INFO 139979114559296] processed a total of 319 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1378.6728382110596, \"sum\": 1378.6728382110596, \"min\": 1378.6728382110596}}, \"EndTime\": 1532647586.692816, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647585.313841}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:26 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=231.363458115 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:26 INFO 139979114559296] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:26 INFO 139979114559296] loss did not improve for 5 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:26 INFO 139979114559296] Epoch[64] Batch[0] avg_epoch_loss=3.232919\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:27 INFO 139979114559296] Epoch[64] Batch[5] avg_epoch_loss=3.065772\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:27 INFO 139979114559296] Epoch[64] Batch [5]#011Speed: 254.79 samples/sec#011loss=3.065772\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:28 INFO 139979114559296] Epoch[64] Batch[10] avg_epoch_loss=3.194105\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:28 INFO 139979114559296] Epoch[64] Batch [10]#011Speed: 243.69 samples/sec#011loss=3.348104\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:28 INFO 139979114559296] processed a total of 349 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1527.8820991516113, \"sum\": 1527.8820991516113, \"min\": 1527.8820991516113}}, \"EndTime\": 1532647588.221104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647586.692892}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:28 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=228.400308567 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:28 INFO 139979114559296] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:28 INFO 139979114559296] loss did not improve for 6 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:28 INFO 139979114559296] Epoch[65] Batch[0] avg_epoch_loss=2.830024\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] Epoch[65] Batch[5] avg_epoch_loss=3.147656\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] Epoch[65] Batch [5]#011Speed: 251.98 samples/sec#011loss=3.147656\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] Epoch[65] Batch[10] avg_epoch_loss=3.253231\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] Epoch[65] Batch [10]#011Speed: 256.01 samples/sec#011loss=3.379921\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] processed a total of 339 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1471.580982208252, \"sum\": 1471.580982208252, \"min\": 1471.580982208252}}, \"EndTime\": 1532647589.693081, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647588.221189}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=230.347880985 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] loss did not improve for 7 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:29 INFO 139979114559296] Epoch[66] Batch[0] avg_epoch_loss=3.098118\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:30 INFO 139979114559296] Epoch[66] Batch[5] avg_epoch_loss=3.178283\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:30 INFO 139979114559296] Epoch[66] Batch [5]#011Speed: 254.89 samples/sec#011loss=3.178283\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[07/26/2018 23:26:31 INFO 139979114559296] processed a total of 303 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1374.3329048156738, \"sum\": 1374.3329048156738, \"min\": 1374.3329048156738}}, \"EndTime\": 1532647591.067807, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647589.693153}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:31 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=220.450980879 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:31 INFO 139979114559296] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:31 INFO 139979114559296] loss did not improve for 8 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:31 INFO 139979114559296] Epoch[67] Batch[0] avg_epoch_loss=3.359209\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:31 INFO 139979114559296] Epoch[67] Batch[5] avg_epoch_loss=3.094839\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:31 INFO 139979114559296] Epoch[67] Batch [5]#011Speed: 243.54 samples/sec#011loss=3.094839\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:32 INFO 139979114559296] processed a total of 316 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1402.163028717041, \"sum\": 1402.163028717041, \"min\": 1402.163028717041}}, \"EndTime\": 1532647592.47043, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647591.06787}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:32 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=225.34953728 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:32 INFO 139979114559296] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:32 INFO 139979114559296] loss did not improve for 9 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:32 INFO 139979114559296] Epoch[68] Batch[0] avg_epoch_loss=3.259624\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] Epoch[68] Batch[5] avg_epoch_loss=2.980228\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] Epoch[68] Batch [5]#011Speed: 247.01 samples/sec#011loss=2.980228\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] processed a total of 313 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1379.5459270477295, \"sum\": 1379.5459270477295, \"min\": 1379.5459270477295}}, \"EndTime\": 1532647593.850428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647592.470495}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] #throughput_metric: host=algo-1, train throughput=226.868173479 records/second\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] loss did not improve for 10 epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] stopping training now\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] Loading parameters from best epoch (58)\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 13.11492919921875, \"sum\": 13.11492919921875, \"min\": 13.11492919921875}}, \"EndTime\": 1532647593.864119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647593.850504}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] Final loss: 2.85591890812 (occurred at epoch 58)\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] #quality_metric: host=algo-1, train final_loss <loss>=2.85591890812\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 WARNING 139979114559296] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:33 INFO 139979114559296] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 633.0139636993408, \"sum\": 633.0139636993408, \"min\": 633.0139636993408}}, \"EndTime\": 1532647594.497706, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647593.864189}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:35 INFO 139979114559296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 1212.946891784668, \"sum\": 1212.946891784668, \"min\": 1212.946891784668}}, \"EndTime\": 1532647595.077607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647594.497771}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:35 INFO 139979114559296] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:35 INFO 139979114559296] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 92.40412712097168, \"sum\": 92.40412712097168, \"min\": 92.40412712097168}}, \"EndTime\": 1532647595.170131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647595.077677}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:35 INFO 139979114559296] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:35 INFO 139979114559296] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.0400543212890625, \"sum\": 0.0400543212890625, \"min\": 0.0400543212890625}}, \"EndTime\": 1532647595.1709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647595.170203}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 2222.1169471740723, \"sum\": 2222.1169471740723, \"min\": 2222.1169471740723}}, \"EndTime\": 1532647597.39298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647595.170943}\n",
      "\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, RMSE): 174.249848682\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, mean_wQuantileLoss): 0.521046\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.1]): 0.256757\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.2]): 0.387031\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.3]): 0.47381\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.4]): 0.535676\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.5]): 0.580952\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.6]): 0.610366\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.7]): 0.624365\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.8]): 0.623301\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #test_score (algo-1, wQuantileLoss[0.9]): 0.59716\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #quality_metric: host=algo-1, test RMSE <loss>=174.249848682\u001b[0m\n",
      "\u001b[31m[07/26/2018 23:26:37 INFO 139979114559296] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.521046340466\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 104685.95695495605, \"sum\": 104685.95695495605, \"min\": 104685.95695495605}, \"setuptime\": {\"count\": 1, \"max\": 9.936809539794922, \"sum\": 9.936809539794922, \"min\": 9.936809539794922}}, \"EndTime\": 1532647597.526076, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1532647597.393047}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: DeeparFinance-2018-07-26-23-21-04-610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n",
      "Billable seconds: 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name DeeparFinance-2018-07-26-23-21-04-610\n",
      "INFO:sagemaker:Creating endpoint with name DeeparFinance-2018-07-26-23-21-04-610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and deploy a DeepAR model\n",
    "\n",
    "# Setup the DeepAR containers/paths \n",
    "containers = {'us-east-1': '522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:latest'}\n",
    "image_name = containers[boto3.Session().region_name]\n",
    "s3filesystem = s3fs.S3FileSystem()\n",
    "s3_data_path = 'jeremydavid1/sagemaker/data' # Replace by a valid S3 bucket name\n",
    "\n",
    "# Prepare the data \n",
    "ts_train = full['close']\n",
    "ts_train_cov = full['STOCKBclose']\n",
    "ts_train_news = full['s']\n",
    "\n",
    "# Fetch data into proper JSON strings that DeepAR can consume, then write to S3\n",
    "s = ts_train.shape\n",
    "lagdeep = round(s[0]/10) # DeepAR samples lag and horiz on each ts so needs length >> (lag + horiz)\n",
    "def load_data(stock, lag, horiz):\n",
    "    data = stock.as_matrix() \n",
    "    lags = []\n",
    "    horizons = [] \n",
    "    nsample = len(data) - horiz  # len(data) - lag - horiz  # Number of time series (Number of sample in 3D)\n",
    "    for i in range(0,nsample,lag): \n",
    "        lags.append(data[i: i + lag])                  \n",
    "        horizons.append(data[i + lag : i + lag + horiz])    \n",
    "    x_train = np.array(lags)\n",
    "    y_train = np.array(horizons)\n",
    "    return [x_train, y_train]\n",
    "\n",
    "X_train, y_train = load_data(ts_train, lagdeep, horiz)\n",
    "X_train_cov, y_train_cov = load_data(ts_train_cov, lagdeep, horiz)\n",
    "X_train_news, y_train_news = load_data(ts_train_news, lagdeep, horiz)\n",
    "\n",
    "def series_to_obj(ts,t,cat):\n",
    "    obj = {\"start\": str(t), \"target\": list(ts), \"cat\": cat}\n",
    "    return obj\n",
    "\n",
    "def series_to_jsonline(ts,t,cat):\n",
    "    return json.dumps(series_to_obj(ts,t,cat))\n",
    "\n",
    "with s3filesystem.open(s3_data_path + \"/train/train.json\", 'wb') as fp:\n",
    "    for i in range(len(X_train)): \n",
    "        fp.write(series_to_jsonline(X_train[i],ts_train.index[i],0).encode(\"utf-8\"))     # cat = 0 for target\n",
    "        fp.write('\\n'.encode(\"utf-8\"))\n",
    "        fp.write(series_to_jsonline(X_train_cov[i],ts_train.index[i],1).encode(\"utf-8\")) # cat = 1 for covariate\n",
    "        fp.write('\\n'.encode(\"utf-8\"))       \n",
    "        fp.write(series_to_jsonline(X_train_news[i],ts_train.index[i],2).encode(\"utf-8\")) # cat = 1 for covariate\n",
    "        fp.write('\\n'.encode(\"utf-8\"))  \n",
    "\n",
    "with s3filesystem.open(s3_data_path + \"/test/test.json\", 'wb') as fp:\n",
    "    for i in range(len(y_train)): \n",
    "        fp.write(series_to_jsonline(y_train[i],ts_train.index[i+lag],0).encode(\"utf-8\"))\n",
    "        fp.write('\\n'.encode(\"utf-8\"))\n",
    "        fp.write(series_to_jsonline(y_train_cov[i],ts_train.index[i+lag],1).encode(\"utf-8\"))\n",
    "        fp.write('\\n'.encode(\"utf-8\"))\n",
    "        fp.write(series_to_jsonline(y_train_news[i],ts_train.index[i+lag],2).encode(\"utf-8\"))\n",
    "        fp.write('\\n'.encode(\"utf-8\"))\n",
    "        \n",
    "# Define DeepAR estimator\n",
    "estimator = sage.estimator.Estimator(\n",
    "    sagemaker_session=sess,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.xlarge',\n",
    "    base_job_name='DeeparFinance',\n",
    "    output_path=\"s3://\" + s3_data_path\n",
    ")\n",
    "\n",
    "# Define hyperparameters\n",
    "freq = 'D'\n",
    "prediction_length = horiz\n",
    "context_length = lag\n",
    "\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"cardinality\": 3,\n",
    "    \"embedding_dimension\": 10,\n",
    "    \"num_cells\": \"100\",\n",
    "    \"num_layers\": \"5\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"100\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"dropout_rate\": \"0.1\",\n",
    "    \"early_stopping_patience\": \"10\"\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "# Train the model\n",
    "data_channels = {\n",
    "    \"train\": \"s3://{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"s3://{}/test/\".format(s3_data_path)\n",
    "}\n",
    "estimator.fit(inputs=data_channels)\n",
    "\n",
    "\n",
    "# Deploy the DeepAR model\n",
    "job_name = estimator.latest_training_job.name\n",
    "endpoint_name = sess.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    deployment_image=image_name,\n",
    "    role=role\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-22\n",
      "2016-06-03\n",
      "Forecasted:  [701.680480957, 718.9865722656, 718.7622680664, 717.1608886719, 714.1392822266, 715.6391601562, 713.3333740234, 712.115234375, 714.0823974609, 707.2515258789]\n",
      "Observed:  [706.3216189658151 705.4624399659621 718.8932927601668 707.2947926159261\n",
      " 726.4835317756862 714.6745181486232 723.9255701536003 722.8790451892575\n",
      " 724.5534665133741 728.6536240571036]\n"
     ]
    }
   ],
   "source": [
    "# Use the DeepAR model to forecast future trends of stock values\n",
    "\n",
    "# Create a pandas series format (= list of df)\n",
    "time_series = []\n",
    "temp = d2[d2.symbol == target]\n",
    "data = temp[temp.index < '2016-06-05']\n",
    "t0 = str(data.index[0]) \n",
    "print(t0)\n",
    "print(data.index[-1])\n",
    "data.drop(['open','low','high','symbol'], 1, inplace=True) \n",
    "s = data.shape\n",
    "index = pd.DatetimeIndex(start=t0, freq=freq, periods=s[0])\n",
    "time_series.append(pd.Series(data=data['close'].tolist(), index=index))\n",
    "\n",
    "# To build a prediction request to the endpoint we'll just adapt the utility class provided in the original \n",
    "# AWS SageMaker DeepAR sample notebook (needs input in pandas series format instead of json string)\n",
    "\n",
    "class DeepARPredictor(sage.predictor.RealTimePredictor):\n",
    "\n",
    "    def set_prediction_parameters(self, freq, prediction_length):\n",
    "        self.freq = freq\n",
    "        self.prediction_length = prediction_length\n",
    "        \n",
    "    def predict(self, ts, cat=None, encoding=\"utf-8\", num_samples=100, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        prediction_times = [x.index[-1]+1 for x in ts]\n",
    "        req = self.__encode_request(ts, cat, encoding, num_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, prediction_times, encoding)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, encoding, num_samples, quantiles):\n",
    "        instances = [series_to_obj(ts[k], ts[k].index[0], cat) for k in range(len(ts))]\n",
    "        configuration = {\"num_samples\": num_samples, \"output_types\": [\"quantiles\"], \"quantiles\": quantiles}\n",
    "        http_request_data = {\"instances\": instances, \"configuration\": configuration}\n",
    "        return json.dumps(http_request_data).encode(encoding)\n",
    "    \n",
    "    def __decode_response(self, response, prediction_times, encoding):\n",
    "        response_data = json.loads(response.decode(encoding))\n",
    "        list_of_df = []\n",
    "        for k in range(len(prediction_times)):\n",
    "            prediction_index = pd.DatetimeIndex(start=prediction_times[k], freq=self.freq, periods=self.prediction_length)\n",
    "            list_of_df.append(pd.DataFrame(data=response_data['predictions'][k]['quantiles'], index=prediction_index))\n",
    "        return (list_of_df, response_data)\n",
    "\n",
    "predictor = DeepARPredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "predictor.set_prediction_parameters(freq, prediction_length)\n",
    "\n",
    "# Forecasting\n",
    "#X_test = testdata['close']\n",
    "#print(time_series_training)\n",
    "results,jsonform = predictor.predict(time_series,0) # cat = 0 for target\n",
    "dfcst = jsonform['predictions'][0]['quantiles']['0.5']\n",
    "print('Forecasted: ',dfcst)\n",
    "print('Observed: ', horizons1[0,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Vizualize results from all methods together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c0e9927f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot observed and predicted horizons for all benchmarked methods\n",
    "xax = np.array([]); xax = [np.append(xax,i) for i in range(1,horiz+1)]\n",
    "plt.figure(1,figsize=(7,5))\n",
    "mpl.rcParams['font.size']=14\n",
    "plt.plot(xax,horizons1[0,:],color='#A9A9A9',marker='s', label=\"Obs\",linewidth=5,markersize=10) \n",
    "plt.plot(xax, afcst,color='#40E0D0',marker='o',label=\"ARIMAx\",linewidth=5,markersize=10)\n",
    "plt.plot(xax, dfcst,color='#00BFFF',marker='o',label=\"DeepAR\",linewidth=5,markersize=10)\n",
    "plt.plot(xax,fcst1[:],color='#FF9900',marker='s', label=\"Cust RNN\",linewidth=5,markersize=10)\n",
    "plt.xlabel('Time (days)')\n",
    "plt.ylabel('Stock value ($)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Day of forecast: '+ dates1[0][0],loc='right')\n",
    "miny = round(min(horizons1[0,:])/10)*10 - 40\n",
    "maxy = miny + 121\n",
    "plt.ylim(miny,maxy)\n",
    "plt.yticks(np.arange(miny,maxy,20))\n",
    "plt.savefig('benchmarks.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: rnn-forecast006-2018-04-20-19-08-28-477\n"
     ]
    }
   ],
   "source": [
    "# Delete endpoint\n",
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
